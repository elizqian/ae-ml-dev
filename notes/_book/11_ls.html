<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>AE 4803 AIM: Course Notes - 2&nbsp; Linear Least Squares Problems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./12_lslinalg.html" rel="next">
<link href="./01_intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./11_ls.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Least Squares Problems</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AE 4803 AIM: Course Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_ls.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Least Squares Problems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_lslinalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">LLS: Linear Algebra Perspective</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_lsstat.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">LLS: Statistical Perspective</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_ugbo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Unconstrained Gradient Based Optimization (UGBO)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_ugbo2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Linear algebra review</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#classifying-regression-problems-as-linear-vs-nonlinear" id="toc-classifying-regression-problems-as-linear-vs-nonlinear" class="nav-link active" data-scroll-target="#classifying-regression-problems-as-linear-vs-nonlinear"><span class="header-section-number">2.1</span> Classifying regression problems as linear vs nonlinear</a></li>
  <li><a href="#mathematical-problem-formulation" id="toc-mathematical-problem-formulation" class="nav-link" data-scroll-target="#mathematical-problem-formulation"><span class="header-section-number">2.2</span> Mathematical problem formulation</a></li>
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples"><span class="header-section-number">2.3</span> Examples</a>
  <ul class="collapse">
  <li><a href="#example-1-aerodynamic-drag-prediction" id="toc-example-1-aerodynamic-drag-prediction" class="nav-link" data-scroll-target="#example-1-aerodynamic-drag-prediction"><span class="header-section-number">2.3.1</span> Example 1: Aerodynamic drag prediction</a></li>
  <li><a href="#example-2-something-else" id="toc-example-2-something-else" class="nav-link" data-scroll-target="#example-2-something-else"><span class="header-section-number">2.3.2</span> Example 2: something else</a></li>
  <li><a href="#example-3-something-else" id="toc-example-3-something-else" class="nav-link" data-scroll-target="#example-3-something-else"><span class="header-section-number">2.3.3</span> Example 3: something else</a></li>
  </ul></li>
  <li><a href="#solving-linear-least-squares-problems" id="toc-solving-linear-least-squares-problems" class="nav-link" data-scroll-target="#solving-linear-least-squares-problems"><span class="header-section-number">2.4</span> Solving linear least squares problems</a></li>
  <li><a href="#assessing-the-learned-models" id="toc-assessing-the-learned-models" class="nav-link" data-scroll-target="#assessing-the-learned-models"><span class="header-section-number">2.5</span> Assessing the learned models</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">2.6</span> Exercises</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">2.7</span> Further reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Least Squares Problems</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<!-- \renewcommand{\P}{\mathrm{P}} -->
<!-- $$
\DeclarePairedDelimiters{\set}{\{}{\}}
\DeclareMathOperator*{\argmax}{argmax}
$$

\definecolor{quarto-callout-note-color}{HTML}{4477AA} -->
</div>
<p>We begin our exploration of scientific machine learning methods in the fundamental setting of <em>linear regression problems</em>. The intended learning outcomes of these notes are that students should be able to:</p>
<ol type="1">
<li><p>Classify a regression problem as linear or nonlinear</p></li>
<li><p>Understand the abstract form of linear least squares problems</p>
<ol type="a">
<li><p>Define the abstract form of linear least squares problems and be able to explain what its key ingredients are</p></li>
<li><p>Translate a description of a model learning problem in words into a specific instance of the abstract form</p></li>
<li><p>Construct examples of linear least squares problems, cast them in the abstract form, and explain their context</p></li>
</ol></li>
<li><p>Solve linear least-squares problems by deriving and solving the normal equations.</p></li>
<li><p>Evaluate linear regression models by computing and interpreting mean error, mean relative error, and R^2 values on both training and test data sets.</p></li>
</ol>
<section id="classifying-regression-problems-as-linear-vs-nonlinear" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="classifying-regression-problems-as-linear-vs-nonlinear"><span class="header-section-number">2.1</span> Classifying regression problems as linear vs nonlinear</h2>
<p>We have previously introduced regression problems in a general way: recall that the three ingredients of (parametrized) regression problems are (1) paired input and output data, (2) the choice of a parametrized model class, and (3) a method for choosing a model from within that class. The classification of a regression problem as <em>linear</em> or <em>nonlinear</em> depends solely on ingredient (2), the parametrized model class: if the models in that class depend linearly on the model parameters, the regression problem is a linear regression problem.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Check your knowledge: Do you remember what it means for a function to depend linearly on a variable?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The function <span class="math inline">\(f(z;\theta): \mathbb{R}^d\times\Theta\to\mathbb{R}\)</span> is said to be <em>linear</em> in the parameters <span class="math inline">\(\theta\)</span> if, for all <span class="math inline">\(a,b\in\mathbb{R}\)</span> and all <span class="math inline">\(\theta_1,\theta_2\in\Theta\)</span>, the following holds: <span class="math inline">\(f(z; a\theta_1 + b\theta_2) = af(z;\theta_1) + bf(z;\theta_2)\)</span>.</p>
<p>Note that when we say a function is “linear”, we have to specify in <em>what</em>. That is, we can also say <span class="math inline">\(f(z;\theta)\)</span> is linear in the <em>inputs</em> if, for all <span class="math inline">\(a,b\in\mathbb{R}\)</span> and all <span class="math inline">\(z_1,z_2\in\mathbb{R}^d\)</span>, the following holds: <span class="math inline">\(f(az_1 + bz_2;\theta) = af(z_1;\theta)+bf(z_2;\theta)\)</span>.</p>
</div>
</div>
</div>
<p>The classification of regression problems as linear or nonlinear depends <strong>solely</strong> on the dependence of the functions in the parametrized model class on the <strong>parameters</strong>. That is, we can define functions that are <em>linear</em> in <span class="math inline">\(\theta\)</span> while being <em>nonlinear</em> in <span class="math inline">\(z\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider the model classes (<span class="quarto-unresolved-ref">?eq-quad-models</span>)-(<span class="quarto-unresolved-ref">?eq-perceptron</span>) introduced previously. Are these model classes linear or nonlinear in the parameters? In the inputs?</p>
</div>
</div>
</section>
<section id="mathematical-problem-formulation" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="mathematical-problem-formulation"><span class="header-section-number">2.2</span> Mathematical problem formulation</h2>
<p>We are now going to introduce an <em>abstract</em> mathematical problem formulation that can be used to describe many <em>specific instances</em> of linear regression problems. This is a theme of the course and throughout computational mathematics and engineering: abstraction using the language of mathematics lets us isolate the core essence of the problem we’re solving and develop powerful algorithms that can solve specific applications of those problems across a wide range of disciplines. I’ll introduce the abstract formulation first, and follow it up with some specific examples.</p>
<p>Ingredient 1 (the data set): let <span class="math inline">\(\{(z_i,y_i)\}_{i=1}^N\)</span> be a given data set of paired inputs <span class="math inline">\(z_i\in\mathbb{R}^d\)</span> and outputs <span class="math inline">\(y_i\in\mathbb{R}\)</span>.</p>
<p>Ingredient 2 (the parametrized model class): let <span class="math inline">\(x:\mathbb{R}^d\to\mathbb{R}^n\)</span> be a function that maps the <span class="math inline">\(d\)</span>-dimensional input to an <span class="math inline">\(n\)</span>-dimensional <em>feature vector</em>. For a fixed <span class="math inline">\(x\)</span>, we will consider the following parametrized model class:</p>
<p><span id="eq-linreg-model-class"><span class="math display">\[
\mathcal{F}_\beta := \{ x(z)^\top \beta : \beta\in\mathbb{R}^n\}
\qquad(2.1)\]</span></span></p>
<p>Recall that <a href="#eq-linreg-model-class" class="quarto-xref">Equation&nbsp;<span>2.1</span></a> is read as “<span class="math inline">\(\mathcal{F}_\beta\)</span> is defined to be the set of all functions <span class="math inline">\(f(z;\beta) = x(z)^\top\beta\)</span> for all <span class="math inline">\(\beta\in\mathbb{R}^n\)</span>.” This is an abstract way to define the model class for <em>any</em> linear regression problem, as we will describe in more detail shortly.</p>
<p>Ingredient 3 (the method of choosing the parameters): let <span class="math inline">\(\beta^*\)</span> be given by</p>
<p><span id="eq-linreg-minimization"><span class="math display">\[
\begin{aligned}
\beta^* &amp;= \arg\min_{\beta\in\mathbb{R}^n} \frac1N \sum_{i=1}^N (f(z_i;\beta) - y_i)^2 \\
&amp;= \arg\min_{\beta\in\mathbb{R}^N} \frac1N \sum_{i=1}^N (x(z_i)^\top\beta - y_i)^2.
\end{aligned}
\qquad(2.2)\]</span></span> Then, we define the <em>learned model</em> to be <span class="math inline">\(f(z;\beta^*) = x(z)^\top\beta^*\)</span>. We call <span class="math inline">\(\beta^*\)</span> defined this way the “optimal regression parameters” or just the “optimal parameters”, because they are the result of solving an optimization problem. Note that the objective of this optimization function is <em>defined by the data</em>, and represents the average squared error of the model over the data set.</p>
<p>Taken together, the three ingredients I have defined above define a <em>linear least squares problem</em>, which is a subclass of linear regression problems. We’ll now give several examples of specific instances of linear least squares problems to illustrate how broadly applicable this abstract framework is.</p>
</section>
<section id="examples" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="examples"><span class="header-section-number">2.3</span> Examples</h2>
<section id="example-1-aerodynamic-drag-prediction" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="example-1-aerodynamic-drag-prediction"><span class="header-section-number">2.3.1</span> Example 1: Aerodynamic drag prediction</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/AirfoilDrag.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Image Source: Embry-Riddle Aeronautical University</figcaption>
</figure>
</div>
<p>An important task in aerodynamic design is predicting lift and drag forces on a body moving through air. Let’s consider a simplified problem where we are given an fixed airfoil design and our goal is to predict the drag force <span class="math inline">\(F_d\)</span> on the airfoil as a function of three parameters which describe its flight conditions:</p>
<ul>
<li>The angle of attack <span class="math inline">\(\alpha\)</span></li>
<li>The density of the fluid <span class="math inline">\(\rho\)</span></li>
<li>The freestream velocity of the air <span class="math inline">\(v\)</span></li>
</ul>
<p>To put this problem in our abstract framework, we define <span class="math inline">\(z = (\alpha,\rho,v)^\top\)</span> to be a three-dimensional input, and take the output to be the drag force <span class="math inline">\(y= F_d\)</span>. In order to define a regression problem, we require the existence of a data set <span class="math inline">\(\{(z_i,y_i)\}_{i=1}^N\)</span>. Note that in this case <span class="math inline">\(z_i = (\alpha_i,\rho_i,v_i)\)</span>. We assume that this data set is given.</p>
<p>In linear regression problems, defining the model class amounts to choosing a set of regression <em>features</em> by defining <span class="math inline">\(x\)</span>. A simple choice takes the inputs themselves to be features: <span class="math inline">\(x^{(1)}(z) = z = (\alpha,\rho,v)^\top\)</span>. This leads to a class of parametrized models with a three-dimensional unknown parameter vector <span class="math inline">\(\beta\in\mathbb{R}^3\)</span>. The models in this class have the following form:</p>
<p><span class="math display">\[
f^{(1)}(z;\beta) = x^{(1)}(z)^\top\beta = (\alpha,\rho,v) \beta = \beta_1\alpha + \beta_2\rho + \beta_3 v.
\]</span></p>
<p>There are many other possible choices. For example, consider <span class="math inline">\(x^{(2)}(z) = (\alpha,\rho, v, \alpha^2, \rho^2, v^2, \alpha\rho, \alpha v, \rho v)^\top\)</span>. This leads to a parametrized model class with a <em>nine</em>-dimensional unknown parameter vector <span class="math inline">\(\beta\in\mathbb{R}^9\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
f^{(2)}(z;\beta) &amp;= x^{(2)}(z)^\top\beta = (\alpha,\rho, v, \alpha^2, \rho^2, v^2, \alpha\rho, \alpha v, \rho v)\beta \\
&amp;= \beta_1\alpha + \beta_2\rho + \beta_3 v + \beta_4\alpha^2 + \beta_5\rho^2 + \beta_6 v^2 + \beta_7\alpha\rho + \beta_8\alpha v + \beta_9 \rho v
\end{aligned}
\]</span></p>
<p>For either the above choices of features <span class="math inline">\(x^{(1)}(z)\)</span> or <span class="math inline">\(x^{(2)}(z)\)</span>, we could then define and solve the minimization <a href="#eq-linreg-minimization" class="quarto-xref">Equation&nbsp;<span>2.2</span></a> to find the optimal regression parameters and define our learned model <span class="math inline">\(f^{(1)}(z;\beta^*)\)</span> or <span class="math inline">\(f^{(2)}(z;\beta^*)\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding notation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that we use <span class="math inline">\(\beta\)</span> to denote the unknown parameters in both <span class="math inline">\(f^{(1)}\)</span> and <span class="math inline">\(f^{(2)}\)</span> above despite <span class="math inline">\(\beta\)</span> referring to different quantities in the definition of the different functions. This is a common notational shortcut — while we could use the notation <span class="math inline">\(\beta^{(1)}\in\mathbb{R}^3\)</span> and <span class="math inline">\(\beta^{(2)}\in\mathbb{R}^9\)</span> to specify the different <span class="math inline">\(\beta\)</span> for the different functions, this can be cumbersome if we are considering many different options for the choice of features <span class="math inline">\(x(z)\)</span>, and it’s standard to just use <span class="math inline">\(\beta\)</span>, where the definition of <span class="math inline">\(\beta\)</span> is implied by the context. One of the challenges in learning about machine learning and computational mathematics more generally is getting used to similar notation meaning different things in different contexts. That’s one of the things that we’ll practice in this course.</p>
</div>
</div>
</section>
<section id="example-2-something-else" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="example-2-something-else"><span class="header-section-number">2.3.2</span> Example 2: something else</h3>
</section>
<section id="example-3-something-else" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="example-3-something-else"><span class="header-section-number">2.3.3</span> Example 3: something else</h3>
</section>
</section>
<section id="solving-linear-least-squares-problems" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="solving-linear-least-squares-problems"><span class="header-section-number">2.4</span> Solving linear least squares problems</h2>
<p>Linear least squares problems are special because they have closed form solutions: that is, we can write an analytical expression for the optimum parameters <span class="math inline">\(\beta^*\)</span> in terms of the data. To do so, we are going to define a feature data matrix <span class="math inline">\(X\in\mathbb{R}^{N\times n}\)</span> and an output data vector <span class="math inline">\(Y\in\mathbb{R}^N\)</span> as follows:</p>
<p><span class="math display">\[
X = \begin{pmatrix}
- &amp;x(z_1) &amp; - \\
&amp; \vdots &amp; \\
- &amp; x(z_N) &amp; -
\end{pmatrix},
\qquad
Y = \begin{pmatrix}
y_1 \\ \vdots \\ y_N
\end{pmatrix},
\]</span> where the <em>rows</em> of <span class="math inline">\(X\)</span> and the <em>elements</em> of <span class="math inline">\(Y\)</span> correspond to input-output pairs in the data set. Note that each <em>column</em> of <span class="math inline">\(X\)</span> corresponds to a different <em>feature</em> defined by an element of the vector-valued function <span class="math inline">\(x\)</span>.</p>
<p>Using this notation, <a href="#eq-linreg-minimization" class="quarto-xref">Equation&nbsp;<span>2.2</span></a> can be rewritten as</p>
<p><span id="eq-linreg-matrix-min"><span class="math display">\[
\beta^* = \arg\min_{\beta\in\mathbb{R}^n} \frac1N\|X \beta - Y\|^2
\qquad(2.3)\]</span></span></p>
<p>This is the minimization of a multivariate function (because <span class="math inline">\(\beta\)</span> is a vector). Recall from calculus that to find minimizers of multivariate functions we first seek <em>critical points</em> that satisfy the <em>first-order necessary conditions</em> for optimality: that is, we look for points where the derivative of the objective function is 0. Let <span class="math inline">\(\mathcal{L}(\beta) = \frac1N\|X\beta-Y\|^2 = \frac1N(X\beta - Y)^\top (X\beta-Y)\)</span>. Then,</p>
<p><span class="math display">\[
\frac{\partial\mathcal{L}}{\partial \beta} = \frac2N(X^\top X\beta - X^\top Y)
\]</span></p>
<p>Setting the derivative equal to 0 yields the standard <em>normal equations</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span class="math display">\[
X^\top X\beta^* = X^\top Y
\]</span></p>
<p>If <span class="math inline">\((X^\top X)\)</span> is invertible, then the unique solution to the normal equations is given by</p>
<p><span class="math display">\[
\beta^* = (X^\top X)^{-1} X^\top Y
\]</span></p>
<p>and this choice of <span class="math inline">\(\beta\)</span> defines our final learned model: <span class="math inline">\(f(z;\beta^*) = x(z)^\top\beta^*\)</span>.</p>
<!-- 
Suppose we have taken $N$ real-life samples of the input variables and their corresponding drag-force, $F_d$. Let each sample of the system under various operating conditions form row of a matrix $\mathbf{X} \in \mathbb{R}^{N \times 4}$ for the inputs and a matrix $\mathbf{Y} \in \mathbb{R}^N$ for their corresponding outputs: 

$$ \mathbf{X} = \begin{bmatrix} 1 & \alpha_1 & \rho_1 & v_1 \\ 1 & \alpha_2 & \rho_2 & v_2 \\ & & \vdots & \\ 1 & \alpha_N & \rho_N & v_N \end{bmatrix} , \mathbf{Y} = \begin{bmatrix} F_{d1} \\ F_{d2} \\ \vdots \\ F_{d3} \end{bmatrix} $$ 

 
We can efficiently compute the predictions of $h(\mathbf{X}; \beta)$ with a simple matrix-vector multiplication:  -->
<!-- $$ \hat{\mathbf{Y}} = \mathbf{X} \beta = \begin{bmatrix} 1 & \alpha_1 & \rho_1 & v_1 \\ 1 & \alpha_2 & \rho_2 & v_2 \\ & & \vdots & \\ 1 & \alpha_N & \rho_N & v_N \end{bmatrix} \begin{bmatrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \beta_3 \end{bmatrix} = \begin{bmatrix}  \beta_0 + \beta_1 \alpha_1 + \beta_2 \rho_1 + \beta_3 v_1 \\ \beta_0 + \beta_1 \alpha_2 + \beta_2 \rho_2 + \beta_3 v_2  \\ \vdots \\ \beta_0 + \beta_1 \alpha_N + \beta_2 \rho_N + \beta_3 v_N \end{bmatrix}  \in \mathbb{R}^N $$  -->
<!-- Our goal is to adjust the parameters $\beta$ so that our predictions, $\hat{\mathbf{Y}}$, are as close to the true outputs, $\mathbf{Y}$ as possible. One way to measure prediction error is with Mean Squared Error: 

$$ \text{MSE} = \frac{1}{N} \sum_{i=1}^N (\hat{y}_i - y_i)^2 = \frac{1}{N} || \hat{\mathbf{Y}} - \mathbf{Y}||_2^2 = \frac{1}{N} || \mathbf{X} \beta - \mathbf{Y} ||_2^2 $$ 

the $\frac{1}{N}$ is only a scalar, we wish to choose the value of $\beta$ that minimizes the following loss-function: 

$$ L(\beta) = ||\mathbf{X} \beta - \mathbf{Y}||_2^2 $$

## Solving the Least-Squares Problem -->
<!-- Because the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as: 

$$ L(\beta) = ||\mathbf{X} \beta - \mathbf{Y}||_2^2= (\mathbf{X} \beta - \mathbf{Y})^\top (\mathbf{X} \beta - \mathbf{Y}) $$
$$ = (\beta^\top \mathbf{X}^\top - \mathbf{Y}^\top) (\mathbf{X} \beta - \mathbf{Y}) $$

$$ = \beta^\top \mathbf{X^\top X} \beta - 2 \beta^\top \mathbf{X^\top \mathbf{Y}} + \mathbf{Y^\top Y}$$ -->
<!-- As we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:

$$ \nabla L_\beta = 2 \mathbf{X^\top X} \beta - 2 \mathbf{X^\top Y} = \mathbf{0}$$ 

Solving this equation for $\beta$ yields only one critical point: 

$$ \hat{\beta} = (\mathbf{X^\top X})^{-1} \mathbf{X^\top Y} $$ 

To check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian: 

$$ \nabla^2 L_\beta = 2 \mathbf{X^\top X} $$ 

Because the Hessian is symmetric positive semidefinite and does not depend on $\beta$, this means that $L(\beta)$ is convex everywhere. Hence, $\hat{\beta}$ must be a global local minimum.  -->
</section>
<section id="assessing-the-learned-models" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="assessing-the-learned-models"><span class="header-section-number">2.5</span> Assessing the learned models</h2>
<p>various metrics, validation? definitely test data sets.</p>
</section>
<section id="exercises" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="exercises"><span class="header-section-number">2.6</span> Exercises</h2>
<p>a few relatively short questions that test the learning outcomes.</p>
<ul>
<li><p>math training: derive the derivative of the loss function by expanding, and then applying identities from <span class="citation" data-cites="petersen2012matrix">(<a href="references.html#ref-petersen2012matrix" role="doc-biblioref">Petersen and Pedersen 2012</a>)</span>. Hard mode: prove the identities by calculation.</p></li>
<li><p>math training/review: what does it mean for a matrix <span class="math inline">\(A\)</span> to be invertible (inverse exists, square and full rank, linearly independent rows/columns)</p></li>
<li><p>math training: prove that <span class="math inline">\(X^\top X\)</span> is invertible iff <span class="math inline">\(X\)</span> has full column rank.</p></li>
<li><p>math training: explain why the minimizer is unique iff <span class="math inline">\(X^\top X\)</span> is invertible… what happens if it’s not invertible?</p></li>
</ul>
</section>
<section id="further-reading" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">2.7</span> Further reading</h2>
<p>any appropriate links</p>
<hr>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-petersen2012matrix" class="csl-entry" role="listitem">
Petersen, Kaare Brandt, and Michael Syskind Pedersen. 2012. <span>“The Matrix Cookbook.”</span> <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf</a>.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>note that the constant factor <span class="math inline">\(\frac2N\)</span> drops out. It’s common to play fast and loose with multiplicative constants in minimizations – other sources define the minimization objective with a <span class="math inline">\(\frac12\)</span> multiplier, which leads to the derivative not having the factor of 2 in front and leads to the same critical point. Or you may see the objective function defined without the <span class="math inline">\(1/N\)</span> in front, which still leads to the same critical point.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01_intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./12_lslinalg.html" class="pagination-link" aria-label="LLS: Linear Algebra Perspective">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">LLS: Linear Algebra Perspective</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>