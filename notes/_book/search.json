[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AE 4803 AIM: Course Notes",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cambridge Dictionary. 2024. “Data Science.”\n2024. https://dictionary.cambridge.org/dictionary/english/data-science.\n\n\nMartins, Joaquim RRA, and Andrew Ning. 2021. Engineering Design\nOptimization. Cambridge University Press.\n\n\nMerriam-Webster Dictionary. 2024. “Machine\nLearning.” 2024. https://www.merriam-webster.com/dictionary/machine%20learning."
  },
  {
    "objectID": "01_ls.html",
    "href": "01_ls.html",
    "title": "ML for AE: Least Squares Regression",
    "section": "",
    "text": "A Motivating Example\nSuppose we wish to efficiently approximate the force of drag (\\(F_d\\)), measured in \\(N\\), on a specific airplane wing if we only have access to the following information about the wing and its operating conditions:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#a-motivating-example",
    "href": "01_ls.html#a-motivating-example",
    "title": "ML for AE: Least Squares Regression",
    "section": "",
    "text": "Image Source: Embry-Riddle Aeronautical University\n\n\n\n\nThe angle of attack (\\(\\alpha\\)), measured in degrees\nThe density of the fluid (\\(\\rho\\)), measured in \\(kg/m^3\\)\nThe velocity of the fluid (\\(v\\)), measured in \\(m/s\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#linear-approximation-of-an-unknown-function",
    "href": "01_ls.html#linear-approximation-of-an-unknown-function",
    "title": "ML for AE: Least Squares Regression",
    "section": "Linear Approximation of an Unknown Function",
    "text": "Linear Approximation of an Unknown Function\nLet’s bundle our inputs into a single vector, defined by:\n\\[ \\mathbf{x} = \\begin{bmatrix} \\alpha \\\\ \\rho \\\\ v\\end{bmatrix} \\]\nWe assume there is some unknown function, \\(f(\\cdot):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\), that gives us an optimal estimate for drag-force based on these “features”:\n\\[ F_d = f (\\mathbf{x}) + \\varepsilon \\]\nwhere \\(\\varepsilon\\) is some external noise, disturbances or information entirely independent of the input variables.\nNow consider a function \\(h(\\mathbf{x}; \\beta):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\) which is a simple linear combination of the inputs:\n\\[ h(\\mathbf{x}; \\beta) = \\begin{bmatrix} 1 & \\mathbf{x}^\\top \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3  \\end{bmatrix} = \\beta_0 + \\beta_1 \\alpha + \\beta_2 \\rho + \\beta_3 v \\]\nThe Million Dollar Question:\nGiven we know the structure of \\(h(\\mathbf{x}; \\beta)\\), how can we efficiently optimize the parameters of \\(h(\\mathbf{x}; \\beta)\\) to best approximate \\(f(\\mathbf{x})\\)?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#representing-observed-input-output-data",
    "href": "01_ls.html#representing-observed-input-output-data",
    "title": "ML for AE: Least Squares Regression",
    "section": "Representing Observed Input-Output Data",
    "text": "Representing Observed Input-Output Data\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#the-least-squares-optimization-problem",
    "href": "01_ls.html#the-least-squares-optimization-problem",
    "title": "ML for AE: Least Squares Regression",
    "section": "The Least-Squares Optimization Problem",
    "text": "The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#solving-the-least-squares-problem",
    "href": "01_ls.html#solving-the-least-squares-problem",
    "title": "ML for AE: Least Squares Regression",
    "section": "Solving the Least-Squares Problem",
    "text": "Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#experimental-example",
    "href": "01_ls.html#experimental-example",
    "title": "ML for AE: Least Squares Regression",
    "section": "Experimental Example",
    "text": "Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#using-nonlinear-features-to-improve-model-performance",
    "href": "01_ls.html#using-nonlinear-features-to-improve-model-performance",
    "title": "ML for AE: Least Squares Regression",
    "section": "Using Nonlinear Features to Improve Model Performance",
    "text": "Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "00_linalg.html",
    "href": "00_linalg.html",
    "title": "Appendix A — Linear algebra review",
    "section": "",
    "text": "A.1 Linear Algebra Crash Course\nBefore we dive into the world of machine learning and optimization, it’s important that we get comfortable with the fundamental building blocks of mathematics in higher dimensions: Linear Algebra. This course assumes you have seen basic concepts in Linear Algebra, but we’ll provide a refresher to get everyone on the same page.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#scalars-vectors-and-matrices",
    "href": "00_linalg.html#scalars-vectors-and-matrices",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.1 Scalars, Vectors, and Matrices",
    "text": "2.1 Scalars, Vectors, and Matrices\nNotation\nLet’s introduce some notation: \\(\\mathbb{R}\\) is the set of real numbers, \\(\\mathbb{C}\\) is the set of complex numbers, and the operator \\(\\in\\) designates that a variable belongs to a set. To define a real scalar (i.e. just a number), \\(c\\), we write:\n\\[ c \\in \\mathbb{R}\\]\nYou can read this as “the variable \\(c\\) belongs to the set of 1-dimensional real numbers.”\nTo define a real \\(n\\) dimensional vector, \\(\\mathbf{x}\\), we write:\n\\[ \\mathbf{x}  = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nTo define a \\(m \\times n\\) matrix \\(\\mathbf{A}\\) of real-valued entries, we write:\n\\[ \\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n }\n\\]\nThe Transposes\nThe “transpose” of a matrix or vector, swaps the rows and columns. In other words, the first row becomes the first column, the second row the second column and so-on:\n\\[ \\mathbf{x}^\\top = \\begin{bmatrix} x_1 & \\dots & x_n \\end{bmatrix} \\in \\mathbb{R}^{1 \\times n} \\]\n\\[ \\mathbf{A}^\\top = \\begin{bmatrix} a_{11} & a_{21} & \\dots & a_{m1} \\\\\na_{12} & a_{22} & & a_{m2} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{n \\times m } \\]\nTransposing the product of matrices reverses their order:\n\\[ \\left( \\mathbf{A} \\mathbf{B} \\mathbf{C} \\mathbf{D} \\right)^\\top = \\mathbf{D}^\\top \\mathbf{C}^\\top \\mathbf{B}^\\top \\mathbf{A}^\\top \\]\nAddition & subtraction\nTechnically, only objects of the same dimensionality can be added or subtracted with one another. So, scalars can only be added to scalars, vectors can only be added to vectors of the same dimension, and matrices can only be added to other matrices with the same numbers of rows and columns. Some software like MATLAB or NumPy might let you add scalars to vectors and matrices and under the hood they multiply that scalar by a vector/matrix of ones to make the dimensions match.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#scalar-multiplication",
    "href": "00_linalg.html#scalar-multiplication",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.2 Scalar Multiplication",
    "text": "2.2 Scalar Multiplication\nGenerally, scalars can multiply by any structure (scalar, vector, and matrix) and do not change its dimension. They only “scale” its value by a certain amount. Hence, multiplying a scalar by a scalar returns a scalar, multiplying a scalar times a vector returns a vector, and multiplying a scalar by a matrix returns a matrix. Scalar multiplication is also commutative, i.e. \\(c\\mathbf{A} = \\mathbf{A}c\\) for all scalars \\(c\\). Consider our scalar, \\(c\\), from the previous section, another scalar, \\(b\\), the vector \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and the matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\)\n\nScalar-Scalar Product: \\[b \\times c = bc \\in \\mathbb{R}\\]\nScalar-Vector Product: \\[ c \\mathbf{x} = \\mathbf{x} c = \\begin{bmatrix} c x_1 \\\\ \\vdots \\\\ c x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nScalar-Matrix Product: \\[ c \\mathbf{A} = \\mathbf{A} c = \\begin{bmatrix} c a_{11} & c a_{12} & \\dots & c a_{1n} \\\\\nc a_{21} & c a_{22} & & c a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\nc a_{m1} & c a_{m2} & \\dots & c a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n } \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#matrix-vector-multiplication",
    "href": "00_linalg.html#matrix-vector-multiplication",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.3 Matrix & Vector Multiplication",
    "text": "2.3 Matrix & Vector Multiplication\nVector-Vector Multiplication\nTo multiply two matrices (or two vectors, or a matrix with a vector), their inner dimensions must always match. Hence, the only valid way to multiply two vectors is by “inner” or “outer” products. Consider two vectors, \\(\\mathbf{u} \\in \\mathbb{R}^n\\) and \\(x \\in \\mathbb{R}^n\\). An “Inner Product” (sometimes called the Dot-Product) is defined as:\n\\[ \\mathbf{u}^\\top \\mathbf{x} = \\begin{bmatrix} u_1 & \\dots & u_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = u_1 x_1 + u_2 x_2 + \\dots u_n x_n \\in \\mathbb{R}\\]\nSome important notes about inner products:\n\nIf the dimensions of \\(\\mathbf{u}\\) and \\(\\mathbf{x}\\) do not match, we cannot multiply them this way as we need to multiply each entry of both vectors.\nThis operation returns a scalar value.\nInner Products are commutative, i.e. \\(\\mathbf{u}^\\top \\mathbf{x} = \\mathbf{x}^\\top \\mathbf{u}\\), as they are sums of scalar-scalar multiplications which are also commutative.\n\nRecall \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Now consider a new vector \\(\\mathbf{w} \\in \\mathbb{R}^m\\) where \\(m \\neq n\\). An “Outer Product” is defined as:\n\\[ \\mathbf{w} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_m \\end{bmatrix} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\mathbf{x}^\\top  \\\\ \\vdots \\\\ w_m \\mathbf{x}^\\top  \\end{bmatrix} = \\begin{bmatrix} w_1 x_1 & w_1 x_2 & \\dots & w_1 x_n \\\\ w_2 x_1 & w_2 x_2 & & w_2 x_n \\\\ \\vdots & & \\ddots & \\vdots \\\\ w_m x_1 & w_m x_2 & \\dots & w_m x_n \\end{bmatrix} \\in \\mathbb{R}^{m \\times n} \\]\nImportant notes on outer products:\n\nOuter products return matrices with dimensions according to the vectors multiplied.\nAs long as \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) are vectors, outer products share an inner dimension of \\(1\\), which means that any two vectors have an outer product.\nLastly, this operation is non-commutative, meaning \\(\\mathbf{w} \\mathbf{x}^\\top \\neq \\mathbf{x} \\mathbf{w}^\\top\\). Rather, these two are transposes of each other.\n\nMatrix-Vector Multiplication\nMultiplying a matrix with a vector means the dimension of the vector must equal the number of columns of the matrix. Recall \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Note that the columns of \\(\\mathbf{A}\\) match the dimension of \\(\\mathbf{x}\\), which are both size \\(n\\). The product \\(\\mathbf{A}\\mathbf{x}\\) can be written as:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n} x_n \\\\  a_{21} x_1 + a_{22} x_2 + \\dots + a_{2n} x_n \\\\ \\vdots \\\\a_{m1} x_1 + a_{m2} x_2 + \\dots + a_{mn} x_n  \\end{bmatrix} \\in \\mathbb{R}^m \\]\nPerhaps a more useful way to visualize this is to break \\(\\mathbf{A}\\) down into its constituent columns and show this as a sum of scalar-vector multiplications:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} x_1 + \\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} x_2 + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} x_n  \\in \\mathbb{R}^m \\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\). Note that matrix-vector multiplication forms a linear map from one dimensional vector-space to another. In this case, \\(\\mathbf{A}\\mathbf{x}\\) maps a vector from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^m\\). This linear transformation from one dimensionality to another is a core component of many machine learning algorithms.\nMatrix-Matrix Multiplication\nConsider two matrices, \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{B} \\in \\mathbb{R}^{n \\times k}\\), where \\(m \\neq k\\). Again, the inner dimensions must match to multiply matrices. Because \\(\\mathbf{A}\\) multiplied by \\(\\mathbf{B}\\) have an inner-dimension of \\(n\\), they can be multiplied. Similar to matrix-vector multiplication, we can visualize the product of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) by breaking up the columns and rows of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), respectively:\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\\\ - & \\mathbf{b}_2 & - \\\\ & \\vdots & \\\\  - & \\mathbf{b}_n & - \\end{bmatrix} \\in \\mathbb{R}^{m \\times k}\\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\) and \\(\\mathbf{b}_i\\) is the \\(i\\)th row of \\(\\mathbf{B}\\). We can expand this expression by multiplying each column of \\(\\mathbf{A}\\) with each row of \\(\\mathbf{B}\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\end{bmatrix} +\\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_2 & - \\end{bmatrix} + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_n & - \\end{bmatrix}\\]\nAs we can see, this is a sum of outer products (vectors multiplied by transposed vectors). We know \\(\\mathbf{A}\\) has \\(m\\) rows and \\(\\mathbf{B}\\) has \\(k\\) columns, so each outer product will form a matrix of dimension \\(m \\times k\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\sum_{i=1}^n \\mathbf{a}_i \\mathbf{b}_i \\in \\mathbb{R}^{m \\times k}\\]\nNote: matrix multiplication is generally non-commutative; The product \\(\\mathbf{A}\\mathbf{B}\\) is valid, because the number of columns of \\(\\mathbf{A}\\) matches the number of rows of \\(\\mathbf{B}\\). However, the product \\(\\mathbf{B}\\mathbf{A}\\) is not valid, because the number of columns of \\(\\mathbf{B}\\) does not equal the number of rows of \\(\\mathbf{A}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#vector-norms",
    "href": "00_linalg.html#vector-norms",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.4 Vector Norms",
    "text": "2.4 Vector Norms\nOftentimes, it is useful to know how “big” a vector is. And there are many different ways of computing this. The “norm” of an object is a measure of how “large” it is, according to some rule. Consider \\(\\mathbf{x} \\in \\mathbb{R}^n\\). The \\(l_p\\) norm is defined by the following:\n\\[ ||\\mathbf{x}||_p = \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} \\]\nThis formula may not be so intuitive, so let’s consider three special instances of the \\(l_p\\) norms:\nThe 1-Norm\nThe 1-norm of \\(\\mathbf{x}\\) is simply the sum of the absolute-value of its entries:\n\\[ ||\\mathbf{x}||_1 = |x_1| + |x_2| + \\dots + |x_n| \\]\nThe 2-Norm\nThe 2-norm of \\(x\\) (which we will use most-often in this class) is defined as the squareroot of the squares of its entries:\n\\[ ||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} \\]\nThe reason the 2-norm is so useful is the fact that the square of the \\(l_2\\) norm is an inner product of a vector with itself:\n\\[ \\mathbf{x}^\\top \\mathbf{x} = x_1^2 + x_2^2 + \\dots + x_3^2 = ||\\mathbf{x}||_2^2 \\]\nThis helps us write a norm in terms of matrix-vector operations, which is extremely useful for optimization. The 2-norm is also quite important because it is the first \\(l_p\\) norm with a continuous derivative, which cannot be said of the 1-norm since it uses absolute-value functions.\nThe Infinity-Norm\nThe infinity-norm takes the limit as \\(p \\rightarrow \\infty\\) and when this limit is solved, this norm simply becomes the entry of \\(x\\) with the largest absolute value:\n\\[ ||\\mathbf{x}||_\\infty = \\max \\{ |x_1|, |x_2|, \\dots, |x_n| \\} \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#rank-rangecolumn-space-and-null-spaces",
    "href": "00_linalg.html#rank-rangecolumn-space-and-null-spaces",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.5 Rank, Range/Column-Space and Null-Spaces",
    "text": "2.5 Rank, Range/Column-Space and Null-Spaces\nLinear-Independence\nThis is a fundamental idea in Linear Algebra. A set of vectors is said to be “Linearly Independent” if no vector in this set can be reconstructed with any of the others. In other words, no one vector can be reproduced by scaling or combining any of the others. For example, consider the following three vectors:\n\\[ \\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\} \\]\nBecause each vector in this set points in its own unique direction, it is impossible to reconstruct one of these vectors as a linear combination of any others. This may be true with more complex vectors that aren’t unit vectors along the dimensions of the vector-space.\nRank\nThe rank of a matrix is simply the number of linearly independent columns. Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 & 1 & 4 \\\\ 0 & 1 & 1 & 2 \\\\ 0 & 0 & 2 & 0 \\end{bmatrix} \\]\nThe first-three columns of \\(\\mathbf{A}\\) are linearly independent because they cannot be reproduced using linear combinations of the other columns. However, the last column is a multiple of column 2, which means it can be reproduced using a linear combination of columns. Hence, this matrix has a rank of 3.\nTheorem: No matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) where \\(m &lt; n\\) can be full-rank. This is because only \\(m\\) vectors can span \\(\\mathbb{R}^m\\), and since there are more than \\(m\\) columns, we must have some redundancy.\nRange/Column-Space\nThe Range, Column-Space or Image of a matrix, \\(\\mathbf{A}\\), is the span of all possible combinations of its columns. In human words, it describes the space of \\(\\mathbf{Ax}\\) for all possible \\(\\mathbf{x}\\). Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\\\ 2 & 4  \\end{bmatrix} \\]\nNote that the second column is a multiple of the first column, hence, the range of \\(\\mathbf{A}\\) is:\n\\[ \\text{Range}(\\mathbf{A}) = \\text{span} \\left( \\begin{bmatrix} 1 \\\\ 3 \\\\ 2 \\end{bmatrix}\\right) \\]\nNull-Space\nThe Null-Space of a matrix, \\(\\mathbf{A}\\) is the set of all nonzero vectors, \\(\\mathbf{x}\\) such that \\(\\mathbf{Ax=0}\\). Consider a simple example:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\]\nWe can find the set of \\(\\mathbf{x}\\) that produce the zero-vector by solving the following equation:\n\\[ \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\]\nThis produces the systems of equations:\n\\[ x_1 - x_3 = 0 \\] \\[ x_2 + x_3 = 0 \\] \\[ x_3 = x_3 \\]\nIf we isolate each entry of \\(\\mathbf{x}\\):\n\\[ x_1 = x_3 \\] \\[ x_2 = -x_3 \\] \\[ x_3 = x_3 \\]\nHence, we see that \\(x_3\\) can be any scalar and satisfy this systems of equations:\n\\[ \\mathbf{x} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} x_3 = \\text{span}\\left( \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} \\right) = \\text{Null}(\\mathbf{A})\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#the-identity-matrix",
    "href": "00_linalg.html#the-identity-matrix",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.6 The Identity Matrix",
    "text": "2.6 The Identity Matrix\nThe identity matrix is a square, \\(n\\)-dimensional matrix consisting of ones on its diagonal and zeros elsewhere. It is called the identity matrix because it preserves the identity when multiplied by matrices and vectors.\n\\[ \\mathbf{I} = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\ 0 & 1  & & 0 \\\\ \\vdots & & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & 1 \\end{bmatrix} \\]\nConsider \\(\\mathbf{I} \\in \\mathbb{R}^{n \\times n}\\) to be an \\(n \\times n\\) identity matrix. If we recall \\(\\mathbf{A} \\in \\mathbb{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\):\n\\[ \\mathbf{A I = I A = A} \\]\n\\[ \\mathbf{I x = x } \\]\n\\[ \\mathbf{x^\\top I = x^\\top} \\]\nWhy is this useful?\nThe identity matrix simplifies expressions involving matrices. If we can transform a term into an identity matrix, then we can reduce the expression to only the remaining terms.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#matrix-inverses",
    "href": "00_linalg.html#matrix-inverses",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.7 Matrix Inverses",
    "text": "2.7 Matrix Inverses\nYou may have noticed that, thus far, we have covered the addition, subtraction, and multiplication of matrices, which conspicuously leaves division. Well, unfortunately, matrix division is complex to say the least. For square matrices, division is accomplished via matrix inversion. However, not all matrices are invertible.\nDefinition: A matrix \\(\\mathbf{B}\\) is called the “inverse” of a square matrix \\(\\mathbf{A}\\) if and only if the following condition holds:\n\\[ \\mathbf{A} \\mathbf{B} = \\mathbf{B} \\mathbf{A} = \\mathbf{I} \\]\nwhere \\(\\mathbf{I}\\) is the identity matrix. Such a \\(\\mathbf{B}\\) is denoted \\(\\mathbf{A}^{-1}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html",
    "href": "20_ugbo.html",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "",
    "text": "4 Problem Motivation\nIn this lecture, we will be focusing on the following optimization problem,\n\\[\\min_x f(x)\\]\nwhere \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\) is our objective function (or loss function), and \\(x\\in\\mathbb{R}^n\\) is a vector of parameters (variables) which we can change. Minimization problems arise in numerous physical and real-world circumstances, including:\nFor this lecture, our approach for solving the above minimization problem will be a gradient-based one. This means that we will make use of information from the gradient of \\(f\\) (first-order information), and the curvature of \\(f\\) (second-order information).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#what-are-we-looking-for",
    "href": "20_ugbo.html#what-are-we-looking-for",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.1 What are we looking for?",
    "text": "5.1 What are we looking for?\nTo start, we first need to motivate some fundamental definitions regarding the nature of the solution we are looking for.\nDefinition: We say that a point \\(x^\\star\\) is a global minimizer of \\(f\\) if: \\[f(x^\\star)\\leq f(x) \\text{ for all }x\\in \\mathcal{D}\\subseteq\\mathbb{R}^n.\\]\nAlthough a global minimizer is the most desireable outcome from our minimization problem, finding a global minimizer is often quite challenging. This is because a global minimizer may not always exist, and because we often only possess local information about the function \\(f\\). This motivates the following defintion:\nDefinition: We say that a point \\(x^\\star\\) is a local minimizer of \\(f\\) if there exists some open set \\(\\mathcal{B}\\), that contains \\(x^\\star\\), such that: \\[\nf(x^\\star)\\leq f(x) \\text{ for all }x\\in\\mathcal{B}.\n\\] If the inequality becomes strict, then \\(x^\\star\\) is referred to as a strict local minimizer. To illustrate the above definitions, let us look at the function \\(f(x) = 2 + \\cos(x) + \\frac{1}{2} \\cos\\left(5x - \\frac{1}{2}\\right)\\) over the domain \\(\\mathcal{D} = [0, 3.7]\\). In this domain, the function has two local minimizers and one global minimizer, as illustrated in the plot below.\n\n\n\n\n\n\n\n\n\nWe now have a way to understand and characterize our solutions. However, the above definitions suggest that we need to examine all points that are next to \\(x^\\star\\) in order to properly characterize it. However, if our function is smooth, i.e., its higher order derivatives exist and are continuous, then we can classify \\(x^\\star\\) by examining the derivatives of \\(f\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#gradient",
    "href": "20_ugbo.html#gradient",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.2 Gradient",
    "text": "5.2 Gradient\nRecall that the gradient of a function \\(f(x)\\), denoted \\(\\nabla f(x)\\), is the column vector of partial derivaties with respect to each parameter: \\[\n\\nabla f(x) =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1}\\\\\n\\vdots\\\\\n\\frac{\\partial f}{\\partial x_i}\\\\\n\\vdots\\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix}\n\\] Each element of \\(\\nabla f(x)\\) captures the rate of change of the function \\(f\\) with respect to the parameter \\(x_i\\). The gradient of a function helps us identify local minimizers and allows us to state (without proof) the first fundamental result of gradient-based optimization.\nTheorem (first-order necessary conditions): If \\(x^\\star\\) is a local minimizer and \\(f\\) is continuously differentiable in an open nieghborhood of \\(x^\\star\\), then \\(\\nabla f(x^\\star) = 0\\).\nA point \\(x^\\star\\) is called a stationary point if \\(\\nabla f(x^\\star) = 0\\). The above theorem guarantees that all local minimizers must be stationary points. However, the theorem cannot guarantee that all stationary points are local minimizers. This is because the conditions are necessary but not sufficient. As a counterexample, a stationary point may be a local maximizer instead of a local minimizer. In order to obtain necessary and suffient conditions, we need to move one derivative higher.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#curvature",
    "href": "20_ugbo.html#curvature",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.3 Curvature",
    "text": "5.3 Curvature\nThe curvature of a function \\(f\\) is the rate of change of the gradient, and tells us whether the slope is stationary, increasing, or decreasing. To compute the curvature of \\(f\\), we need to take a partial derivate of every component of the gradient with respect to each coordinate direction. This leads to an \\((n\\times n)\\) matrix of second partial derivatives called the Hessian:\n\\[\nH(x) = \\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n\\end{bmatrix}\n\\]\nIf our function \\(f\\) has continuous second partial derivatives, then the order of differentiation does not matter and the matrix \\(H\\) becomes symmetric. The Hessian allows us to establish two more (stronger) fundamental results of gradient-based optimization. Before stating them, let us recall that a matrix \\(A\\) is positive definite if \\(x^\\top A x &gt; 0\\) for all \\(x\\neq 0\\) and positive semidefinite if \\(x^\\top A x \\geq 0\\) for all \\(x\\).\nTheorem (second-order necessary conditions): If \\(x^\\star\\) is a local minimizer of \\(f\\) and the Hessian \\(H\\) exists and is continuous in an open neighborhood of \\(x^\\star\\), then \\(\\nabla f(x^\\star) = 0\\) and \\(H\\) is positive semidefinite.\nTheorem (second-order sufficient conditions): Suppose that \\(H\\) is is continuous in an open neighborhood of \\(x^\\star\\) and that \\(\\nabla f(x^\\star) =0\\) and \\(H\\) is positive definite. Then, \\(x^\\star\\) is a strict local minimizer of \\(f\\).\nIt is important to remark that the second-order sufficient condition gurantee a stronger result when compared to the second-order necessary condtions. Namely, the second-order sufficient conditions lead to a strict local minimizer. Furthermore, we should also note that the sufficient condtions are not necessary; it is possible for a point \\(x^\\star\\) to be a strict local minimizer but fail to satisfy the sufficient conditions. As an example, consider \\(f(x) = x^6\\), where \\(x^\\star = 0\\) is a strict local minimizer, yet the Hessian evaluates to zero at \\(x^\\star = 0\\) and is therefore not positive definite.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#a-complete-example",
    "href": "20_ugbo.html#a-complete-example",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.4 A complete example",
    "text": "5.4 A complete example\nHere, we work our way through an example problem where we can see how the concepts from above can be applied to help us identify and characterize critical points. Consider the function:\n\\[\nf(x_1, x_2) = 0.5x_1^4 + 2x_1^3 + 1.5x_1^2 + x_2^2 - 2x_1x_2\n\\]\nLet’s plot the contours of \\(f\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function\ndef f(x1, x2):\n    return 0.5 * x1**4 + 2 * x1**3 + (3/2) * x1**2 + x2**2 - 2 * x1 * x2\n\n# Create the contour plot\nx = np.linspace(-4, 2, 1000)\ny = np.linspace(-4, 2, 1000)\nX, Y = np.meshgrid(x, y)\nZ = f(X, Y)\n\nplt.figure(figsize=(9.5, 5))\ncontour = plt.contour(X, Y, Z, levels=75)\nplt.xlabel(r'$x_1$')\nplt.ylabel(r'$x_2$')\n\nText(0, 0.5, '$x_2$')\n\n\n\n\n\n\n\n\n\nTo start, we need to identify all critical points of \\(f\\). We can do that by solving for all points such that \\(\\nabla f(x) = 0\\), i.e.,\n\\[\n\\nabla f(x_1, x_2) =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2}\n\\end{bmatrix} =\n\\begin{bmatrix}\n2x_1^3 + 6x_1^2 + 3x_1 - 2x_2 \\\\ 2x_2 - 2x_1\n\\end{bmatrix} =\n\\begin{bmatrix}\n0 \\\\ 0\n\\end{bmatrix}\n\\]\nWe can do that by using fsolve() from scipy.optimize.\n\nfrom scipy.optimize import fsolve\n\n# Define the first partial derivatives\ndef df_dx1(x1, x2):\n    return 2 * x1**3 + 6 * x1**2 + 3 * x1 - 2 * x2\n\ndef df_dx2(x1, x2):\n    return 2 * x2 - 2 * x1\n\n# Define the system of equations\ndef equations(vars):\n    x1, x2 = vars\n    return [df_dx1(x1, x2), df_dx2(x1, x2)]\n\n# Solve for critical points\ninitial_guesses = [(0, 0), (-1, -1), (-10, -10)]\ncritical_points = [fsolve(equations, guess) for guess in initial_guesses]\n\nprint(critical_points)\n\n[array([0., 0.]), array([-0.17712434, -0.17712434]), array([-2.82287566, -2.82287566])]\n\n\nNow, we need to classify each critical point. To do so, let’s compute the Hessian:\n\\[\nH(x_1, x_2) =\n\\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n6x_1^2 + 12x_1 + 3 & -2 \\\\\n-2 & 2\n\\end{bmatrix}\n\\]\nWe now need to evaluate the Hessian at each one of the critical points and check whether is it positive semidefinite. There are a number of ways we can check this, but we will be examining the eigenvalues of the Hessian and checking whether they are all positive.\n\n# Define the Hessian\ndef Hessian(x1, x2):\n    return np.array([[6 * x1**2 + 12 * x1 + 3, -2], [-2, 2]])\n\neigs = [np.linalg.eigvals(Hessian(pt[0], pt[1])) for pt in critical_points]\n\nprint(eigs)\n\n[array([4.56155281, 0.43844719]), array([-0.5227962 ,  3.58554227]), array([17.20040482,  1.73684911])]\n\n\nBased on these results, we know that the first and third critical points are local minimizers. The second critical point is classifies as a saddle point because the Hessian is not positive semidefinite. To find out which of the local minimizers is the global minimzer, we evaluate the function at each of these points. Let’s go ahead and label the points accordingly.\n\n# Create the contour plot\nx = np.linspace(-4, 2, 1000)\ny = np.linspace(-4, 2, 1000)\nX, Y = np.meshgrid(x, y)\nZ = f(X, Y)\n\nplt.figure(figsize=(9.5, 5))\ncontour = plt.contour(X, Y, Z, levels=75)\nplt.xlabel(r'$x_1$')\nplt.ylabel(r'$x_2$')\n\n# Plot and label the critical points\nlabels = [\"local minimum\", \"saddle point\", \"global minimum\"]\n\nfor (x, y), label in zip(critical_points, labels):\n    plt.scatter(x, y, label=f'{label} ({x:.2f}, {y:.2f})', s=100)\n    if label == \"saddle point\":\n        plt.text(x, y, f' {label}', fontsize=12, ha='right', weight='bold')\n    else:\n        plt.text(x, y, f' {label}', fontsize=12, ha='left', weight='bold')\n\nplt.grid(False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "21_ugbo2.html",
    "href": "21_ugbo2.html",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "",
    "text": "5 Problem Motivation\nSo far, we have developed analytical tools that allow us to find and classify critical points of functions. However, this analytical approach to finding minima is often infeasible, esecially when the objective function is a result of a numerical model. To combat this, we turn to interative algorithms that prgressively work towards finding a minimum while only relying on function and gradient evaluations. The main idea is that we will start from some initial guess \\(x_0\\) and produce a sequence of points \\(x_1, x_2, x_3, \\ldots, x_j, \\ldots\\), eventually converging to some local minimizer \\(x^\\star\\).\nThere are two major classes of iterative optimization methods that produce the aforementioned sequence of points: line search methods and trust region methods. In this course, we will focus on the former, but we will provide some resources for those interested in the latter. Line search methods consist of three main steps that occur at each iteration:\nThe whole process is summarized in the diagram below.\nflowchart LR\n  A(Starting guess) --&gt; B(Search direction)\n  B --&gt; C(Step size)\n  C --&gt; D(Is this a minimum?)\n  D --&gt;|Yes| E(Converged)\n  D --&gt;|No| F(Update values)\n  F --&gt; B\nSteps 1 and 2 can be understood as two separate subproblems in the overall optimization scheme. In this note, we will examine the first of these subproblems by introducing the steepest descent algorithm, and seeing how the subproblem of determining a suitable step size arises as a natural consequence."
  },
  {
    "objectID": "21_ugbo2.html#motivation",
    "href": "21_ugbo2.html#motivation",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "6.1 Motivation",
    "text": "6.1 Motivation\nGiven some objective function \\(f\\), recall that the gradient \\(\\nabla f\\) is a vector with each component quantifying the function’s local rate of change with respect to each variable.\nFact: The gradient is a vector that points to the direction that yields the greatest function increase from the current point.\nIdea: From any given point \\(x\\), we can find the direction of steepest descent by taking \\(-\\nabla f(x)\\). So, we can define our search direction at iteration \\(k\\) as: \\(p_k = -\\nabla f(x_k)\\)\nOne problem with the above idea is that the gradient does not give us any information regarding the step size we should take. Hence, the search direction is often normalized as:\n\\[\np_k = -\\frac{\\nabla f(x_k)}{\\|\\nabla f(x_k)\\|_2}\n\\]"
  },
  {
    "objectID": "21_ugbo2.html#algorithm",
    "href": "21_ugbo2.html#algorithm",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "6.2 Algorithm",
    "text": "6.2 Algorithm\nNeed to include an algorithm block here."
  },
  {
    "objectID": "21_ugbo2.html#example",
    "href": "21_ugbo2.html#example",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "6.3 Example",
    "text": "6.3 Example\nConsider the quadratic function: \\[\nf(x_1, x_2) = x_1^2 + \\beta x_2^2\n\\]\nFirst, let us consider the case where \\(\\beta = 1\\) and the starting point is \\(x_0 = (10,1)\\).\n\n\n0.0002487577548903103\n\n\nText(0, 0.5, '$x_2$')\n\n\n\n\n\nThis is a test citation (Martins and Ning 2021).\n\n\n\n\nMartins, Joaquim RRA, and Andrew Ning. 2021. Engineering Design Optimization. Cambridge University Press."
  },
  {
    "objectID": "00_linalg.html#linear-algebra-crash-course",
    "href": "00_linalg.html#linear-algebra-crash-course",
    "title": "Appendix A — Linear algebra review",
    "section": "A.1 Linear Algebra Crash Course",
    "text": "A.1 Linear Algebra Crash Course\nBefore we dive into the world of machine learning and optimization, it’s important that we get comfortable with the fundamental building blocks of mathematics in higher dimensions: Linear Algebra. This course assumes you have seen basic concepts in Linear Algebra, but we’ll provide a refresher to get everyone on the same page.\n\nA.1.0.1 Scalars, Vectors, and Matrices\nNotation\nLet’s introduce some notation: \\(\\mathbb{R}\\) is the set of real numbers, \\(\\mathbb{C}\\) is the set of complex numbers, and the operator \\(\\in\\) designates that a variable belongs to a set. To define a real scalar (i.e. just a number), \\(c\\), we write:\n\\[ c \\in \\mathbb{R}\\]\nYou can read this as “the variable \\(c\\) belongs to the set of 1-dimensional real numbers.”\nTo define a real \\(n\\) dimensional vector, \\(\\mathbf{x}\\), we write:\n\\[ \\mathbf{x}  = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nTo define a \\(m \\times n\\) matrix \\(\\mathbf{A}\\) of real-valued entries, we write:\n\\[ \\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n }\n\\]\nThe Transposes\nThe “transpose” of a matrix or vector, swaps the rows and columns. In other words, the first row becomes the first column, the second row the second column and so-on:\n\\[ \\mathbf{x}^\\top = \\begin{bmatrix} x_1 & \\dots & x_n \\end{bmatrix} \\in \\mathbb{R}^{1 \\times n} \\]\n\\[ \\mathbf{A}^\\top = \\begin{bmatrix} a_{11} & a_{21} & \\dots & a_{m1} \\\\\na_{12} & a_{22} & & a_{m2} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{n \\times m } \\]\nTransposing the product of matrices reverses their order:\n\\[ \\left( \\mathbf{A} \\mathbf{B} \\mathbf{C} \\mathbf{D} \\right)^\\top = \\mathbf{D}^\\top \\mathbf{C}^\\top \\mathbf{B}^\\top \\mathbf{A}^\\top \\]\nAddition & subtraction\nTechnically, only objects of the same dimensionality can be added or subtracted with one another. So, scalars can only be added to scalars, vectors can only be added to vectors of the same dimension, and matrices can only be added to other matrices with the same numbers of rows and columns. Some software like MATLAB or NumPy might let you add scalars to vectors and matrices and under the hood they multiply that scalar by a vector/matrix of ones to make the dimensions match.\n\n\nA.1.0.2 Scalar Multiplication\nGenerally, scalars can multiply by any structure (scalar, vector, and matrix) and do not change its dimension. They only “scale” its value by a certain amount. Hence, multiplying a scalar by a scalar returns a scalar, multiplying a scalar times a vector returns a vector, and multiplying a scalar by a matrix returns a matrix. Scalar multiplication is also commutative, i.e. \\(c\\mathbf{A} = \\mathbf{A}c\\) for all scalars \\(c\\). Consider our scalar, \\(c\\), from the previous section, another scalar, \\(b\\), the vector \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and the matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\)\n\nScalar-Scalar Product: \\[b \\times c = bc \\in \\mathbb{R}\\]\nScalar-Vector Product: \\[ c \\mathbf{x} = \\mathbf{x} c = \\begin{bmatrix} c x_1 \\\\ \\vdots \\\\ c x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nScalar-Matrix Product: \\[ c \\mathbf{A} = \\mathbf{A} c = \\begin{bmatrix} c a_{11} & c a_{12} & \\dots & c a_{1n} \\\\\nc a_{21} & c a_{22} & & c a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\nc a_{m1} & c a_{m2} & \\dots & c a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n } \\]\n\n\n\nA.1.0.3 Matrix & Vector Multiplication\nVector-Vector Multiplication\nTo multiply two matrices (or two vectors, or a matrix with a vector), their inner dimensions must always match. Hence, the only valid way to multiply two vectors is by “inner” or “outer” products. Consider two vectors, \\(\\mathbf{u} \\in \\mathbb{R}^n\\) and \\(x \\in \\mathbb{R}^n\\). An “Inner Product” (sometimes called the Dot-Product) is defined as:\n\\[ \\mathbf{u}^\\top \\mathbf{x} = \\begin{bmatrix} u_1 & \\dots & u_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = u_1 x_1 + u_2 x_2 + \\dots u_n x_n \\in \\mathbb{R}\\]\nSome important notes about inner products:\n\nIf the dimensions of \\(\\mathbf{u}\\) and \\(\\mathbf{x}\\) do not match, we cannot multiply them this way as we need to multiply each entry of both vectors.\nThis operation returns a scalar value.\nInner Products are commutative, i.e. \\(\\mathbf{u}^\\top \\mathbf{x} = \\mathbf{x}^\\top \\mathbf{u}\\), as they are sums of scalar-scalar multiplications which are also commutative.\n\nRecall \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Now consider a new vector \\(\\mathbf{w} \\in \\mathbb{R}^m\\) where \\(m \\neq n\\). An “Outer Product” is defined as:\n\\[ \\mathbf{w} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_m \\end{bmatrix} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\mathbf{x}^\\top  \\\\ \\vdots \\\\ w_m \\mathbf{x}^\\top  \\end{bmatrix} = \\begin{bmatrix} w_1 x_1 & w_1 x_2 & \\dots & w_1 x_n \\\\ w_2 x_1 & w_2 x_2 & & w_2 x_n \\\\ \\vdots & & \\ddots & \\vdots \\\\ w_m x_1 & w_m x_2 & \\dots & w_m x_n \\end{bmatrix} \\in \\mathbb{R}^{m \\times n} \\]\nImportant notes on outer products:\n\nOuter products return matrices with dimensions according to the vectors multiplied.\nAs long as \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) are vectors, outer products share an inner dimension of \\(1\\), which means that any two vectors have an outer product.\nLastly, this operation is non-commutative, meaning \\(\\mathbf{w} \\mathbf{x}^\\top \\neq \\mathbf{x} \\mathbf{w}^\\top\\). Rather, these two are transposes of each other.\n\nMatrix-Vector Multiplication\nMultiplying a matrix with a vector means the dimension of the vector must equal the number of columns of the matrix. Recall \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Note that the columns of \\(\\mathbf{A}\\) match the dimension of \\(\\mathbf{x}\\), which are both size \\(n\\). The product \\(\\mathbf{A}\\mathbf{x}\\) can be written as:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n} x_n \\\\  a_{21} x_1 + a_{22} x_2 + \\dots + a_{2n} x_n \\\\ \\vdots \\\\a_{m1} x_1 + a_{m2} x_2 + \\dots + a_{mn} x_n  \\end{bmatrix} \\in \\mathbb{R}^m \\]\nPerhaps a more useful way to visualize this is to break \\(\\mathbf{A}\\) down into its constituent columns and show this as a sum of scalar-vector multiplications:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} x_1 + \\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} x_2 + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} x_n  \\in \\mathbb{R}^m \\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\). Note that matrix-vector multiplication forms a linear map from one dimensional vector-space to another. In this case, \\(\\mathbf{A}\\mathbf{x}\\) maps a vector from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^m\\). This linear transformation from one dimensionality to another is a core component of many machine learning algorithms.\nMatrix-Matrix Multiplication\nConsider two matrices, \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{B} \\in \\mathbb{R}^{n \\times k}\\), where \\(m \\neq k\\). Again, the inner dimensions must match to multiply matrices. Because \\(\\mathbf{A}\\) multiplied by \\(\\mathbf{B}\\) have an inner-dimension of \\(n\\), they can be multiplied. Similar to matrix-vector multiplication, we can visualize the product of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) by breaking up the columns and rows of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), respectively:\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\\\ - & \\mathbf{b}_2 & - \\\\ & \\vdots & \\\\  - & \\mathbf{b}_n & - \\end{bmatrix} \\in \\mathbb{R}^{m \\times k}\\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\) and \\(\\mathbf{b}_i\\) is the \\(i\\)th row of \\(\\mathbf{B}\\). We can expand this expression by multiplying each column of \\(\\mathbf{A}\\) with each row of \\(\\mathbf{B}\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\end{bmatrix} +\\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_2 & - \\end{bmatrix} + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_n & - \\end{bmatrix}\\]\nAs we can see, this is a sum of outer products (vectors multiplied by transposed vectors). We know \\(\\mathbf{A}\\) has \\(m\\) rows and \\(\\mathbf{B}\\) has \\(k\\) columns, so each outer product will form a matrix of dimension \\(m \\times k\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\sum_{i=1}^n \\mathbf{a}_i \\mathbf{b}_i \\in \\mathbb{R}^{m \\times k}\\]\nNote: matrix multiplication is generally non-commutative; The product \\(\\mathbf{A}\\mathbf{B}\\) is valid, because the number of columns of \\(\\mathbf{A}\\) matches the number of rows of \\(\\mathbf{B}\\). However, the product \\(\\mathbf{B}\\mathbf{A}\\) is not valid, because the number of columns of \\(\\mathbf{B}\\) does not equal the number of rows of \\(\\mathbf{A}\\).\n\n\nA.1.0.4 Vector Norms\nOftentimes, it is useful to know how “big” a vector is. And there are many different ways of computing this. The “norm” of an object is a measure of how “large” it is, according to some rule. Consider \\(\\mathbf{x} \\in \\mathbb{R}^n\\). The \\(l_p\\) norm is defined by the following:\n\\[ ||\\mathbf{x}||_p = \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} \\]\nThis formula may not be so intuitive, so let’s consider three special instances of the \\(l_p\\) norms:\nThe 1-Norm\nThe 1-norm of \\(\\mathbf{x}\\) is simply the sum of the absolute-value of its entries:\n\\[ ||\\mathbf{x}||_1 = |x_1| + |x_2| + \\dots + |x_n| \\]\nThe 2-Norm\nThe 2-norm of \\(x\\) (which we will use most-often in this class) is defined as the squareroot of the squares of its entries:\n\\[ ||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} \\]\nThe reason the 2-norm is so useful is the fact that the square of the \\(l_2\\) norm is an inner product of a vector with itself:\n\\[ \\mathbf{x}^\\top \\mathbf{x} = x_1^2 + x_2^2 + \\dots + x_3^2 = ||\\mathbf{x}||_2^2 \\]\nThis helps us write a norm in terms of matrix-vector operations, which is extremely useful for optimization. The 2-norm is also quite important because it is the first \\(l_p\\) norm with a continuous derivative, which cannot be said of the 1-norm since it uses absolute-value functions.\nThe Infinity-Norm\nThe infinity-norm takes the limit as \\(p \\rightarrow \\infty\\) and when this limit is solved, this norm simply becomes the entry of \\(x\\) with the largest absolute value:\n\\[ ||\\mathbf{x}||_\\infty = \\max \\{ |x_1|, |x_2|, \\dots, |x_n| \\} \\]\n\n\nA.1.1 Rank, Range/Column-Space and Null-Spaces\nLinear-Independence\nThis is a fundamental idea in Linear Algebra. A set of vectors is said to be “Linearly Independent” if no vector in this set can be reconstructed with any of the others. In other words, no one vector can be reproduced by scaling or combining any of the others. For example, consider the following three vectors:\n\\[ \\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\} \\]\nBecause each vector in this set points in its own unique direction, it is impossible to reconstruct one of these vectors as a linear combination of any others. This may be true with more complex vectors that aren’t unit vectors along the dimensions of the vector-space.\nRank\nThe rank of a matrix is simply the number of linearly independent columns. Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 & 1 & 4 \\\\ 0 & 1 & 1 & 2 \\\\ 0 & 0 & 2 & 0 \\end{bmatrix} \\]\nThe first-three columns of \\(\\mathbf{A}\\) are linearly independent because they cannot be reproduced using linear combinations of the other columns. However, the last column is a multiple of column 2, which means it can be reproduced using a linear combination of columns. Hence, this matrix has a rank of 3.\nTheorem: No matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) where \\(m &lt; n\\) can be full-rank. This is because only \\(m\\) vectors can span \\(\\mathbb{R}^m\\), and since there are more than \\(m\\) columns, we must have some redundancy.\nRange/Column-Space\nThe Range, Column-Space or Image of a matrix, \\(\\mathbf{A}\\), is the span of all possible combinations of its columns. In human words, it describes the space of \\(\\mathbf{Ax}\\) for all possible \\(\\mathbf{x}\\). Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\\\ 2 & 4  \\end{bmatrix} \\]\nNote that the second column is a multiple of the first column, hence, the range of \\(\\mathbf{A}\\) is:\n\\[ \\text{Range}(\\mathbf{A}) = \\text{span} \\left( \\begin{bmatrix} 1 \\\\ 3 \\\\ 2 \\end{bmatrix}\\right) \\]\nNull-Space\nThe Null-Space of a matrix, \\(\\mathbf{A}\\) is the set of all nonzero vectors, \\(\\mathbf{x}\\) such that \\(\\mathbf{Ax=0}\\). Consider a simple example:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\]\nWe can find the set of \\(\\mathbf{x}\\) that produce the zero-vector by solving the following equation:\n\\[ \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\]\nThis produces the systems of equations:\n\\[ x_1 - x_3 = 0 \\] \\[ x_2 + x_3 = 0 \\] \\[ x_3 = x_3 \\]\nIf we isolate each entry of \\(\\mathbf{x}\\):\n\\[ x_1 = x_3 \\] \\[ x_2 = -x_3 \\] \\[ x_3 = x_3 \\]\nHence, we see that \\(x_3\\) can be any scalar and satisfy this systems of equations:\n\\[ \\mathbf{x} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} x_3 = \\text{span}\\left( \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} \\right) = \\text{Null}(\\mathbf{A})\\]\n\nA.1.1.1 The Identity Matrix\nThe identity matrix is a square, \\(n\\)-dimensional matrix consisting of ones on its diagonal and zeros elsewhere. It is called the identity matrix because it preserves the identity when multiplied by matrices and vectors.\n\\[ \\mathbf{I} = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\ 0 & 1  & & 0 \\\\ \\vdots & & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & 1 \\end{bmatrix} \\]\nConsider \\(\\mathbf{I} \\in \\mathbb{R}^{n \\times n}\\) to be an \\(n \\times n\\) identity matrix. If we recall \\(\\mathbf{A} \\in \\mathbb{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\):\n\\[ \\mathbf{A I = I A = A} \\]\n\\[ \\mathbf{I x = x } \\]\n\\[ \\mathbf{x^\\top I = x^\\top} \\]\nWhy is this useful?\nThe identity matrix simplifies expressions involving matrices. If we can transform a term into an identity matrix, then we can reduce the expression to only the remaining terms.\n\n\n\nA.1.2 Matrix Inverses\nYou may have noticed that, thus far, we have covered the addition, subtraction, and multiplication of matrices, which conspicuously leaves division. Well, unfortunately, matrix division is complex to say the least. For square matrices, division is accomplished via matrix inversion. However, not all matrices are invertible.\nDefinition: A matrix \\(\\mathbf{B}\\) is called the “inverse” of a square matrix \\(\\mathbf{A}\\) if and only if the following condition holds:\n\\[ \\mathbf{A} \\mathbf{B} = \\mathbf{B} \\mathbf{A} = \\mathbf{I} \\]\nwhere \\(\\mathbf{I}\\) is the identity matrix. Such a \\(\\mathbf{B}\\) is denoted \\(\\mathbf{A}^{-1}\\)."
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 What’s in a name? Artificial intelligence, machine learning, and data science\nI googled “artificial intelligence” and the first result comes from Google’s new “AI overview” feature1:\nBecause I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer:\nThese are probably both reasonable definitions for casual conversation, but that’s not what we’re here for. Instead, we’re here to really learn deeply about what AI is, and for that we’re going to need precision – that is, of our definitions.\nI’m not going to provide a definition of AI for now and instead I’m going to throw two more terms into the mix that you may have heard. The first is “machine learning”. Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition (Merriam-Webster Dictionary 2024):\nAnd finally I’ll add the term “data science.” I wanted to give you a Merriam-Webster definition here, but the term isn’t in their dictionary as of writing this on October 28, 2024. So instead I’m going to use Cambridge Dictionary’s definition (Cambridge Dictionary 2024):\nThat’s probably a reasonable definition for casual conversation, although\nsome remarks about what these things mean to different people, some links to further reading, narrow focus to supervised learning",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#a-motivating-example",
    "href": "01_intro.html#a-motivating-example",
    "title": "1  Introduction",
    "section": "",
    "text": "The angle of attack (\\(\\alpha\\)), measured in degrees\nThe density of the fluid (\\(\\rho\\)), measured in \\(kg/m^3\\)\nThe velocity of the fluid (\\(v\\)), measured in \\(m/s\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#linear-approximation-of-an-unknown-function",
    "href": "01_intro.html#linear-approximation-of-an-unknown-function",
    "title": "1  Introduction",
    "section": "1.2 Linear Approximation of an Unknown Function",
    "text": "1.2 Linear Approximation of an Unknown Function\nLet’s bundle our inputs into a single vector, defined by:\n\\[ \\mathbf{x} = \\begin{bmatrix} \\alpha \\\\ \\rho \\\\ v\\end{bmatrix} \\]\nWe assume there is some unknown function, \\(f(\\cdot):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\), that gives us an optimal estimate for drag-force based on these “features”:\n\\[ F_d = f (\\mathbf{x}) + \\varepsilon \\]\nwhere \\(\\varepsilon\\) is some external noise, disturbances or information entirely independent of the input variables.\nNow consider a function \\(h(\\mathbf{x}; \\beta):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\) which is a simple linear combination of the inputs:\n\\[ h(\\mathbf{x}; \\beta) = \\begin{bmatrix} 1 & \\mathbf{x}^\\top \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3  \\end{bmatrix} = \\beta_0 + \\beta_1 \\alpha + \\beta_2 \\rho + \\beta_3 v \\]\nThe Million Dollar Question:\nGiven we know the structure of \\(h(\\mathbf{x}; \\beta)\\), how can we efficiently optimize the parameters of \\(h(\\mathbf{x}; \\beta)\\) to best approximate \\(f(\\mathbf{x})\\)?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#representing-observed-input-output-data",
    "href": "01_intro.html#representing-observed-input-output-data",
    "title": "1  Introduction",
    "section": "1.2 Representing Observed Input-Output Data",
    "text": "1.2 Representing Observed Input-Output Data\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#the-least-squares-optimization-problem",
    "href": "01_intro.html#the-least-squares-optimization-problem",
    "title": "1  Introduction",
    "section": "1.3 The Least-Squares Optimization Problem",
    "text": "1.3 The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#solving-the-least-squares-problem",
    "href": "01_intro.html#solving-the-least-squares-problem",
    "title": "1  Introduction",
    "section": "1.4 Solving the Least-Squares Problem",
    "text": "1.4 Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#experimental-example",
    "href": "01_intro.html#experimental-example",
    "title": "1  Introduction",
    "section": "1.5 Experimental Example",
    "text": "1.5 Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#using-nonlinear-features-to-improve-model-performance",
    "href": "01_intro.html#using-nonlinear-features-to-improve-model-performance",
    "title": "1  Introduction",
    "section": "1.6 Using Nonlinear Features to Improve Model Performance",
    "text": "1.6 Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "11_ls.html",
    "href": "11_ls.html",
    "title": "ML for AE: Least Squares Regression",
    "section": "",
    "text": "A Motivating Example\nSuppose we wish to efficiently approximate the force of drag (\\(F_d\\)), measured in \\(N\\), on a specific airplane wing if we only have access to the following information about the wing and its operating conditions:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "11_ls.html#a-motivating-example",
    "href": "11_ls.html#a-motivating-example",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "A Motivating Example",
    "text": "A Motivating Example\n\n\n\nImage Source: Embry-Riddle Aeronautical University\n\n\nSuppose we wish to efficiently approximate the force of drag (\\(F_d\\)), measured in \\(N\\), on a specific airplane wing if we only have access to the following information about the wing and its operating conditions:\n\nThe angle of attack (\\(\\alpha\\)), measured in degrees\nThe density of the fluid (\\(\\rho\\)), measured in \\(kg/m^3\\)\nThe velocity of the fluid (\\(v\\)), measured in \\(m/s\\)"
  },
  {
    "objectID": "11_ls.html#linear-approximation-of-an-unknown-function",
    "href": "11_ls.html#linear-approximation-of-an-unknown-function",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "Linear Approximation of an Unknown Function",
    "text": "Linear Approximation of an Unknown Function\nLet’s bundle our inputs into a single vector, defined by:\n\\[ \\mathbf{x} = \\begin{bmatrix} \\alpha \\\\ \\rho \\\\ v\\end{bmatrix} \\]\nWe assume there is some unknown function, \\(f(\\cdot):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\), that gives us an optimal estimate for drag-force based on these “features”:\n\\[ F_d = f (\\mathbf{x}) + \\varepsilon \\]\nwhere \\(\\varepsilon\\) is some external noise, disturbances or information entirely independent of the input variables.\nNow consider a function \\(h(\\mathbf{x}; \\beta):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\) which is a simple linear combination of the inputs:\n\\[ h(\\mathbf{x}; \\beta) = \\begin{bmatrix} 1 & \\mathbf{x}^\\top \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3  \\end{bmatrix} = \\beta_0 + \\beta_1 \\alpha + \\beta_2 \\rho + \\beta_3 v \\]\nThe Million Dollar Question:\nGiven we know the structure of \\(h(\\mathbf{x}; \\beta)\\), how can we efficiently optimize the parameters of \\(h(\\mathbf{x}; \\beta)\\) to best approximate \\(f(\\mathbf{x})\\)?"
  },
  {
    "objectID": "11_ls.html#representing-observed-input-output-data",
    "href": "11_ls.html#representing-observed-input-output-data",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "Representing Observed Input-Output Data",
    "text": "Representing Observed Input-Output Data\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]"
  },
  {
    "objectID": "11_ls.html#the-least-squares-optimization-problem",
    "href": "11_ls.html#the-least-squares-optimization-problem",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "The Least-Squares Optimization Problem",
    "text": "The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]"
  },
  {
    "objectID": "11_ls.html#solving-the-least-squares-problem",
    "href": "11_ls.html#solving-the-least-squares-problem",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "Solving the Least-Squares Problem",
    "text": "Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum."
  },
  {
    "objectID": "11_ls.html#experimental-example",
    "href": "11_ls.html#experimental-example",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "Experimental Example",
    "text": "Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47"
  },
  {
    "objectID": "11_ls.html#using-nonlinear-features-to-improve-model-performance",
    "href": "11_ls.html#using-nonlinear-features-to-improve-model-performance",
    "title": "2  ML for AE: Least Squares Regression",
    "section": "Using Nonlinear Features to Improve Model Performance",
    "text": "Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions."
  },
  {
    "objectID": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-and-data-science",
    "href": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-and-data-science",
    "title": "1  Introduction",
    "section": "1.1 What’s in a name? Artificial intelligence, machine learning, and data science",
    "text": "1.1 What’s in a name? Artificial intelligence, machine learning, and data science\nI googled “artificial intelligence” (often abbreviated AI) and the first result comes from Google’s new “AI overview” feature1: \nBecause I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer: \nThese are probably both reasonable definitions for casual conversation, but that’s not what we’re here for. Instead, we’re here to really learn deeply about what AI is, and for that we’re going to need precision – that is, of our definitions.\n\n\n\n\n\n\nExercise\n\n\n\nConsider the two different definitions of “AI” above carefully. In what (if any) senses are they (a) exactly the same, (b) similar, (c) somewhat different, (d) very different? What consequences might these differences have (a) developing AI algorithms, (b) evaluating AI impacts, (c) creating AI policies?\n\n\nI’m not going to provide a definition of AI for now and instead I’m going to throw two more terms into the mix that you may have heard. The first is “machine learning” (often abbreviated ML). Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition (Merriam-Webster Dictionary 2024):\n\na computational method that is a subfield of artificial intelligence and that enables a computer to learn to perform tasks by analyzing a large dataset without being explicitly programmed\n\nAnd finally I’ll add the term “data science” (curiously, rarely abbreviated DS). I wanted to give you a Merriam-Webster definition here, but the term isn’t in their dictionary as of writing this on October 28, 2024. So instead I’m going to use Cambridge Dictionary’s definition (Cambridge Dictionary 2024):\n\nthe use of scientific methods to obtain useful information from computer data, especially large amounts of data\n\n\n\n\n\n\n\nExercise\n\n\n\nFor both the terms “machine learning” and “data science”, find an alternative definition from a source that is not a generative AI. What differences exist between the new definitions you’ve found and the ones I’ve cited above?\n\n\nClearly, different people/entities may have different ideas of what AI, ML, and data science may mean. Some people may use these terms to describe generative tools like ChatGPT, GitHub copilot, and Dall-E (or similar products developed by other entities). Others use these terms to refer to more purpose-built algorithms like AlphaGo (for playing Go) or GraphCast (for weather prediction).2 Many academics use these terms to describe the study of the underlying mathematical and programming ideas on which such products are built.\nMy goal is not to give you a single definition of any of these terms and then to argue that my definition is more correct than any other definition. The point I want to make is that it’s worth being clear about how we define these terms in any given context, whether it be in a textbook, a news article, or perhaps a spirited discussion between friends. To that end, I now want to make clear what it is that we will and will not cover in this class, which is a “foundations”-level course in the College of Engineering’s AI minor.\nThe focus of this class will be the mathematical and programming foundations of scientific machine learning, which I define as the study of algorithms which use scientific data to define computational tools that perform useful scientific tasks. In particular, the focus of this class is going to be on regression problems and their solutions, which describes the age-old problem of predicting numerical outputs from numerical inputs. Regression problems\nInstead, I want you to notice some key commonalities in the definitions above (of all three terms): the first is the data seems to be important for all\nsome remarks about what these things mean to different people, some links to further reading, narrow focus to supervised learning\n\n1.1.1 Regression\nproblem of predicting outputs from inputs\nformulation as selection from within a parametrized model class\nchoosing parameters via optimization\n\n\n1.1.2 Things that are not regression\nGive one example, list other examples, I cannot possibly hope to cover all these things in this course, so another goal of the course is to teach the language of ML so you are prepared to learn other things in future courses and on your own."
  },
  {
    "objectID": "01_intro.html#the-three-pillars-of-ai-mathematics-computation-and-human-intelligence",
    "href": "01_intro.html#the-three-pillars-of-ai-mathematics-computation-and-human-intelligence",
    "title": "1  Introduction",
    "section": "1.3 The three pillars of AI: mathematics, computation, and human intelligence",
    "text": "1.3 The three pillars of AI: mathematics, computation, and human intelligence\nmathematics is the language that describes what we want to do\ncomputation/programming is the execution (translation)\nhuman intelligence is woven throughout, specifies problem, evaluates results, re-specifies problem.\n\n1.3.1 Course structure and intended learning outcomes\nfill in nearer to term\n\n\n\n\n\n\n\n\n\n\nCambridge Dictionary. 2024. “Data Science.” 2024. https://dictionary.cambridge.org/dictionary/english/data-science.\n\n\nMerriam-Webster Dictionary. 2024. “Machine Learning.” 2024. https://www.merriam-webster.com/dictionary/machine%20learning."
  },
  {
    "objectID": "01_intro.html#footnotes",
    "href": "01_intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "It seems apt to use AI to define AI, and I’m quoting it for illustrative purposes here, but I do want to point out that Google’s AI Overview is not at all transparent about how these responses are generated and thus does not meet the standards for being cited as a source in most publishing venues.↩︎\nthis paragraph lists examples that came to me most quickly and thus reflects to some extent my own cognitive biases based on the media I’ve consumed. I welcome suggestions of other examples of AI/ML/data science to include that are less well-known – Email me!↩︎"
  },
  {
    "objectID": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-data-science-and-the-scope-of-this-course.",
    "href": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-data-science-and-the-scope-of-this-course.",
    "title": "1  Introduction",
    "section": "1.1 What’s in a name? Artificial intelligence, machine learning, data science, and the scope of this course.",
    "text": "1.1 What’s in a name? Artificial intelligence, machine learning, data science, and the scope of this course.\nI googled “artificial intelligence” (often abbreviated AI) and the first result comes from Google’s new “AI overview” feature1: \nBecause I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer: \nThese are probably both reasonable definitions for casual conversation, but that’s not what we’re here for. Instead, we’re here to really learn deeply about what AI is, and for that we’re going to need precision – that is, of our definitions.\n\n\n\n\n\n\nExercise\n\n\n\nConsider the two different definitions of “AI” above carefully. In what (if any) senses are they (a) exactly the same, (b) similar, (c) somewhat different, (d) very different? What consequences might these differences have (a) developing AI algorithms, (b) evaluating AI impacts, (c) creating AI policies?\n\n\nI’m not going to provide a definition of AI for now and instead I’m going to throw two more terms into the mix that you may have heard. The first is “machine learning” (often abbreviated ML). Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition (Merriam-Webster Dictionary 2024):\n\na computational method that is a subfield of artificial intelligence and that enables a computer to learn to perform tasks by analyzing a large dataset without being explicitly programmed\n\nAnd finally I’ll add the term “data science” (curiously, rarely abbreviated DS). I wanted to give you a Merriam-Webster definition here, but the term isn’t in their dictionary as of writing this on October 28, 2024. So instead I’m going to use Cambridge Dictionary’s definition (Cambridge Dictionary 2024):\n\nthe use of scientific methods to obtain useful information from computer data, especially large amounts of data\n\n\n\n\n\n\n\nExercise\n\n\n\nFor both the terms “machine learning” and “data science”, find an alternative definition from a source that is not a generative AI. What differences exist between the new definitions you’ve found and the ones I’ve cited above?\n\n\nClearly, different people/entities may have different ideas of what AI, ML, and data science may mean. Some people may use these terms to describe generative tools like ChatGPT, GitHub copilot, and Dall-E (or similar products developed by other entities). Others use these terms to refer to more purpose-built algorithms like AlphaGo (for playing Go) or GraphCast (for weather prediction).2 Many academics use these terms to describe the study of the underlying mathematical and programming ideas on which such products are built.\nMy goal is not to give you a single definition of any of these terms and then to argue that my definition is more correct than any other definition. The point I want to make is that it’s worth being clear about how we define these terms in any given context, whether it be in a textbook, a news article, or perhaps a spirited discussion between friends. To that end, I now want to make clear what it is that we will and will not cover in this class, which is a “foundations”-level course in the College of Engineering’s AI minor.\nThe focus of this class will be the mathematical and programming foundations of scientific machine learning, which I define as the study of algorithms which use scientific data to define computational tools that perform useful scientific tasks. The main scientific task that we will focus on in this course is the task of predictive simulation, which seeks to predict the behavior or outcomes of scientific or engineering systems. Predictive simulation is a key task in engineering disciplines like design and control, where we seek to predict design outcomes and control responses in order to make decisions about design parameters and control inputs. The class of machine learning methods that we will focus on in this class will therefore be regression methods, which use data to define relationships between inputs and outputs that allow us to take a specified input and issue a prediction for the output."
  },
  {
    "objectID": "01_intro.html#regression-methods-an-overview",
    "href": "01_intro.html#regression-methods-an-overview",
    "title": "1  Introduction",
    "section": "1.2 Regression methods: an overview",
    "text": "1.2 Regression methods: an overview\n\n1.2.1 Predicting inputs from outputs\nWe use the notation \\(z\\in \\mathbb{R}^d\\) to denote a real-valued vector of \\(d\\) input variables, and the notation \\(y \\in\\mathbb{R}\\) to denote a real-valued scalar output variable. Our goal is to be able to predict the value of \\(y\\) if we know the value(s) of the input variable \\(z\\). Some examples:\n\nin aerodynamic modeling, \\(z\\) could contain airfoil geometry parameters like camber and thickness, and \\(y\\) could represent the lift coefficient. Being able to predict \\(y\\) from \\(z\\) enables engineers to choose more aerodynamically efficient designs.\nin orbital dynamics, \\(z\\) could represent orbital parameters like altitude and inclination, and \\(y\\) could represent the total time a satellite spends outside the sun’s shadow in a given time period. Being able to predict \\(y\\) from \\(z\\) enables engineers to determine if a satellite’s solar panels will generate enough power to support the satellite’s mission.\nin chemical process engineering, \\(z\\) could represent conditions within a reactor like temperature and chemical mixture properties and \\(y\\) could represent the reaction rate. Being able to predict \\(y\\) from \\(z\\) enables engineers to design more efficient reactors.\n\n\n\n\n\n\n\nExercise\n\n\n\nPropose your own example scenario where it would be useful to predict real-valued outputs from inputs, drawing on your own experience, e.g. in personal projects, previous coursework, work/internship/co-op experiences, or extracurriculars. What would \\(z\\) and \\(y\\) represent? What does predicting \\(y\\) from \\(z\\) enable in your scenario?\n\n\nMathematically, predicting \\(y\\) from \\(z\\) amounts to defining a function \\(f\\) that takes in a \\(d\\)-dimensional input and outputs a scalar. Mathematical notational shorthand for this is \\(f:\\mathbb{R}^d\\to\\mathbb{R}\\). The question at hand is: how do we choose \\(f\\)? There are many ways to do so:\n\nAt a baseline, you could just make up a model: let’s just say \\(y = f(z) = \\|z\\|^2\\). This is mathematically valid, but it’s probably a bad model for the three example scenarios above, because this model probably issues predictions that are very different from the true outputs.\nAlternatively, you could develop a model based on physical principles (a “physics-based” model) – if you have taken classes in (aero/thermo)dynamics, then you would have learned some ways to calculate \\(y\\) from \\(z\\) in the above examples, e.g. based on potential flow theory, rigid body dynamics, or the Arrhenius equation. These models are likely to be more accurate than our made-up model above, although they are often imperfectly accurate because they make simplifying assumptions. One drawback of physics-based models is that they may be computationally expensive (some computational fluid dynamics simulations require many thousands of hours of supercomputing time). Additionally, fully physics-based models may not even exist in some applications (e.g., there are many aspects of plasma physics for which we currently lack a complete theoretical understanding).\nFinally, our focus will be on using data to define a model (a “data-driven” model or a “learned” model). We assume that we have a data set consisting of \\(N\\) pairs of input and output data, \\((z_i,y_i)\\) for \\(i = 1,\\ldots,N\\). To define our model, we want to choose an \\(f\\) so that the predicted output \\(f(z_i)\\) is close to the output data \\(y_i\\) for all the data in our data set. This is sometimes called “fitting” the model to data. The advantages of data-driven models are that they may be significantly cheaper than physics-based models, and they can be fit to experimental data even when we lack scientific theory for developing physics-based models. The disadvantages are that data-driven models require data – and the amount of data that would be “enough” to ensure that the learned model is accurate or useful is highly dependent on the application.\n\nLearning how to fit models to data and assess their accuracy and usefulness is the focus of this course.\n\n\n1.2.2 Mathematical setting and problem formulation\nformulation as selection from within a parametrized model class\nchoosing parameters via optimization\nsome implication of the breadth of methods\n\n\n1.2.3 Things that are not regression\nI want to emphasize that this class is not and indeed cannot (realistically) be an exhaustive introduction to machine learning, artificial intelligence, or data science. Even the community of professionals who describe themselves as working in “scientific machine learning” is quite broad in scope and would include folks working on topics that I do not intend to cover in this class. There are many topics within AI/ML/data science we will not cover (beyond perhaps at most a very surface level), including generative modeling, decision trees, unsupervised learning methods like clustering, and many more.\nGive one example, list other examples, I cannot possibly hope to cover all these things in this course, so another goal of the course is to teach the language of ML so you are prepared to learn other things in future courses and on your own."
  }
]