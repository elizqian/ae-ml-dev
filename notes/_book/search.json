[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AE 4803 AIM: Course Notes",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Cambridge Dictionary. 2024. “Data Science.”\n2024. https://dictionary.cambridge.org/dictionary/english/data-science.\n\n\nMartins, Joaquim RRA, and Andrew Ning. 2021. Engineering Design\nOptimization. Cambridge University Press.\n\n\nMerriam-Webster Dictionary. 2024. “Machine\nLearning.” 2024. https://www.merriam-webster.com/dictionary/machine%20learning."
  },
  {
    "objectID": "01_ls.html",
    "href": "01_ls.html",
    "title": "ML for AE: Least Squares Regression",
    "section": "",
    "text": "A Motivating Example\nSuppose we wish to efficiently approximate the force of drag (\\(F_d\\)), measured in \\(N\\), on a specific airplane wing if we only have access to the following information about the wing and its operating conditions:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#a-motivating-example",
    "href": "01_ls.html#a-motivating-example",
    "title": "ML for AE: Least Squares Regression",
    "section": "",
    "text": "Image Source: Embry-Riddle Aeronautical University\n\n\n\n\nThe angle of attack (\\(\\alpha\\)), measured in degrees\nThe density of the fluid (\\(\\rho\\)), measured in \\(kg/m^3\\)\nThe velocity of the fluid (\\(v\\)), measured in \\(m/s\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#linear-approximation-of-an-unknown-function",
    "href": "01_ls.html#linear-approximation-of-an-unknown-function",
    "title": "ML for AE: Least Squares Regression",
    "section": "Linear Approximation of an Unknown Function",
    "text": "Linear Approximation of an Unknown Function\nLet’s bundle our inputs into a single vector, defined by:\n\\[ \\mathbf{x} = \\begin{bmatrix} \\alpha \\\\ \\rho \\\\ v\\end{bmatrix} \\]\nWe assume there is some unknown function, \\(f(\\cdot):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\), that gives us an optimal estimate for drag-force based on these “features”:\n\\[ F_d = f (\\mathbf{x}) + \\varepsilon \\]\nwhere \\(\\varepsilon\\) is some external noise, disturbances or information entirely independent of the input variables.\nNow consider a function \\(h(\\mathbf{x}; \\beta):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\) which is a simple linear combination of the inputs:\n\\[ h(\\mathbf{x}; \\beta) = \\begin{bmatrix} 1 & \\mathbf{x}^\\top \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3  \\end{bmatrix} = \\beta_0 + \\beta_1 \\alpha + \\beta_2 \\rho + \\beta_3 v \\]\nThe Million Dollar Question:\nGiven we know the structure of \\(h(\\mathbf{x}; \\beta)\\), how can we efficiently optimize the parameters of \\(h(\\mathbf{x}; \\beta)\\) to best approximate \\(f(\\mathbf{x})\\)?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#representing-observed-input-output-data",
    "href": "01_ls.html#representing-observed-input-output-data",
    "title": "ML for AE: Least Squares Regression",
    "section": "Representing Observed Input-Output Data",
    "text": "Representing Observed Input-Output Data\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#the-least-squares-optimization-problem",
    "href": "01_ls.html#the-least-squares-optimization-problem",
    "title": "ML for AE: Least Squares Regression",
    "section": "The Least-Squares Optimization Problem",
    "text": "The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#solving-the-least-squares-problem",
    "href": "01_ls.html#solving-the-least-squares-problem",
    "title": "ML for AE: Least Squares Regression",
    "section": "Solving the Least-Squares Problem",
    "text": "Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#experimental-example",
    "href": "01_ls.html#experimental-example",
    "title": "ML for AE: Least Squares Regression",
    "section": "Experimental Example",
    "text": "Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "01_ls.html#using-nonlinear-features-to-improve-model-performance",
    "href": "01_ls.html#using-nonlinear-features-to-improve-model-performance",
    "title": "ML for AE: Least Squares Regression",
    "section": "Using Nonlinear Features to Improve Model Performance",
    "text": "Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "00_linalg.html",
    "href": "00_linalg.html",
    "title": "Appendix A — Linear algebra review",
    "section": "",
    "text": "A.1 Linear Algebra Crash Course\nBefore we dive into the world of machine learning and optimization, it’s important that we get comfortable with the fundamental building blocks of mathematics in higher dimensions: Linear Algebra. This course assumes you have seen basic concepts in Linear Algebra, but we’ll provide a refresher to get everyone on the same page.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#scalars-vectors-and-matrices",
    "href": "00_linalg.html#scalars-vectors-and-matrices",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.1 Scalars, Vectors, and Matrices",
    "text": "2.1 Scalars, Vectors, and Matrices\nNotation\nLet’s introduce some notation: \\(\\mathbb{R}\\) is the set of real numbers, \\(\\mathbb{C}\\) is the set of complex numbers, and the operator \\(\\in\\) designates that a variable belongs to a set. To define a real scalar (i.e. just a number), \\(c\\), we write:\n\\[ c \\in \\mathbb{R}\\]\nYou can read this as “the variable \\(c\\) belongs to the set of 1-dimensional real numbers.”\nTo define a real \\(n\\) dimensional vector, \\(\\mathbf{x}\\), we write:\n\\[ \\mathbf{x}  = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nTo define a \\(m \\times n\\) matrix \\(\\mathbf{A}\\) of real-valued entries, we write:\n\\[ \\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n }\n\\]\nThe Transposes\nThe “transpose” of a matrix or vector, swaps the rows and columns. In other words, the first row becomes the first column, the second row the second column and so-on:\n\\[ \\mathbf{x}^\\top = \\begin{bmatrix} x_1 & \\dots & x_n \\end{bmatrix} \\in \\mathbb{R}^{1 \\times n} \\]\n\\[ \\mathbf{A}^\\top = \\begin{bmatrix} a_{11} & a_{21} & \\dots & a_{m1} \\\\\na_{12} & a_{22} & & a_{m2} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{n \\times m } \\]\nTransposing the product of matrices reverses their order:\n\\[ \\left( \\mathbf{A} \\mathbf{B} \\mathbf{C} \\mathbf{D} \\right)^\\top = \\mathbf{D}^\\top \\mathbf{C}^\\top \\mathbf{B}^\\top \\mathbf{A}^\\top \\]\nAddition & subtraction\nTechnically, only objects of the same dimensionality can be added or subtracted with one another. So, scalars can only be added to scalars, vectors can only be added to vectors of the same dimension, and matrices can only be added to other matrices with the same numbers of rows and columns. Some software like MATLAB or NumPy might let you add scalars to vectors and matrices and under the hood they multiply that scalar by a vector/matrix of ones to make the dimensions match.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#scalar-multiplication",
    "href": "00_linalg.html#scalar-multiplication",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.2 Scalar Multiplication",
    "text": "2.2 Scalar Multiplication\nGenerally, scalars can multiply by any structure (scalar, vector, and matrix) and do not change its dimension. They only “scale” its value by a certain amount. Hence, multiplying a scalar by a scalar returns a scalar, multiplying a scalar times a vector returns a vector, and multiplying a scalar by a matrix returns a matrix. Scalar multiplication is also commutative, i.e. \\(c\\mathbf{A} = \\mathbf{A}c\\) for all scalars \\(c\\). Consider our scalar, \\(c\\), from the previous section, another scalar, \\(b\\), the vector \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and the matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\)\n\nScalar-Scalar Product: \\[b \\times c = bc \\in \\mathbb{R}\\]\nScalar-Vector Product: \\[ c \\mathbf{x} = \\mathbf{x} c = \\begin{bmatrix} c x_1 \\\\ \\vdots \\\\ c x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nScalar-Matrix Product: \\[ c \\mathbf{A} = \\mathbf{A} c = \\begin{bmatrix} c a_{11} & c a_{12} & \\dots & c a_{1n} \\\\\nc a_{21} & c a_{22} & & c a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\nc a_{m1} & c a_{m2} & \\dots & c a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n } \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#matrix-vector-multiplication",
    "href": "00_linalg.html#matrix-vector-multiplication",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.3 Matrix & Vector Multiplication",
    "text": "2.3 Matrix & Vector Multiplication\nVector-Vector Multiplication\nTo multiply two matrices (or two vectors, or a matrix with a vector), their inner dimensions must always match. Hence, the only valid way to multiply two vectors is by “inner” or “outer” products. Consider two vectors, \\(\\mathbf{u} \\in \\mathbb{R}^n\\) and \\(x \\in \\mathbb{R}^n\\). An “Inner Product” (sometimes called the Dot-Product) is defined as:\n\\[ \\mathbf{u}^\\top \\mathbf{x} = \\begin{bmatrix} u_1 & \\dots & u_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = u_1 x_1 + u_2 x_2 + \\dots u_n x_n \\in \\mathbb{R}\\]\nSome important notes about inner products:\n\nIf the dimensions of \\(\\mathbf{u}\\) and \\(\\mathbf{x}\\) do not match, we cannot multiply them this way as we need to multiply each entry of both vectors.\nThis operation returns a scalar value.\nInner Products are commutative, i.e. \\(\\mathbf{u}^\\top \\mathbf{x} = \\mathbf{x}^\\top \\mathbf{u}\\), as they are sums of scalar-scalar multiplications which are also commutative.\n\nRecall \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Now consider a new vector \\(\\mathbf{w} \\in \\mathbb{R}^m\\) where \\(m \\neq n\\). An “Outer Product” is defined as:\n\\[ \\mathbf{w} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_m \\end{bmatrix} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\mathbf{x}^\\top  \\\\ \\vdots \\\\ w_m \\mathbf{x}^\\top  \\end{bmatrix} = \\begin{bmatrix} w_1 x_1 & w_1 x_2 & \\dots & w_1 x_n \\\\ w_2 x_1 & w_2 x_2 & & w_2 x_n \\\\ \\vdots & & \\ddots & \\vdots \\\\ w_m x_1 & w_m x_2 & \\dots & w_m x_n \\end{bmatrix} \\in \\mathbb{R}^{m \\times n} \\]\nImportant notes on outer products:\n\nOuter products return matrices with dimensions according to the vectors multiplied.\nAs long as \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) are vectors, outer products share an inner dimension of \\(1\\), which means that any two vectors have an outer product.\nLastly, this operation is non-commutative, meaning \\(\\mathbf{w} \\mathbf{x}^\\top \\neq \\mathbf{x} \\mathbf{w}^\\top\\). Rather, these two are transposes of each other.\n\nMatrix-Vector Multiplication\nMultiplying a matrix with a vector means the dimension of the vector must equal the number of columns of the matrix. Recall \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Note that the columns of \\(\\mathbf{A}\\) match the dimension of \\(\\mathbf{x}\\), which are both size \\(n\\). The product \\(\\mathbf{A}\\mathbf{x}\\) can be written as:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n} x_n \\\\  a_{21} x_1 + a_{22} x_2 + \\dots + a_{2n} x_n \\\\ \\vdots \\\\a_{m1} x_1 + a_{m2} x_2 + \\dots + a_{mn} x_n  \\end{bmatrix} \\in \\mathbb{R}^m \\]\nPerhaps a more useful way to visualize this is to break \\(\\mathbf{A}\\) down into its constituent columns and show this as a sum of scalar-vector multiplications:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} x_1 + \\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} x_2 + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} x_n  \\in \\mathbb{R}^m \\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\). Note that matrix-vector multiplication forms a linear map from one dimensional vector-space to another. In this case, \\(\\mathbf{A}\\mathbf{x}\\) maps a vector from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^m\\). This linear transformation from one dimensionality to another is a core component of many machine learning algorithms.\nMatrix-Matrix Multiplication\nConsider two matrices, \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{B} \\in \\mathbb{R}^{n \\times k}\\), where \\(m \\neq k\\). Again, the inner dimensions must match to multiply matrices. Because \\(\\mathbf{A}\\) multiplied by \\(\\mathbf{B}\\) have an inner-dimension of \\(n\\), they can be multiplied. Similar to matrix-vector multiplication, we can visualize the product of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) by breaking up the columns and rows of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), respectively:\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\\\ - & \\mathbf{b}_2 & - \\\\ & \\vdots & \\\\  - & \\mathbf{b}_n & - \\end{bmatrix} \\in \\mathbb{R}^{m \\times k}\\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\) and \\(\\mathbf{b}_i\\) is the \\(i\\)th row of \\(\\mathbf{B}\\). We can expand this expression by multiplying each column of \\(\\mathbf{A}\\) with each row of \\(\\mathbf{B}\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\end{bmatrix} +\\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_2 & - \\end{bmatrix} + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_n & - \\end{bmatrix}\\]\nAs we can see, this is a sum of outer products (vectors multiplied by transposed vectors). We know \\(\\mathbf{A}\\) has \\(m\\) rows and \\(\\mathbf{B}\\) has \\(k\\) columns, so each outer product will form a matrix of dimension \\(m \\times k\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\sum_{i=1}^n \\mathbf{a}_i \\mathbf{b}_i \\in \\mathbb{R}^{m \\times k}\\]\nNote: matrix multiplication is generally non-commutative; The product \\(\\mathbf{A}\\mathbf{B}\\) is valid, because the number of columns of \\(\\mathbf{A}\\) matches the number of rows of \\(\\mathbf{B}\\). However, the product \\(\\mathbf{B}\\mathbf{A}\\) is not valid, because the number of columns of \\(\\mathbf{B}\\) does not equal the number of rows of \\(\\mathbf{A}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#vector-norms",
    "href": "00_linalg.html#vector-norms",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.4 Vector Norms",
    "text": "2.4 Vector Norms\nOftentimes, it is useful to know how “big” a vector is. And there are many different ways of computing this. The “norm” of an object is a measure of how “large” it is, according to some rule. Consider \\(\\mathbf{x} \\in \\mathbb{R}^n\\). The \\(l_p\\) norm is defined by the following:\n\\[ ||\\mathbf{x}||_p = \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} \\]\nThis formula may not be so intuitive, so let’s consider three special instances of the \\(l_p\\) norms:\nThe 1-Norm\nThe 1-norm of \\(\\mathbf{x}\\) is simply the sum of the absolute-value of its entries:\n\\[ ||\\mathbf{x}||_1 = |x_1| + |x_2| + \\dots + |x_n| \\]\nThe 2-Norm\nThe 2-norm of \\(x\\) (which we will use most-often in this class) is defined as the squareroot of the squares of its entries:\n\\[ ||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} \\]\nThe reason the 2-norm is so useful is the fact that the square of the \\(l_2\\) norm is an inner product of a vector with itself:\n\\[ \\mathbf{x}^\\top \\mathbf{x} = x_1^2 + x_2^2 + \\dots + x_3^2 = ||\\mathbf{x}||_2^2 \\]\nThis helps us write a norm in terms of matrix-vector operations, which is extremely useful for optimization. The 2-norm is also quite important because it is the first \\(l_p\\) norm with a continuous derivative, which cannot be said of the 1-norm since it uses absolute-value functions.\nThe Infinity-Norm\nThe infinity-norm takes the limit as \\(p \\rightarrow \\infty\\) and when this limit is solved, this norm simply becomes the entry of \\(x\\) with the largest absolute value:\n\\[ ||\\mathbf{x}||_\\infty = \\max \\{ |x_1|, |x_2|, \\dots, |x_n| \\} \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#rank-rangecolumn-space-and-null-spaces",
    "href": "00_linalg.html#rank-rangecolumn-space-and-null-spaces",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.5 Rank, Range/Column-Space and Null-Spaces",
    "text": "2.5 Rank, Range/Column-Space and Null-Spaces\nLinear-Independence\nThis is a fundamental idea in Linear Algebra. A set of vectors is said to be “Linearly Independent” if no vector in this set can be reconstructed with any of the others. In other words, no one vector can be reproduced by scaling or combining any of the others. For example, consider the following three vectors:\n\\[ \\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\} \\]\nBecause each vector in this set points in its own unique direction, it is impossible to reconstruct one of these vectors as a linear combination of any others. This may be true with more complex vectors that aren’t unit vectors along the dimensions of the vector-space.\nRank\nThe rank of a matrix is simply the number of linearly independent columns. Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 & 1 & 4 \\\\ 0 & 1 & 1 & 2 \\\\ 0 & 0 & 2 & 0 \\end{bmatrix} \\]\nThe first-three columns of \\(\\mathbf{A}\\) are linearly independent because they cannot be reproduced using linear combinations of the other columns. However, the last column is a multiple of column 2, which means it can be reproduced using a linear combination of columns. Hence, this matrix has a rank of 3.\nTheorem: No matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) where \\(m &lt; n\\) can be full-rank. This is because only \\(m\\) vectors can span \\(\\mathbb{R}^m\\), and since there are more than \\(m\\) columns, we must have some redundancy.\nRange/Column-Space\nThe Range, Column-Space or Image of a matrix, \\(\\mathbf{A}\\), is the span of all possible combinations of its columns. In human words, it describes the space of \\(\\mathbf{Ax}\\) for all possible \\(\\mathbf{x}\\). Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\\\ 2 & 4  \\end{bmatrix} \\]\nNote that the second column is a multiple of the first column, hence, the range of \\(\\mathbf{A}\\) is:\n\\[ \\text{Range}(\\mathbf{A}) = \\text{span} \\left( \\begin{bmatrix} 1 \\\\ 3 \\\\ 2 \\end{bmatrix}\\right) \\]\nNull-Space\nThe Null-Space of a matrix, \\(\\mathbf{A}\\) is the set of all nonzero vectors, \\(\\mathbf{x}\\) such that \\(\\mathbf{Ax=0}\\). Consider a simple example:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\]\nWe can find the set of \\(\\mathbf{x}\\) that produce the zero-vector by solving the following equation:\n\\[ \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\]\nThis produces the systems of equations:\n\\[ x_1 - x_3 = 0 \\] \\[ x_2 + x_3 = 0 \\] \\[ x_3 = x_3 \\]\nIf we isolate each entry of \\(\\mathbf{x}\\):\n\\[ x_1 = x_3 \\] \\[ x_2 = -x_3 \\] \\[ x_3 = x_3 \\]\nHence, we see that \\(x_3\\) can be any scalar and satisfy this systems of equations:\n\\[ \\mathbf{x} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} x_3 = \\text{span}\\left( \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} \\right) = \\text{Null}(\\mathbf{A})\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#the-identity-matrix",
    "href": "00_linalg.html#the-identity-matrix",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.6 The Identity Matrix",
    "text": "2.6 The Identity Matrix\nThe identity matrix is a square, \\(n\\)-dimensional matrix consisting of ones on its diagonal and zeros elsewhere. It is called the identity matrix because it preserves the identity when multiplied by matrices and vectors.\n\\[ \\mathbf{I} = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\ 0 & 1  & & 0 \\\\ \\vdots & & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & 1 \\end{bmatrix} \\]\nConsider \\(\\mathbf{I} \\in \\mathbb{R}^{n \\times n}\\) to be an \\(n \\times n\\) identity matrix. If we recall \\(\\mathbf{A} \\in \\mathbb{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\):\n\\[ \\mathbf{A I = I A = A} \\]\n\\[ \\mathbf{I x = x } \\]\n\\[ \\mathbf{x^\\top I = x^\\top} \\]\nWhy is this useful?\nThe identity matrix simplifies expressions involving matrices. If we can transform a term into an identity matrix, then we can reduce the expression to only the remaining terms.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#matrix-inverses",
    "href": "00_linalg.html#matrix-inverses",
    "title": "1  Notes 00: Linear algebra review",
    "section": "2.7 Matrix Inverses",
    "text": "2.7 Matrix Inverses\nYou may have noticed that, thus far, we have covered the addition, subtraction, and multiplication of matrices, which conspicuously leaves division. Well, unfortunately, matrix division is complex to say the least. For square matrices, division is accomplished via matrix inversion. However, not all matrices are invertible.\nDefinition: A matrix \\(\\mathbf{B}\\) is called the “inverse” of a square matrix \\(\\mathbf{A}\\) if and only if the following condition holds:\n\\[ \\mathbf{A} \\mathbf{B} = \\mathbf{B} \\mathbf{A} = \\mathbf{I} \\]\nwhere \\(\\mathbf{I}\\) is the identity matrix. Such a \\(\\mathbf{B}\\) is denoted \\(\\mathbf{A}^{-1}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Notes 00: Linear algebra review</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html",
    "href": "20_ugbo.html",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "",
    "text": "4 Problem Motivation\nIn this lecture, we will be focusing on the following optimization problem,\n\\[\\min_x f(x)\\]\nwhere \\(f: \\mathbb{R}^n \\to \\mathbb{R}\\) is our objective function (or loss function), and \\(x\\in\\mathbb{R}^n\\) is a vector of parameters (variables) which we can change. Minimization problems arise in numerous physical and real-world circumstances, including:\nFor this lecture, our approach for solving the above minimization problem will be a gradient-based one. This means that we will make use of information from the gradient of \\(f\\) (first-order information), and the curvature of \\(f\\) (second-order information).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#what-are-we-looking-for",
    "href": "20_ugbo.html#what-are-we-looking-for",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.1 What are we looking for?",
    "text": "5.1 What are we looking for?\nTo start, we first need to motivate some fundamental definitions regarding the nature of the solution we are looking for.\nDefinition: We say that a point \\(x^\\star\\) is a global minimizer of \\(f\\) if: \\[f(x^\\star)\\leq f(x) \\text{ for all }x\\in \\mathcal{D}\\subseteq\\mathbb{R}^n.\\]\nAlthough a global minimizer is the most desireable outcome from our minimization problem, finding a global minimizer is often quite challenging. This is because a global minimizer may not always exist, and because we often only possess local information about the function \\(f\\). This motivates the following defintion:\nDefinition: We say that a point \\(x^\\star\\) is a local minimizer of \\(f\\) if there exists some open set \\(\\mathcal{B}\\), that contains \\(x^\\star\\), such that: \\[\nf(x^\\star)\\leq f(x) \\text{ for all }x\\in\\mathcal{B}.\n\\] If the inequality becomes strict, then \\(x^\\star\\) is referred to as a strict local minimizer. To illustrate the above definitions, let us look at the function \\(f(x) = 2 + \\cos(x) + \\frac{1}{2} \\cos\\left(5x - \\frac{1}{2}\\right)\\) over the domain \\(\\mathcal{D} = [0, 3.7]\\). In this domain, the function has two local minimizers and one global minimizer, as illustrated in the plot below.\n\n\n\n\n\n\n\n\n\nWe now have a way to understand and characterize our solutions. However, the above definitions suggest that we need to examine all points that are next to \\(x^\\star\\) in order to properly characterize it. However, if our function is smooth, i.e., its higher order derivatives exist and are continuous, then we can classify \\(x^\\star\\) by examining the derivatives of \\(f\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#gradient",
    "href": "20_ugbo.html#gradient",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.2 Gradient",
    "text": "5.2 Gradient\nRecall that the gradient of a function \\(f(x)\\), denoted \\(\\nabla f(x)\\), is the column vector of partial derivaties with respect to each parameter: \\[\n\\nabla f(x) =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1}\\\\\n\\vdots\\\\\n\\frac{\\partial f}{\\partial x_i}\\\\\n\\vdots\\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{bmatrix}\n\\] Each element of \\(\\nabla f(x)\\) captures the rate of change of the function \\(f\\) with respect to the parameter \\(x_i\\). The gradient of a function helps us identify local minimizers and allows us to state (without proof) the first fundamental result of gradient-based optimization.\nTheorem (first-order necessary conditions): If \\(x^\\star\\) is a local minimizer and \\(f\\) is continuously differentiable in an open nieghborhood of \\(x^\\star\\), then \\(\\nabla f(x^\\star) = 0\\).\nA point \\(x^\\star\\) is called a stationary point if \\(\\nabla f(x^\\star) = 0\\). The above theorem guarantees that all local minimizers must be stationary points. However, the theorem cannot guarantee that all stationary points are local minimizers. This is because the conditions are necessary but not sufficient. As a counterexample, a stationary point may be a local maximizer instead of a local minimizer. In order to obtain necessary and suffient conditions, we need to move one derivative higher.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#curvature",
    "href": "20_ugbo.html#curvature",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.3 Curvature",
    "text": "5.3 Curvature\nThe curvature of a function \\(f\\) is the rate of change of the gradient, and tells us whether the slope is stationary, increasing, or decreasing. To compute the curvature of \\(f\\), we need to take a partial derivate of every component of the gradient with respect to each coordinate direction. This leads to an \\((n\\times n)\\) matrix of second partial derivatives called the Hessian:\n\\[\nH(x) = \\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_2 \\partial x_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_n \\partial x_2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n\\end{bmatrix}\n\\]\nIf our function \\(f\\) has continuous second partial derivatives, then the order of differentiation does not matter and the matrix \\(H\\) becomes symmetric. The Hessian allows us to establish two more (stronger) fundamental results of gradient-based optimization. Before stating them, let us recall that a matrix \\(A\\) is positive definite if \\(x^\\top A x &gt; 0\\) for all \\(x\\neq 0\\) and positive semidefinite if \\(x^\\top A x \\geq 0\\) for all \\(x\\).\nTheorem (second-order necessary conditions): If \\(x^\\star\\) is a local minimizer of \\(f\\) and the Hessian \\(H\\) exists and is continuous in an open neighborhood of \\(x^\\star\\), then \\(\\nabla f(x^\\star) = 0\\) and \\(H\\) is positive semidefinite.\nTheorem (second-order sufficient conditions): Suppose that \\(H\\) is is continuous in an open neighborhood of \\(x^\\star\\) and that \\(\\nabla f(x^\\star) =0\\) and \\(H\\) is positive definite. Then, \\(x^\\star\\) is a strict local minimizer of \\(f\\).\nIt is important to remark that the second-order sufficient condition gurantee a stronger result when compared to the second-order necessary condtions. Namely, the second-order sufficient conditions lead to a strict local minimizer. Furthermore, we should also note that the sufficient condtions are not necessary; it is possible for a point \\(x^\\star\\) to be a strict local minimizer but fail to satisfy the sufficient conditions. As an example, consider \\(f(x) = x^6\\), where \\(x^\\star = 0\\) is a strict local minimizer, yet the Hessian evaluates to zero at \\(x^\\star = 0\\) and is therefore not positive definite.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "20_ugbo.html#a-complete-example",
    "href": "20_ugbo.html#a-complete-example",
    "title": "3  Unconstrained Gradient Based Optimization (UGBO)",
    "section": "5.4 A complete example",
    "text": "5.4 A complete example\nHere, we work our way through an example problem where we can see how the concepts from above can be applied to help us identify and characterize critical points. Consider the function:\n\\[\nf(x_1, x_2) = 0.5x_1^4 + 2x_1^3 + 1.5x_1^2 + x_2^2 - 2x_1x_2\n\\]\nLet’s plot the contours of \\(f\\).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the function\ndef f(x1, x2):\n    return 0.5 * x1**4 + 2 * x1**3 + (3/2) * x1**2 + x2**2 - 2 * x1 * x2\n\n# Create the contour plot\nx = np.linspace(-4, 2, 1000)\ny = np.linspace(-4, 2, 1000)\nX, Y = np.meshgrid(x, y)\nZ = f(X, Y)\n\nplt.figure(figsize=(9.5, 5))\ncontour = plt.contour(X, Y, Z, levels=75)\nplt.xlabel(r'$x_1$')\nplt.ylabel(r'$x_2$')\n\nText(0, 0.5, '$x_2$')\n\n\n\n\n\n\n\n\n\nTo start, we need to identify all critical points of \\(f\\). We can do that by solving for all points such that \\(\\nabla f(x) = 0\\), i.e.,\n\\[\n\\nabla f(x_1, x_2) =\n\\begin{bmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2}\n\\end{bmatrix} =\n\\begin{bmatrix}\n2x_1^3 + 6x_1^2 + 3x_1 - 2x_2 \\\\ 2x_2 - 2x_1\n\\end{bmatrix} =\n\\begin{bmatrix}\n0 \\\\ 0\n\\end{bmatrix}\n\\]\nWe can do that by using fsolve() from scipy.optimize.\n\nfrom scipy.optimize import fsolve\n\n# Define the first partial derivatives\ndef df_dx1(x1, x2):\n    return 2 * x1**3 + 6 * x1**2 + 3 * x1 - 2 * x2\n\ndef df_dx2(x1, x2):\n    return 2 * x2 - 2 * x1\n\n# Define the system of equations\ndef equations(vars):\n    x1, x2 = vars\n    return [df_dx1(x1, x2), df_dx2(x1, x2)]\n\n# Solve for critical points\ninitial_guesses = [(0, 0), (-1, -1), (-10, -10)]\ncritical_points = [fsolve(equations, guess) for guess in initial_guesses]\n\nprint(critical_points)\n\n[array([0., 0.]), array([-0.17712434, -0.17712434]), array([-2.82287566, -2.82287566])]\n\n\nNow, we need to classify each critical point. To do so, let’s compute the Hessian:\n\\[\nH(x_1, x_2) =\n\\begin{bmatrix}\n\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\\n\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n6x_1^2 + 12x_1 + 3 & -2 \\\\\n-2 & 2\n\\end{bmatrix}\n\\]\nWe now need to evaluate the Hessian at each one of the critical points and check whether is it positive semidefinite. There are a number of ways we can check this, but we will be examining the eigenvalues of the Hessian and checking whether they are all positive.\n\n# Define the Hessian\ndef Hessian(x1, x2):\n    return np.array([[6 * x1**2 + 12 * x1 + 3, -2], [-2, 2]])\n\neigs = [np.linalg.eigvals(Hessian(pt[0], pt[1])) for pt in critical_points]\n\nprint(eigs)\n\n[array([4.56155281, 0.43844719]), array([-0.5227962 ,  3.58554227]), array([17.20040482,  1.73684911])]\n\n\nBased on these results, we know that the first and third critical points are local minimizers. The second critical point is classifies as a saddle point because the Hessian is not positive semidefinite. To find out which of the local minimizers is the global minimzer, we evaluate the function at each of these points. Let’s go ahead and label the points accordingly.\n\n# Create the contour plot\nx = np.linspace(-4, 2, 1000)\ny = np.linspace(-4, 2, 1000)\nX, Y = np.meshgrid(x, y)\nZ = f(X, Y)\n\nplt.figure(figsize=(9.5, 5))\ncontour = plt.contour(X, Y, Z, levels=75)\nplt.xlabel(r'$x_1$')\nplt.ylabel(r'$x_2$')\n\n# Plot and label the critical points\nlabels = [\"local minimum\", \"saddle point\", \"global minimum\"]\n\nfor (x, y), label in zip(critical_points, labels):\n    plt.scatter(x, y, label=f'{label} ({x:.2f}, {y:.2f})', s=100)\n    if label == \"saddle point\":\n        plt.text(x, y, f' {label}', fontsize=12, ha='right', weight='bold')\n    else:\n        plt.text(x, y, f' {label}', fontsize=12, ha='left', weight='bold')\n\nplt.grid(False)\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO)</span>"
    ]
  },
  {
    "objectID": "21_ugbo2.html",
    "href": "21_ugbo2.html",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "",
    "text": "5 Problem Motivation\nSo far, we have developed analytical tools that allow us to find and classify critical points of functions. However, this analytical approach to finding minima is often infeasible, esecially when the objective function is a result of a numerical model. To combat this, we turn to interative algorithms that prgressively work towards finding a minimum while only relying on function and gradient evaluations. The main idea is that we will start from some initial guess \\(x_0\\) and produce a sequence of points \\(x_1, x_2, x_3, \\ldots, x_j, \\ldots\\), eventually converging to some local minimizer \\(x^\\star\\).\nThere are two major classes of iterative optimization methods that produce the aforementioned sequence of points: line search methods and trust region methods. In this course, we will focus on the former, but we will provide some resources for those interested in the latter. Line search methods consist of three main steps that occur at each iteration:\nThe whole process is summarized in the diagram below.\nflowchart LR\n  A(Starting guess) --&gt; B(Search direction)\n  B --&gt; C(Step size)\n  C --&gt; D(Is this a minimum?)\n  D --&gt;|Yes| E(Converged)\n  D --&gt;|No| F(Update values)\n  F --&gt; B\nSteps 1 and 2 can be understood as two separate subproblems in the overall optimization scheme. In this note, we will examine the first of these subproblems by introducing the steepest descent algorithm, and seeing how the subproblem of determining a suitable step size arises as a natural consequence.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent</span>"
    ]
  },
  {
    "objectID": "21_ugbo2.html#motivation",
    "href": "21_ugbo2.html#motivation",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "6.1 Motivation",
    "text": "6.1 Motivation\nGiven some objective function \\(f\\), recall that the gradient \\(\\nabla f\\) is a vector with each component quantifying the function’s local rate of change with respect to each variable.\nFact: The gradient is a vector that points to the direction that yields the greatest function increase from the current point.\nIdea: From any given point \\(x\\), we can find the direction of steepest descent by taking \\(-\\nabla f(x)\\). So, we can define our search direction at iteration \\(k\\) as: \\(p_k = -\\nabla f(x_k)\\)\nOne problem with the above idea is that the gradient does not give us any information regarding the step size we should take. Hence, the search direction is often normalized as:\n\\[\np_k = -\\frac{\\nabla f(x_k)}{\\|\\nabla f(x_k)\\|_2}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent</span>"
    ]
  },
  {
    "objectID": "21_ugbo2.html#algorithm",
    "href": "21_ugbo2.html#algorithm",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "6.2 Algorithm",
    "text": "6.2 Algorithm\nNeed to include an algorithm block here.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent</span>"
    ]
  },
  {
    "objectID": "21_ugbo2.html#example",
    "href": "21_ugbo2.html#example",
    "title": "4  Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent",
    "section": "6.3 Example",
    "text": "6.3 Example\nConsider the quadratic function: \\[\nf(x_1, x_2) = x_1^2 + \\beta x_2^2\n\\]\nFirst, let us consider the case where \\(\\beta = 1\\) and the starting point is \\(x_0 = (10,1)\\).\n\n\n0.0002487577548903103\n\n\nText(0, 0.5, '$x_2$')\n\n\n\n\n\n\n\n\n\nThis is a test citation (Martins and Ning 2021).\n\n\n\n\nMartins, Joaquim RRA, and Andrew Ning. 2021. Engineering Design Optimization. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent</span>"
    ]
  },
  {
    "objectID": "00_linalg.html#linear-algebra-crash-course",
    "href": "00_linalg.html#linear-algebra-crash-course",
    "title": "Appendix A — Linear algebra review",
    "section": "A.1 Linear Algebra Crash Course",
    "text": "A.1 Linear Algebra Crash Course\nBefore we dive into the world of machine learning and optimization, it’s important that we get comfortable with the fundamental building blocks of mathematics in higher dimensions: Linear Algebra. This course assumes you have seen basic concepts in Linear Algebra, but we’ll provide a refresher to get everyone on the same page.\n\nA.1.0.1 Scalars, Vectors, and Matrices\nNotation\nLet’s introduce some notation: \\(\\mathbb{R}\\) is the set of real numbers, \\(\\mathbb{C}\\) is the set of complex numbers, and the operator \\(\\in\\) designates that a variable belongs to a set. To define a real scalar (i.e. just a number), \\(c\\), we write:\n\\[ c \\in \\mathbb{R}\\]\nYou can read this as “the variable \\(c\\) belongs to the set of 1-dimensional real numbers.”\nTo define a real \\(n\\) dimensional vector, \\(\\mathbf{x}\\), we write:\n\\[ \\mathbf{x}  = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nTo define a \\(m \\times n\\) matrix \\(\\mathbf{A}\\) of real-valued entries, we write:\n\\[ \\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n }\n\\]\nThe Transposes\nThe “transpose” of a matrix or vector, swaps the rows and columns. In other words, the first row becomes the first column, the second row the second column and so-on:\n\\[ \\mathbf{x}^\\top = \\begin{bmatrix} x_1 & \\dots & x_n \\end{bmatrix} \\in \\mathbb{R}^{1 \\times n} \\]\n\\[ \\mathbf{A}^\\top = \\begin{bmatrix} a_{11} & a_{21} & \\dots & a_{m1} \\\\\na_{12} & a_{22} & & a_{m2} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{1n} & a_{2n} & \\dots & a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{n \\times m } \\]\nTransposing the product of matrices reverses their order:\n\\[ \\left( \\mathbf{A} \\mathbf{B} \\mathbf{C} \\mathbf{D} \\right)^\\top = \\mathbf{D}^\\top \\mathbf{C}^\\top \\mathbf{B}^\\top \\mathbf{A}^\\top \\]\nAddition & subtraction\nTechnically, only objects of the same dimensionality can be added or subtracted with one another. So, scalars can only be added to scalars, vectors can only be added to vectors of the same dimension, and matrices can only be added to other matrices with the same numbers of rows and columns. Some software like MATLAB or NumPy might let you add scalars to vectors and matrices and under the hood they multiply that scalar by a vector/matrix of ones to make the dimensions match.\n\n\nA.1.0.2 Scalar Multiplication\nGenerally, scalars can multiply by any structure (scalar, vector, and matrix) and do not change its dimension. They only “scale” its value by a certain amount. Hence, multiplying a scalar by a scalar returns a scalar, multiplying a scalar times a vector returns a vector, and multiplying a scalar by a matrix returns a matrix. Scalar multiplication is also commutative, i.e. \\(c\\mathbf{A} = \\mathbf{A}c\\) for all scalars \\(c\\). Consider our scalar, \\(c\\), from the previous section, another scalar, \\(b\\), the vector \\(\\mathbf{x} \\in \\mathbb{R}^n\\) and the matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\)\n\nScalar-Scalar Product: \\[b \\times c = bc \\in \\mathbb{R}\\]\nScalar-Vector Product: \\[ c \\mathbf{x} = \\mathbf{x} c = \\begin{bmatrix} c x_1 \\\\ \\vdots \\\\ c x_n \\end{bmatrix} \\in \\mathbb{R}^n \\]\nScalar-Matrix Product: \\[ c \\mathbf{A} = \\mathbf{A} c = \\begin{bmatrix} c a_{11} & c a_{12} & \\dots & c a_{1n} \\\\\nc a_{21} & c a_{22} & & c a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\nc a_{m1} & c a_{m2} & \\dots & c a_{mn}\n\\end{bmatrix} \\in \\mathbb{R}^{m \\times n } \\]\n\n\n\nA.1.0.3 Matrix & Vector Multiplication\nVector-Vector Multiplication\nTo multiply two matrices (or two vectors, or a matrix with a vector), their inner dimensions must always match. Hence, the only valid way to multiply two vectors is by “inner” or “outer” products. Consider two vectors, \\(\\mathbf{u} \\in \\mathbb{R}^n\\) and \\(x \\in \\mathbb{R}^n\\). An “Inner Product” (sometimes called the Dot-Product) is defined as:\n\\[ \\mathbf{u}^\\top \\mathbf{x} = \\begin{bmatrix} u_1 & \\dots & u_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = u_1 x_1 + u_2 x_2 + \\dots u_n x_n \\in \\mathbb{R}\\]\nSome important notes about inner products:\n\nIf the dimensions of \\(\\mathbf{u}\\) and \\(\\mathbf{x}\\) do not match, we cannot multiply them this way as we need to multiply each entry of both vectors.\nThis operation returns a scalar value.\nInner Products are commutative, i.e. \\(\\mathbf{u}^\\top \\mathbf{x} = \\mathbf{x}^\\top \\mathbf{u}\\), as they are sums of scalar-scalar multiplications which are also commutative.\n\nRecall \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Now consider a new vector \\(\\mathbf{w} \\in \\mathbb{R}^m\\) where \\(m \\neq n\\). An “Outer Product” is defined as:\n\\[ \\mathbf{w} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\\\ \\vdots \\\\ w_m \\end{bmatrix} \\mathbf{x}^\\top = \\begin{bmatrix} w_1 \\mathbf{x}^\\top  \\\\ \\vdots \\\\ w_m \\mathbf{x}^\\top  \\end{bmatrix} = \\begin{bmatrix} w_1 x_1 & w_1 x_2 & \\dots & w_1 x_n \\\\ w_2 x_1 & w_2 x_2 & & w_2 x_n \\\\ \\vdots & & \\ddots & \\vdots \\\\ w_m x_1 & w_m x_2 & \\dots & w_m x_n \\end{bmatrix} \\in \\mathbb{R}^{m \\times n} \\]\nImportant notes on outer products:\n\nOuter products return matrices with dimensions according to the vectors multiplied.\nAs long as \\(\\mathbf{w}\\) and \\(\\mathbf{x}\\) are vectors, outer products share an inner dimension of \\(1\\), which means that any two vectors have an outer product.\nLastly, this operation is non-commutative, meaning \\(\\mathbf{w} \\mathbf{x}^\\top \\neq \\mathbf{x} \\mathbf{w}^\\top\\). Rather, these two are transposes of each other.\n\nMatrix-Vector Multiplication\nMultiplying a matrix with a vector means the dimension of the vector must equal the number of columns of the matrix. Recall \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\). Note that the columns of \\(\\mathbf{A}\\) match the dimension of \\(\\mathbf{x}\\), which are both size \\(n\\). The product \\(\\mathbf{A}\\mathbf{x}\\) can be written as:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\\na_{21} & a_{22} & & a_{2n} \\\\\n\\vdots & & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\dots & a_{mn}\n\\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} a_{11} x_1 + a_{12} x_2 + \\dots + a_{1n} x_n \\\\  a_{21} x_1 + a_{22} x_2 + \\dots + a_{2n} x_n \\\\ \\vdots \\\\a_{m1} x_1 + a_{m2} x_2 + \\dots + a_{mn} x_n  \\end{bmatrix} \\in \\mathbb{R}^m \\]\nPerhaps a more useful way to visualize this is to break \\(\\mathbf{A}\\) down into its constituent columns and show this as a sum of scalar-vector multiplications:\n\\[ \\mathbf{A}\\mathbf{x} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\end{bmatrix} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} x_1 + \\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} x_2 + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} x_n  \\in \\mathbb{R}^m \\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\). Note that matrix-vector multiplication forms a linear map from one dimensional vector-space to another. In this case, \\(\\mathbf{A}\\mathbf{x}\\) maps a vector from \\(\\mathbb{R}^n\\) to \\(\\mathbb{R}^m\\). This linear transformation from one dimensionality to another is a core component of many machine learning algorithms.\nMatrix-Matrix Multiplication\nConsider two matrices, \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) and \\(\\mathbf{B} \\in \\mathbb{R}^{n \\times k}\\), where \\(m \\neq k\\). Again, the inner dimensions must match to multiply matrices. Because \\(\\mathbf{A}\\) multiplied by \\(\\mathbf{B}\\) have an inner-dimension of \\(n\\), they can be multiplied. Similar to matrix-vector multiplication, we can visualize the product of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) by breaking up the columns and rows of \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\), respectively:\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | & | &  & | \\\\\n\\mathbf{a}_1 & \\mathbf{a}_2 & \\dots & \\mathbf{a}_n \\\\\n| & | & & | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\\\ - & \\mathbf{b}_2 & - \\\\ & \\vdots & \\\\  - & \\mathbf{b}_n & - \\end{bmatrix} \\in \\mathbb{R}^{m \\times k}\\]\nwhere \\(\\mathbf{a}_i\\) is the \\(i\\)th column of \\(\\mathbf{A}\\) and \\(\\mathbf{b}_i\\) is the \\(i\\)th row of \\(\\mathbf{B}\\). We can expand this expression by multiplying each column of \\(\\mathbf{A}\\) with each row of \\(\\mathbf{B}\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\begin{bmatrix} | \\\\ \\mathbf{a}_1 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_1 & - \\end{bmatrix} +\\begin{bmatrix} | \\\\ \\mathbf{a}_2 \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_2 & - \\end{bmatrix} + \\dots + \\begin{bmatrix} | \\\\ \\mathbf{a}_n \\\\ | \\end{bmatrix} \\begin{bmatrix} - & \\mathbf{b}_n & - \\end{bmatrix}\\]\nAs we can see, this is a sum of outer products (vectors multiplied by transposed vectors). We know \\(\\mathbf{A}\\) has \\(m\\) rows and \\(\\mathbf{B}\\) has \\(k\\) columns, so each outer product will form a matrix of dimension \\(m \\times k\\):\n\\[ \\mathbf{A}\\mathbf{B} = \\sum_{i=1}^n \\mathbf{a}_i \\mathbf{b}_i \\in \\mathbb{R}^{m \\times k}\\]\nNote: matrix multiplication is generally non-commutative; The product \\(\\mathbf{A}\\mathbf{B}\\) is valid, because the number of columns of \\(\\mathbf{A}\\) matches the number of rows of \\(\\mathbf{B}\\). However, the product \\(\\mathbf{B}\\mathbf{A}\\) is not valid, because the number of columns of \\(\\mathbf{B}\\) does not equal the number of rows of \\(\\mathbf{A}\\).\n\n\nA.1.0.4 Vector Norms\nOftentimes, it is useful to know how “big” a vector is. And there are many different ways of computing this. The “norm” of an object is a measure of how “large” it is, according to some rule. Consider \\(\\mathbf{x} \\in \\mathbb{R}^n\\). The \\(l_p\\) norm is defined by the following:\n\\[ ||\\mathbf{x}||_p = \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} \\]\nThis formula may not be so intuitive, so let’s consider three special instances of the \\(l_p\\) norms:\nThe 1-Norm\nThe 1-norm of \\(\\mathbf{x}\\) is simply the sum of the absolute-value of its entries:\n\\[ ||\\mathbf{x}||_1 = |x_1| + |x_2| + \\dots + |x_n| \\]\nThe 2-Norm\nThe 2-norm of \\(x\\) (which we will use most-often in this class) is defined as the squareroot of the squares of its entries:\n\\[ ||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2} \\]\nThe reason the 2-norm is so useful is the fact that the square of the \\(l_2\\) norm is an inner product of a vector with itself:\n\\[ \\mathbf{x}^\\top \\mathbf{x} = x_1^2 + x_2^2 + \\dots + x_3^2 = ||\\mathbf{x}||_2^2 \\]\nThis helps us write a norm in terms of matrix-vector operations, which is extremely useful for optimization. The 2-norm is also quite important because it is the first \\(l_p\\) norm with a continuous derivative, which cannot be said of the 1-norm since it uses absolute-value functions.\nThe Infinity-Norm\nThe infinity-norm takes the limit as \\(p \\rightarrow \\infty\\) and when this limit is solved, this norm simply becomes the entry of \\(x\\) with the largest absolute value:\n\\[ ||\\mathbf{x}||_\\infty = \\max \\{ |x_1|, |x_2|, \\dots, |x_n| \\} \\]\n\n\nA.1.1 Rank, Range/Column-Space and Null-Spaces\nLinear-Independence\nThis is a fundamental idea in Linear Algebra. A set of vectors is said to be “Linearly Independent” if no vector in this set can be reconstructed with any of the others. In other words, no one vector can be reproduced by scaling or combining any of the others. For example, consider the following three vectors:\n\\[ \\{ \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\\} \\]\nBecause each vector in this set points in its own unique direction, it is impossible to reconstruct one of these vectors as a linear combination of any others. This may be true with more complex vectors that aren’t unit vectors along the dimensions of the vector-space.\nRank\nThe rank of a matrix is simply the number of linearly independent columns. Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 & 1 & 4 \\\\ 0 & 1 & 1 & 2 \\\\ 0 & 0 & 2 & 0 \\end{bmatrix} \\]\nThe first-three columns of \\(\\mathbf{A}\\) are linearly independent because they cannot be reproduced using linear combinations of the other columns. However, the last column is a multiple of column 2, which means it can be reproduced using a linear combination of columns. Hence, this matrix has a rank of 3.\nTheorem: No matrix \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\) where \\(m &lt; n\\) can be full-rank. This is because only \\(m\\) vectors can span \\(\\mathbb{R}^m\\), and since there are more than \\(m\\) columns, we must have some redundancy.\nRange/Column-Space\nThe Range, Column-Space or Image of a matrix, \\(\\mathbf{A}\\), is the span of all possible combinations of its columns. In human words, it describes the space of \\(\\mathbf{Ax}\\) for all possible \\(\\mathbf{x}\\). Consider the following matrix:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 6 \\\\ 2 & 4  \\end{bmatrix} \\]\nNote that the second column is a multiple of the first column, hence, the range of \\(\\mathbf{A}\\) is:\n\\[ \\text{Range}(\\mathbf{A}) = \\text{span} \\left( \\begin{bmatrix} 1 \\\\ 3 \\\\ 2 \\end{bmatrix}\\right) \\]\nNull-Space\nThe Null-Space of a matrix, \\(\\mathbf{A}\\) is the set of all nonzero vectors, \\(\\mathbf{x}\\) such that \\(\\mathbf{Ax=0}\\). Consider a simple example:\n\\[ \\mathbf{A} = \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\]\nWe can find the set of \\(\\mathbf{x}\\) that produce the zero-vector by solving the following equation:\n\\[ \\begin{bmatrix} 1 & 0 & -1\\\\ 0 & 1 & 1   \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} \\]\nThis produces the systems of equations:\n\\[ x_1 - x_3 = 0 \\] \\[ x_2 + x_3 = 0 \\] \\[ x_3 = x_3 \\]\nIf we isolate each entry of \\(\\mathbf{x}\\):\n\\[ x_1 = x_3 \\] \\[ x_2 = -x_3 \\] \\[ x_3 = x_3 \\]\nHence, we see that \\(x_3\\) can be any scalar and satisfy this systems of equations:\n\\[ \\mathbf{x} = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} x_3 = \\text{span}\\left( \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} \\right) = \\text{Null}(\\mathbf{A})\\]\n\nA.1.1.1 The Identity Matrix\nThe identity matrix is a square, \\(n\\)-dimensional matrix consisting of ones on its diagonal and zeros elsewhere. It is called the identity matrix because it preserves the identity when multiplied by matrices and vectors.\n\\[ \\mathbf{I} = \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\ 0 & 1  & & 0 \\\\ \\vdots & & \\ddots & \\vdots \\\\ 0 & 0 & \\dots & 1 \\end{bmatrix} \\]\nConsider \\(\\mathbf{I} \\in \\mathbb{R}^{n \\times n}\\) to be an \\(n \\times n\\) identity matrix. If we recall \\(\\mathbf{A} \\in \\mathbb{m \\times n}\\) and \\(\\mathbf{x} \\in \\mathbb{R}^n\\):\n\\[ \\mathbf{A I = I A = A} \\]\n\\[ \\mathbf{I x = x } \\]\n\\[ \\mathbf{x^\\top I = x^\\top} \\]\nWhy is this useful?\nThe identity matrix simplifies expressions involving matrices. If we can transform a term into an identity matrix, then we can reduce the expression to only the remaining terms.\n\n\n\nA.1.2 Matrix Inverses\nYou may have noticed that, thus far, we have covered the addition, subtraction, and multiplication of matrices, which conspicuously leaves division. Well, unfortunately, matrix division is complex to say the least. For square matrices, division is accomplished via matrix inversion. However, not all matrices are invertible.\nDefinition: A matrix \\(\\mathbf{B}\\) is called the “inverse” of a square matrix \\(\\mathbf{A}\\) if and only if the following condition holds:\n\\[ \\mathbf{A} \\mathbf{B} = \\mathbf{B} \\mathbf{A} = \\mathbf{I} \\]\nwhere \\(\\mathbf{I}\\) is the identity matrix. Such a \\(\\mathbf{B}\\) is denoted \\(\\mathbf{A}^{-1}\\)."
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 What’s in a name? Artificial intelligence, machine learning, data science, and the scope of this course.\nI googled “artificial intelligence” (often abbreviated AI) and the first result comes from Google’s new “AI overview” feature1:\nBecause I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer:\nThese are probably both reasonable definitions for casual conversation, but that’s not what we’re here for. Instead, we’re here to really learn deeply about what AI is, and for that we’re going to need precision – that is, of our definitions.\nI’m not going to provide a definition of AI for now and instead I’m going to throw two more terms into the mix that you may have heard. The first is “machine learning” (often abbreviated ML). Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition (Merriam-Webster Dictionary 2024):\nAnd finally I’ll add the term “data science” (curiously, rarely abbreviated DS). I wanted to give you a Merriam-Webster definition here, but the term isn’t in their dictionary as of writing this on October 28, 2024. So instead I’m going to use Cambridge Dictionary’s definition (Cambridge Dictionary 2024):\nClearly, different people/entities may have different ideas of what AI, ML, and data science may mean. Some people may use these terms to describe generative tools like ChatGPT, GitHub copilot, and Dall-E (or similar products developed by other entities). Others use these terms to refer to more purpose-built algorithms like AlphaGo (for playing Go) or GraphCast (for weather prediction).2 Many academics use these terms to describe the study of the underlying mathematical and programming ideas on which such products are built.\nMy goal is not to give you a single definition of any of these terms and then to argue that my definition is more correct than any other definition. The point I want to make is that it’s worth being clear about how we define these terms in any given context, whether it be in a textbook, a news article, or perhaps a spirited discussion between friends. To that end, I now want to make clear what it is that we will and will not cover in this class, which is a “foundations”-level course in the College of Engineering’s AI minor.\nThe focus of this class will be the mathematical and programming foundations of scientific machine learning, which I define as the study of algorithms which use scientific data to define computational tools that perform useful scientific tasks. The main scientific task that we will focus on in this course is the task of predictive simulation, which seeks to predict the behavior or outcomes of scientific or engineering systems. Predictive simulation is a key task in engineering disciplines like design and control, where we seek to predict design outcomes and control responses in order to make decisions about design parameters and control inputs. The class of machine learning methods that we will focus on in this class will therefore be regression methods, which use data to define relationships between inputs and outputs that allow us to take a specified input and issue a prediction for the output.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#a-motivating-example",
    "href": "01_intro.html#a-motivating-example",
    "title": "1  Introduction",
    "section": "",
    "text": "The angle of attack (\\(\\alpha\\)), measured in degrees\nThe density of the fluid (\\(\\rho\\)), measured in \\(kg/m^3\\)\nThe velocity of the fluid (\\(v\\)), measured in \\(m/s\\)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#linear-approximation-of-an-unknown-function",
    "href": "01_intro.html#linear-approximation-of-an-unknown-function",
    "title": "1  Introduction",
    "section": "1.2 Linear Approximation of an Unknown Function",
    "text": "1.2 Linear Approximation of an Unknown Function\nLet’s bundle our inputs into a single vector, defined by:\n\\[ \\mathbf{x} = \\begin{bmatrix} \\alpha \\\\ \\rho \\\\ v\\end{bmatrix} \\]\nWe assume there is some unknown function, \\(f(\\cdot):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\), that gives us an optimal estimate for drag-force based on these “features”:\n\\[ F_d = f (\\mathbf{x}) + \\varepsilon \\]\nwhere \\(\\varepsilon\\) is some external noise, disturbances or information entirely independent of the input variables.\nNow consider a function \\(h(\\mathbf{x}; \\beta):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\) which is a simple linear combination of the inputs:\n\\[ h(\\mathbf{x}; \\beta) = \\begin{bmatrix} 1 & \\mathbf{x}^\\top \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3  \\end{bmatrix} = \\beta_0 + \\beta_1 \\alpha + \\beta_2 \\rho + \\beta_3 v \\]\nThe Million Dollar Question:\nGiven we know the structure of \\(h(\\mathbf{x}; \\beta)\\), how can we efficiently optimize the parameters of \\(h(\\mathbf{x}; \\beta)\\) to best approximate \\(f(\\mathbf{x})\\)?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#representing-observed-input-output-data",
    "href": "01_intro.html#representing-observed-input-output-data",
    "title": "1  Introduction",
    "section": "1.2 Representing Observed Input-Output Data",
    "text": "1.2 Representing Observed Input-Output Data\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#the-least-squares-optimization-problem",
    "href": "01_intro.html#the-least-squares-optimization-problem",
    "title": "1  Introduction",
    "section": "1.3 The Least-Squares Optimization Problem",
    "text": "1.3 The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#solving-the-least-squares-problem",
    "href": "01_intro.html#solving-the-least-squares-problem",
    "title": "1  Introduction",
    "section": "1.4 Solving the Least-Squares Problem",
    "text": "1.4 Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#experimental-example",
    "href": "01_intro.html#experimental-example",
    "title": "1  Introduction",
    "section": "1.5 Experimental Example",
    "text": "1.5 Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#using-nonlinear-features-to-improve-model-performance",
    "href": "01_intro.html#using-nonlinear-features-to-improve-model-performance",
    "title": "1  Introduction",
    "section": "1.6 Using Nonlinear Features to Improve Model Performance",
    "text": "1.6 Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "11_ls.html",
    "href": "11_ls.html",
    "title": "ML for AE: Least Squares Regression",
    "section": "",
    "text": "A Motivating Example\nSuppose we wish to efficiently approximate the force of drag (\\(F_d\\)), measured in \\(N\\), on a specific airplane wing if we only have access to the following information about the wing and its operating conditions:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ML for AE: Least Squares Regression</span>"
    ]
  },
  {
    "objectID": "11_ls.html#a-motivating-example",
    "href": "11_ls.html#a-motivating-example",
    "title": "2  Linear Regression Problems",
    "section": "2.2 A Motivating Example",
    "text": "2.2 A Motivating Example\n\n\n\nImage Source: Embry-Riddle Aeronautical University\n\n\nSuppose we wish to efficiently approximate the force of drag (\\(F_d\\)), measured in \\(N\\), on a specific airplane wing if we only have access to the following information about the wing and its operating conditions:\n\nThe angle of attack (\\(\\alpha\\)), measured in degrees\nThe density of the fluid (\\(\\rho\\)), measured in \\(kg/m^3\\)\nThe velocity of the fluid (\\(v\\)), measured in \\(m/s\\)"
  },
  {
    "objectID": "11_ls.html#linear-approximation-of-an-unknown-function",
    "href": "11_ls.html#linear-approximation-of-an-unknown-function",
    "title": "2  Linear Regression Problems",
    "section": "2.3 Linear Approximation of an Unknown Function",
    "text": "2.3 Linear Approximation of an Unknown Function\nLet’s bundle our inputs into a single vector, defined by:\n\\[ \\mathbf{x} = \\begin{bmatrix} \\alpha \\\\ \\rho \\\\ v\\end{bmatrix} \\]\nWe assume there is some unknown function, \\(f(\\cdot):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\), that gives us an optimal estimate for drag-force based on these “features”:\n\\[ F_d = f (\\mathbf{x}) + \\varepsilon \\]\nwhere \\(\\varepsilon\\) is some external noise, disturbances or information entirely independent of the input variables.\nNow consider a function \\(h(\\mathbf{x}; \\beta):\\mathbb{R}^3 \\rightarrow \\mathbb{R}\\) which is a simple linear combination of the inputs:\n\\[ h(\\mathbf{x}; \\beta) = \\begin{bmatrix} 1 & \\mathbf{x}^\\top \\end{bmatrix} \\begin{bmatrix}  \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3  \\end{bmatrix} = \\beta_0 + \\beta_1 \\alpha + \\beta_2 \\rho + \\beta_3 v \\]\nThe Million Dollar Question:\nGiven we know the structure of \\(h(\\mathbf{x}; \\beta)\\), how can we efficiently optimize the parameters of \\(h(\\mathbf{x}; \\beta)\\) to best approximate \\(f(\\mathbf{x})\\)?"
  },
  {
    "objectID": "11_ls.html#representing-observed-input-output-data",
    "href": "11_ls.html#representing-observed-input-output-data",
    "title": "2  Linear Regression Problems",
    "section": "2.7 Representing Observed Input-Output Data",
    "text": "2.7 Representing Observed Input-Output Data\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]"
  },
  {
    "objectID": "11_ls.html#the-least-squares-optimization-problem",
    "href": "11_ls.html#the-least-squares-optimization-problem",
    "title": "2  Linear Regression Problems",
    "section": "2.8 The Least-Squares Optimization Problem",
    "text": "2.8 The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]"
  },
  {
    "objectID": "11_ls.html#solving-the-least-squares-problem",
    "href": "11_ls.html#solving-the-least-squares-problem",
    "title": "2  Linear Regression Problems",
    "section": "2.9 Solving the Least-Squares Problem",
    "text": "2.9 Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum."
  },
  {
    "objectID": "11_ls.html#experimental-example",
    "href": "11_ls.html#experimental-example",
    "title": "2  Linear Regression Problems",
    "section": "2.10 Experimental Example",
    "text": "2.10 Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47"
  },
  {
    "objectID": "11_ls.html#using-nonlinear-features-to-improve-model-performance",
    "href": "11_ls.html#using-nonlinear-features-to-improve-model-performance",
    "title": "2  Linear Regression Problems",
    "section": "2.11 Using Nonlinear Features to Improve Model Performance",
    "text": "2.11 Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions."
  },
  {
    "objectID": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-and-data-science",
    "href": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-and-data-science",
    "title": "1  Introduction",
    "section": "1.1 What’s in a name? Artificial intelligence, machine learning, and data science",
    "text": "1.1 What’s in a name? Artificial intelligence, machine learning, and data science\nI googled “artificial intelligence” (often abbreviated AI) and the first result comes from Google’s new “AI overview” feature1: \nBecause I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer: \nThese are probably both reasonable definitions for casual conversation, but that’s not what we’re here for. Instead, we’re here to really learn deeply about what AI is, and for that we’re going to need precision – that is, of our definitions.\n\n\n\n\n\n\nExercise\n\n\n\nConsider the two different definitions of “AI” above carefully. In what (if any) senses are they (a) exactly the same, (b) similar, (c) somewhat different, (d) very different? What consequences might these differences have (a) developing AI algorithms, (b) evaluating AI impacts, (c) creating AI policies?\n\n\nI’m not going to provide a definition of AI for now and instead I’m going to throw two more terms into the mix that you may have heard. The first is “machine learning” (often abbreviated ML). Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition (Merriam-Webster Dictionary 2024):\n\na computational method that is a subfield of artificial intelligence and that enables a computer to learn to perform tasks by analyzing a large dataset without being explicitly programmed\n\nAnd finally I’ll add the term “data science” (curiously, rarely abbreviated DS). I wanted to give you a Merriam-Webster definition here, but the term isn’t in their dictionary as of writing this on October 28, 2024. So instead I’m going to use Cambridge Dictionary’s definition (Cambridge Dictionary 2024):\n\nthe use of scientific methods to obtain useful information from computer data, especially large amounts of data\n\n\n\n\n\n\n\nExercise\n\n\n\nFor both the terms “machine learning” and “data science”, find an alternative definition from a source that is not a generative AI. What differences exist between the new definitions you’ve found and the ones I’ve cited above?\n\n\nClearly, different people/entities may have different ideas of what AI, ML, and data science may mean. Some people may use these terms to describe generative tools like ChatGPT, GitHub copilot, and Dall-E (or similar products developed by other entities). Others use these terms to refer to more purpose-built algorithms like AlphaGo (for playing Go) or GraphCast (for weather prediction).2 Many academics use these terms to describe the study of the underlying mathematical and programming ideas on which such products are built.\nMy goal is not to give you a single definition of any of these terms and then to argue that my definition is more correct than any other definition. The point I want to make is that it’s worth being clear about how we define these terms in any given context, whether it be in a textbook, a news article, or perhaps a spirited discussion between friends. To that end, I now want to make clear what it is that we will and will not cover in this class, which is a “foundations”-level course in the College of Engineering’s AI minor.\nThe focus of this class will be the mathematical and programming foundations of scientific machine learning, which I define as the study of algorithms which use scientific data to define computational tools that perform useful scientific tasks. In particular, the focus of this class is going to be on regression problems and their solutions, which describes the age-old problem of predicting numerical outputs from numerical inputs. Regression problems\nInstead, I want you to notice some key commonalities in the definitions above (of all three terms): the first is the data seems to be important for all\nsome remarks about what these things mean to different people, some links to further reading, narrow focus to supervised learning\n\n1.1.1 Regression\nproblem of predicting outputs from inputs\nformulation as selection from within a parametrized model class\nchoosing parameters via optimization\n\n\n1.1.2 Things that are not regression\nGive one example, list other examples, I cannot possibly hope to cover all these things in this course, so another goal of the course is to teach the language of ML so you are prepared to learn other things in future courses and on your own."
  },
  {
    "objectID": "01_intro.html#the-three-pillars-of-ai-mathematics-computation-and-human-intelligence",
    "href": "01_intro.html#the-three-pillars-of-ai-mathematics-computation-and-human-intelligence",
    "title": "1  Introduction",
    "section": "1.4 The three pillars of AI: mathematics, computation, and human intelligence",
    "text": "1.4 The three pillars of AI: mathematics, computation, and human intelligence\nmathematics is the language that describes what we want to do\ncomputation/programming is the execution (translation)\nhuman intelligence is woven throughout, specifies problem, evaluates results, re-specifies problem.\n\n1.4.1 Course structure and intended learning outcomes\nfill in nearer to term\n\n\n\n\n\nCambridge Dictionary. 2024. “Data Science.” 2024. https://dictionary.cambridge.org/dictionary/english/data-science.\n\n\nMerriam-Webster Dictionary. 2024. “Machine Learning.” 2024. https://www.merriam-webster.com/dictionary/machine%20learning.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01_intro.html#footnotes",
    "href": "01_intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "It seems apt to use AI to define AI, and I’m quoting it for illustrative purposes here, but I do want to point out that Google’s AI Overview is not at all transparent about how these responses are generated and thus does not meet the standards for being cited as a source in most publishing venues.↩︎\nthis paragraph lists examples that came to me most quickly and thus reflects to some extent my own cognitive biases based on the media I’ve consumed. I welcome suggestions of other examples of AI/ML/data science to include that are less well-known – Email me!↩︎\nFollowing the same notational convention, we could write the data set as \\(\\{(z_i,y_i) : i =1,\\ldots,N\\}\\), which we would read as the set of all pairs \\((z_i,y_i)\\) for \\(i = 1,\\ldots,N\\), but the notation \\(\\{(z_i,y_i)\\}_{i=1}^N\\) is more compact and more common. I don’t make the rules. 🤷‍♀️↩︎\nThese are common conventions, but the ML community is comprised of a diverse group of scientists and engineers across disciplines, and it’s very common to read things that use entirely different notation. This is unfortunately the reality of things, and one of the reasons I am going to push you in this class to be comfortable describing the underlying concepts precisely using different notations - that is, you are going to develop flexibility in re-assigning meaning to different symbols as we go along (I hope).↩︎\nI’m making an effort to explicitly define notation when I introduce it, and to give examples of how to read and understand it, but it’s easy for me to miss things, so please speak up or write us a message if you have a question.↩︎"
  },
  {
    "objectID": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-data-science-and-the-scope-of-this-course.",
    "href": "01_intro.html#whats-in-a-name-artificial-intelligence-machine-learning-data-science-and-the-scope-of-this-course.",
    "title": "1  Introduction",
    "section": "1.1 What’s in a name? Artificial intelligence, machine learning, data science, and the scope of this course.",
    "text": "1.1 What’s in a name? Artificial intelligence, machine learning, data science, and the scope of this course.\nI googled “artificial intelligence” (often abbreviated AI) and the first result comes from Google’s new “AI overview” feature1: \nBecause I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer: \nThese are probably both reasonable definitions for casual conversation, but that’s not what we’re here for. Instead, we’re here to really learn deeply about what AI is, and for that we’re going to need precision – that is, of our definitions.\n\n\n\n\n\n\nExercise\n\n\n\nConsider the two different definitions of “AI” above carefully. In what (if any) senses are they (a) exactly the same, (b) similar, (c) somewhat different, (d) very different? What consequences might these differences have (a) developing AI algorithms, (b) evaluating AI impacts, (c) creating AI policies?\n\n\nI’m not going to provide a definition of AI for now and instead I’m going to throw two more terms into the mix that you may have heard. The first is “machine learning” (often abbreviated ML). Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition (Merriam-Webster Dictionary 2024):\n\na computational method that is a subfield of artificial intelligence and that enables a computer to learn to perform tasks by analyzing a large dataset without being explicitly programmed\n\nAnd finally I’ll add the term “data science” (curiously, rarely abbreviated DS). I wanted to give you a Merriam-Webster definition here, but the term isn’t in their dictionary as of writing this on October 28, 2024. So instead I’m going to use Cambridge Dictionary’s definition (Cambridge Dictionary 2024):\n\nthe use of scientific methods to obtain useful information from computer data, especially large amounts of data\n\n\n\n\n\n\n\nExercise\n\n\n\nFor both the terms “machine learning” and “data science”, find an alternative definition from a source that is not a generative AI. What differences exist between the new definitions you’ve found and the ones I’ve cited above?\n\n\nClearly, different people/entities may have different ideas of what AI, ML, and data science may mean. Some people may use these terms to describe generative tools like ChatGPT, GitHub copilot, and Dall-E (or similar products developed by other entities). Others use these terms to refer to more purpose-built algorithms like AlphaGo (for playing Go) or GraphCast (for weather prediction).2 Many academics use these terms to describe the study of the underlying mathematical and programming ideas on which such products are built.\nMy goal is not to give you a single definition of any of these terms and then to argue that my definition is more correct than any other definition. The point I want to make is that it’s worth being clear about how we define these terms in any given context, whether it be in a textbook, a news article, or perhaps a spirited discussion between friends. To that end, I now want to make clear what it is that we will and will not cover in this class, which is a “foundations”-level course in the College of Engineering’s AI minor.\nThe focus of this class will be the mathematical and programming foundations of scientific machine learning, which I define as the study of algorithms which use scientific data to define computational tools that perform useful scientific tasks. The main scientific task that we will focus on in this course is the task of predictive simulation, which seeks to predict the behavior or outcomes of scientific or engineering systems. Predictive simulation is a key task in engineering disciplines like design and control, where we seek to predict design outcomes and control responses in order to make decisions about design parameters and control inputs. The class of machine learning methods that we will focus on in this class will therefore be regression methods, which use data to define relationships between inputs and outputs that allow us to take a specified input and issue a prediction for the output."
  },
  {
    "objectID": "01_intro.html#regression-methods-an-overview",
    "href": "01_intro.html#regression-methods-an-overview",
    "title": "1  Introduction",
    "section": "1.2 Regression methods: an overview",
    "text": "1.2 Regression methods: an overview\n\n1.2.1 Motivation and problem description\nWe use the notation \\(z\\in \\mathbb{R}^d\\) to denote a real-valued vector of \\(d\\) input variables, and the notation \\(y \\in\\mathbb{R}\\) to denote a real-valued scalar output variable. Our goal is to be able to predict the value of \\(y\\) if we know the value(s) of the input variable \\(z\\). Some examples:\n\nin aerodynamic modeling, \\(z\\) could contain airfoil geometry parameters like camber and thickness, and \\(y\\) could represent the lift coefficient. Being able to predict \\(y\\) from \\(z\\) enables engineers to choose more aerodynamically efficient designs.\nin orbital dynamics, \\(z\\) could represent orbital parameters like altitude and inclination, and \\(y\\) could represent the total time a satellite spends outside the sun’s shadow in a given time period. Being able to predict \\(y\\) from \\(z\\) enables engineers to determine if a satellite’s solar panels will generate enough power to support the satellite’s mission.\nin chemical process engineering, \\(z\\) could represent conditions within a reactor like temperature and chemical mixture properties and \\(y\\) could represent the reaction rate. Being able to predict \\(y\\) from \\(z\\) enables engineers to design more efficient reactors.\n\n\n\n\n\n\n\nExercise\n\n\n\nPropose your own example scenario where it would be useful to predict real-valued outputs from inputs, drawing on your own experience, e.g. in personal projects, previous coursework, work/internship/co-op experiences, or extracurriculars. What would \\(z\\) and \\(y\\) represent? What does predicting \\(y\\) from \\(z\\) enable in your scenario?\n\n\nMathematically, predicting \\(y\\) from \\(z\\) amounts to defining a function \\(f\\) that takes in a \\(d\\)-dimensional input and outputs a scalar. Mathematical notational shorthand for this is \\(f:\\mathbb{R}^d\\to\\mathbb{R}\\). This function \\(f\\) is often called a model. The question at hand is: how do we choose \\(f\\)? There are many ways to do so:\n\nAt a baseline, you could just make up a model: let’s just say \\(y = f(z) = \\|z\\|^2\\). This is mathematically valid, but it’s probably a bad model for the three example scenarios above, because this model probably issues predictions that are very different from the true outputs.\nAlternatively, you could develop a model based on physical principles (a “physics-based” model) – if you have taken classes in (aero/thermo)dynamics, then you would have learned some ways to calculate \\(y\\) from \\(z\\) in the above examples, e.g. based on potential flow theory, rigid body dynamics, or the Arrhenius equation. These models are likely to be more accurate than our made-up model above, although they are often imperfectly accurate because they make simplifying assumptions. One drawback of physics-based models is that they may be computationally expensive (some computational fluid dynamics simulations require many thousands of hours of supercomputing time). Additionally, fully physics-based models may not even exist in some applications (e.g., there are many aspects of plasma physics for which we currently lack a complete theoretical understanding).\nFinally, our focus will be on using data to define a model (a “data-driven” model or a “learned” model). We assume that we have a data set consisting of \\(N\\) pairs of input and output data, \\((z_i,y_i)\\) for \\(i = 1,\\ldots,N\\). To define our model, we want to choose an \\(f\\) so that the predicted output \\(f(z_i)\\) is close to the output data \\(y_i\\) for all the data in our data set. This is sometimes called “fitting” the model to data. The advantages of data-driven models are that they may be significantly cheaper than physics-based models, and they can be fit to experimental data even when we lack scientific theory for developing physics-based models. The disadvantages are that data-driven models require data – and the amount of data that would be “enough” to ensure that the learned model is accurate or useful is highly dependent on the application.\n\nLearning how to fit models to data and assess their accuracy and usefulness is the focus of this course.\n\n\n1.2.2 Mathematical setting and problem formulation\nHot take: Machine learning methods, at their core, are simply very complicated calculators.\nOur goal is to understand the calculations that these methods are carrying out, which is going to enable us to understand and assess both the successes and failures of the methods. This means we want to be precise about the mathematical problem formulation, that is, the characterization of the math problem that is being solved by the methods.\nFormulating a regression problem requires three ingredients:\n\nPaired input and output data: let \\(N\\) be the number of pairs, and let \\(z_1,\\ldots,z_N\\) denote the \\(N\\) input data and \\(y_1,\\ldots,y_N\\) denote the \\(N\\) corresponding outputs. It is common to notate the set of all these data pairs as \\(\\{(z_i,y_i)\\}_{i=1}^N\\).\nThe definition of a parametrized model class – more details on this in a moment, but you should think of this as a set of possible functions that map \\(z\\) to \\(y\\).\nA method for choosing a model from within the chosen model class – in regression problems this is most frequently done by solving an appropriate optimization problem to pick the “best” possible model from within the class.\n\nLet’s focus on the second ingredient, the parametrized model class. We use the mathematical term “class” in a similar way to the mathematical term “set”. For example, perhaps you will have heard before that the numbers \\(1,2,3,\\ldots\\) all the way to infinity form the “set of natural numbers” (often denoted \\(\\mathbb{N}\\)). As another example, \\(\\{H,T\\}\\) can denote the set of possible outcomes of flipping a two-sided coin (H for heads, T for tails). Note that it is common to use curly braces \\(\\{\\cdot\\}\\) to enclose a set (notice where it appears in our shorthand notation for the data set!). Similarly, we can define a set of possible functions that map \\(z\\) to \\(y\\), for example (assuming \\(d=1\\) so that \\(z\\) is a scalar for the moment):\n\\[\n\\mathcal{F}:= \\{z^2, \\sin(z), \\exp(z)\\}\n\\]\nIn the above expression, the notation \\(:=\\) indicates that \\(\\mathcal{F}\\) is being defined as the expression that follows \\(:=\\), that is, \\(\\mathcal{F}\\) is the set of three possible functions: \\(f(z)=z^2\\), \\(f(z)=\\sin(z)\\), and \\(f(z)=\\exp(z)\\). You see that it might be cumbersome to write the “\\(f(z)=\\)” part of every function, so that part often gets dropped.\nBut so far I have still only been saying “set” — what distinguishes a “class” of potential models from a “set” of potential models? Usually we use the term “class” to denote a set of functions that share certain properties or functional forms, for example (still assuming \\(z\\) is scalar for the moment) the class of all quadratic functions:\n\\[\n\\{c_0 + c_1 z + c_2 z^2 : c_0,c_1,c_2\\in\\mathbb{R}\\}\n\\qquad(1.1)\\]\nThe way to read this notation above is as the set of all functions of the form \\(f(z) = c_0 + c_1 z + c_2 z^2\\) that can be obtained when \\(c_0,c_1,c_2\\) are allowed to take on any real values.3 We call this the class of all quadratic functions because by varying \\(c_0,c_1,c_2\\) we always get a quadratic function (noting that with our mathematics hats on, linear functions are just special cases of quadratic functions where the second-order coefficient is zero). Thus, functions within the class share a functional form, unlike the set \\(\\mathcal{F}\\) we defined above. However, we could use the functions in the set \\(\\mathcal{F}\\) to construct an alternative model class:\n\\[\n\\{a z^2 + b\\sin(z) + c\\exp(z) : a,b,c\\in\\mathbb{R}\\}\n\\qquad(1.2)\\]\nor, allowing \\(z\\) to be a \\(d\\)-dimensional vector again, we could consider the following model class:\n\\[\n\\{\\max(0,a^\\top (Wz + b)): W\\in\\mathbb{R}^{d\\times d}, \\,a,b\\in\\mathbb{R}^d\\}\n\\qquad(1.3)\\]\n\n\n\n\n\n\nExercise\n\n\n\nHow would you read and understand the two classes of functions notated above?\n\n\nNotice that the notation we have been using to define function classes follows a pattern: within the brackets, before the colon comes the form of the function, followed by a list of some variables that appear in the function definition, together with a specification of what values those variables are allowed to take on. We call the post-colon variables parameters, and the set of all values that the parameters are allowed to be chosen from is called the parameter space. Any of the classes of functions we have defined above can be described as a parametrized model class, because they define sets of functions with a shared form, where the individual functions within the set arise from varying the values of the parameters.\nLet me describe some common notational conventions that I want you to be familiar with.45 It is common to use a single lowercase letter (usually a Greek one) to denote the set of all parameters – e.g., \\(\\beta = \\{c_0,c_1,c_2\\}\\) or \\(\\theta = \\{a,b,W\\}\\), and the corresponding capital letter to denote the corresponding parameter space, i.e., \\(B = \\mathbb{R}^3\\) and \\(\\Theta = \\mathbb{R}\\times \\mathbb{R}\\times \\mathbb{R}^{d\\times d}\\). Where we might write \\(y = f(z)\\) for a general abstract model \\(f\\), we will typically write \\(y = f(z;\\beta)\\) or \\(y = f(z;\\theta)\\) to indicate a model parametrized by \\(\\beta\\) or \\(\\theta\\) (note that we separate inputs from parameters using a semicolon).\n\nIf you’ve heard the term “model architecture” used to describe a machine learning model, what this means is the specification of the parametrized model class. As the term “architecture” suggests, choosing the model class is a design choice, and different model classes have varying advantages and disadvantages in terms of best possible performance, difficulty to train (more on that shortly), computational cost, and more. We’ll cover many possible choices of model class, and explore their pros and cons, throughout the course.\nNow we will turn our attention to the third ingredient, the method of selecting a model from within the chosen class. Because parametrized models are defined by their parameters, the choice of model amounts to choosing the parameter values. Again, you could just make up the parameter values (choose your favorite numbers), but this is unlikely to match the data well and unlikely to yield accurate predictions. In some cases you could also derive the parameter values based on physical principles (this is possible when models in the chosen class have some physical interpretation). But our focus will be on choosing parameters that define a model that “best matches” the available data. A basic and standard version of this parameter selection task is to solve the following minimization problem:\n\\[\n\\theta^* = \\arg\\min_{\\theta\\in\\Theta}\\frac 1N \\sum_{i=1}^N (f(z_i;\\theta)-y_i)^2\n\\]\nNote that for the above expression to be well-defined, we need our first two ingredients – that is, we need our data set, and we need to have already chosen the parametrized model class, which gives us an expression for the parametrized function \\(f(z;\\theta)\\). Once we have those ingredients, this expression defines \\(\\theta^*\\) as the parameter that minimizes the average square error of the learned model over the available data. In this sense, this parameter \\(\\theta^*\\) defines a learned model \\(f(z;\\theta^*)\\) that “best fits” the data (it is better than all other models in its class).\nAs we progress through this course, we will learn more about how we can solve the above optimization (it is different for different model architectures), and about alternative ways to select the parameter based on alternative minimization problems."
  },
  {
    "objectID": "01_intro.html#things-that-are-not-regression",
    "href": "01_intro.html#things-that-are-not-regression",
    "title": "1  Introduction",
    "section": "1.3 Things that are not regression",
    "text": "1.3 Things that are not regression\nI want to emphasize that this class is not and indeed cannot (realistically) be an exhaustive introduction to machine learning, artificial intelligence, or data science. Even the community of professionals who describe themselves as working in “scientific machine learning” is quite broad in scope and would include folks working on topics that I do not intend to cover in this class. There are many topics within AI/ML/data science we will not cover (beyond perhaps at most a very surface level), including generative modeling, decision trees, unsupervised learning methods like clustering, and many more.\nGive one example, list other examples, I cannot possibly hope to cover all these things in this course, so another goal of the course is to teach the language of ML so you are prepared to learn other things in future courses and on your own."
  },
  {
    "objectID": "01_intro.html#course-principles-structure-and-intended-learning-outcomes",
    "href": "01_intro.html#course-principles-structure-and-intended-learning-outcomes",
    "title": "1  Introduction",
    "section": "1.4 Course principles, structure, and intended learning outcomes",
    "text": "1.4 Course principles, structure, and intended learning outcomes\nThe three pillars of AI: mathematics, computation, and human intelligence\nmathematics is the language that describes what we want to do\ncomputation/programming is the execution (translation)\nhuman intelligence is woven throughout, specifies problem, evaluates results, re-specifies problem.\nat a high level we want to teach you how to work with all three of these, and that motivates the structure of the course assignments and learning outcomes\nlearning outcomes\nproblem solving review - meant to develop your skills in demonstrating human intelligence\n\n\n\n\nCambridge Dictionary. 2024. “Data Science.” 2024. https://dictionary.cambridge.org/dictionary/english/data-science.\n\n\nMerriam-Webster Dictionary. 2024. “Machine Learning.” 2024. https://www.merriam-webster.com/dictionary/machine%20learning."
  },
  {
    "objectID": "01_intro.html#a-foundation-for-learning-about-ml-beyond-parametrized-regression",
    "href": "01_intro.html#a-foundation-for-learning-about-ml-beyond-parametrized-regression",
    "title": "1  Introduction",
    "section": "1.3 A foundation for learning about ML beyond parametrized regression",
    "text": "1.3 A foundation for learning about ML beyond parametrized regression\nI want to emphasize that this class is not and indeed cannot (realistically) be an exhaustive introduction to machine learning, artificial intelligence, or data science. Even the community of professionals who describe themselves as working in “scientific machine learning” is quite broad in scope and would include folks working on topics that I do not intend to cover in this class. There are many topics within AI/ML/data science we will not cover (beyond perhaps at most a very surface level), including generative modeling, decision trees, unsupervised learning methods like clustering, and many more. The philosophy of this course is to empower you to learn about these other methods through future coursework or independent study, by providing a foundation in what I term the `three pillars of artificial intelligence’:\n\nMathematics: all machine learning methods are fundamentally solving mathematical problems at their core. The first pillar of AI is to be able to mathematically define the problem one seeks to solve.\nComputation: once a mathematical problem is defined, an ML method must define an algorithm that carries out the calculations to solve the problem. The second pillar of AI is to define an algorithm that (approximately) solves the mathematical problem.\nHuman intelligence: this is the crucial third pillar of AI. Human intelligence is vital for defining mathematical problem formulations, designing algorithms, and assessing the results and iteratively updating the mathematical problem formulation and computational algorithm to achieve desired outcomes.\n\nWe will seek to develop a firm foundation in these three pillars of AI throughout the course."
  },
  {
    "objectID": "01_intro.html#course-structure-and-intended-learning-outcomes",
    "href": "01_intro.html#course-structure-and-intended-learning-outcomes",
    "title": "1  Introduction",
    "section": "1.4 Course structure and intended learning outcomes",
    "text": "1.4 Course structure and intended learning outcomes\n\nlearning outcomes\nproblem solving review - meant to develop your skills in demonstrating human intelligence\n\n\n\n\nCambridge Dictionary. 2024. “Data Science.” 2024. https://dictionary.cambridge.org/dictionary/english/data-science.\n\n\nMerriam-Webster Dictionary. 2024. “Machine Learning.” 2024. https://www.merriam-webster.com/dictionary/machine%20learning."
  },
  {
    "objectID": "11_ls.html#problem-formulation",
    "href": "11_ls.html#problem-formulation",
    "title": "2  Linear Regression Problems",
    "section": "Problem formulation",
    "text": "Problem formulation"
  },
  {
    "objectID": "11_ls.html#mathematical-problem-formulation",
    "href": "11_ls.html#mathematical-problem-formulation",
    "title": "2  Linear Least Squares Problems",
    "section": "2.2 Mathematical problem formulation",
    "text": "2.2 Mathematical problem formulation\nWe are now going to introduce an abstract mathematical problem formulation that can be used to describe many specific instances of linear regression problems. This is a theme of the course and throughout computational mathematics and engineering: abstraction using the language of mathematics lets us isolate the core essence of the problem we’re solving and develop powerful algorithms that can solve specific applications of those problems across a wide range of disciplines. I’ll introduce the abstract formulation first, and follow it up with some specific examples.\nIngredient 1 (the data set): let \\(\\{(z_i,y_i)\\}_{i=1}^N\\) be a given data set of paired inputs \\(z_i\\in\\mathbb{R}^d\\) and outputs \\(y_i\\in\\mathbb{R}\\).\nIngredient 2 (the parametrized model class): let \\(x:\\mathbb{R}^d\\to\\mathbb{R}^n\\) be a function that maps the \\(d\\)-dimensional input to an \\(n\\)-dimensional feature vector. For a fixed \\(x\\), we will consider the following parametrized model class:\n\\[\n\\mathcal{F}_\\beta := \\{ x(z)^\\top \\beta : \\beta\\in\\mathbb{R}^n\\}\n\\qquad(2.1)\\]\nRecall that Equation 2.1 is read as “\\(\\mathcal{F}_\\beta\\) is defined to be the set of all functions \\(f(z;\\beta) = x(z)^\\top\\beta\\) for all \\(\\beta\\in\\mathbb{R}^n\\).” This is an abstract way to define the model class for any linear regression problem, as we will describe in more detail shortly.\nIngredient 3 (the method of choosing the parameters): let \\(\\beta^*\\) be given by\n\\[\n\\begin{aligned}\n\\beta^* &= \\arg\\min_{\\beta\\in\\mathbb{R}^n} \\frac1N \\sum_{i=1}^N (f(z_i;\\beta) - y_i)^2 \\\\\n&= \\arg\\min_{\\beta\\in\\mathbb{R}^N} \\frac1N \\sum_{i=1}^N (x(z_i)^\\top\\beta - y_i)^2.\n\\end{aligned}\n\\qquad(2.2)\\] Then, we define the learned model to be \\(f(z;\\beta^*) = x(z)^\\top\\beta^*\\). We call \\(\\beta^*\\) defined this way the “optimal regression parameters” or just the “optimal parameters”, because they are the result of solving an optimization problem. Note that the objective of this optimization function is defined by the data, and represents the average squared error of the model over the data set.\nTaken together, the three ingredients I have defined above define a linear least squares problem, which is a subclass of linear regression problems. We’ll now give several examples of specific instances of linear least squares problems to illustrate how broadly applicable this abstract framework is."
  },
  {
    "objectID": "11_ls.html#examples",
    "href": "11_ls.html#examples",
    "title": "2  Linear Least Squares Problems",
    "section": "2.3 Examples",
    "text": "2.3 Examples\n\n2.3.1 Example 1: Aerodynamic drag prediction\n\n\n\nImage Source: Embry-Riddle Aeronautical University\n\n\nAn important task in aerodynamic design is predicting lift and drag forces on a body moving through air. Let’s consider a simplified problem where we are given an fixed airfoil design and our goal is to predict the drag force \\(F_d\\) on the airfoil as a function of three parameters which describe its flight conditions:\n\nThe angle of attack \\(\\alpha\\)\nThe density of the fluid \\(\\rho\\)\nThe freestream velocity of the air \\(v\\)\n\nTo put this problem in our abstract framework, we define \\(z = (\\alpha,\\rho,v)^\\top\\) to be a three-dimensional input, and take the output to be the drag force \\(y= F_d\\). In order to define a regression problem, we require the existence of a data set \\(\\{(z_i,y_i)\\}_{i=1}^N\\). Note that in this case \\(z_i = (\\alpha_i,\\rho_i,v_i)\\). We assume that this data set is given.\nIn linear regression problems, defining the model class amounts to choosing a set of regression features by defining \\(x\\). A simple choice takes the inputs themselves to be features: \\(x^{(1)}(z) = z = (\\alpha,\\rho,v)^\\top\\). This leads to a class of parametrized models with a three-dimensional unknown parameter vector \\(\\beta\\in\\mathbb{R}^3\\). The models in this class have the following form:\n\\[\nf^{(1)}(z;\\beta) = x^{(1)}(z)^\\top\\beta = (\\alpha,\\rho,v) \\beta = \\beta_1\\alpha + \\beta_2\\rho + \\beta_3 v.\n\\]\nThere are many other possible choices. For example, consider \\(x^{(2)}(z) = (\\alpha,\\rho, v, \\alpha^2, \\rho^2, v^2, \\alpha\\rho, \\alpha v, \\rho v)^\\top\\). This leads to a parametrized model class with a nine-dimensional unknown parameter vector \\(\\beta\\in\\mathbb{R}^9\\):\n\\[\n\\begin{aligned}\nf^{(2)}(z;\\beta) &= x^{(2)}(z)^\\top\\beta = (\\alpha,\\rho, v, \\alpha^2, \\rho^2, v^2, \\alpha\\rho, \\alpha v, \\rho v)\\beta \\\\\n&= \\beta_1\\alpha + \\beta_2\\rho + \\beta_3 v + \\beta_4\\alpha^2 + \\beta_5\\rho^2 + \\beta_6 v^2 + \\beta_7\\alpha\\rho + \\beta_8\\alpha v + \\beta_9 \\rho v\n\\end{aligned}\n\\]\nFor either the above choices of features \\(x^{(1)}(z)\\) or \\(x^{(2)}(z)\\), we could then define and solve the minimization Equation 2.2 to find the optimal regression parameters and define our learned model \\(f^{(1)}(z;\\beta^*)\\) or \\(f^{(2)}(z;\\beta^*)\\).\n\n\n\n\n\n\nUnderstanding notation\n\n\n\nNote that we use \\(\\beta\\) to denote the unknown parameters in both \\(f^{(1)}\\) and \\(f^{(2)}\\) above despite \\(\\beta\\) referring to different quantities in the definition of the different functions. This is a common notational shortcut — while we could use the notation \\(\\beta^{(1)}\\in\\mathbb{R}^3\\) and \\(\\beta^{(2)}\\in\\mathbb{R}^9\\) to specify the different \\(\\beta\\) for the different functions, this can be cumbersome if we are considering many different options for the choice of features \\(x(z)\\), and it’s standard to just use \\(\\beta\\), where the definition of \\(\\beta\\) is implied by the context. One of the challenges in learning about machine learning and computational mathematics more generally is getting used to similar notation meaning different things in different contexts. That’s one of the things that we’ll practice in this course.\n\n\n\n\n2.3.2 Example 2: something else\n\n\n2.3.3 Example 3: something else"
  },
  {
    "objectID": "11_ls.html#example-1-aerodynamic-drag-prediction",
    "href": "11_ls.html#example-1-aerodynamic-drag-prediction",
    "title": "2  Linear Least Squares Problems",
    "section": "2.3 Example 1: Aerodynamic drag prediction",
    "text": "2.3 Example 1: Aerodynamic drag prediction\n\n\n\nImage Source: Embry-Riddle Aeronautical University\n\n\nAn important task in aerodynamic design is predicting lift and drag forces on a body moving through air. Let’s consider a simplified problem where we are given an fixed airfoil design and our goal is to predict the drag force \\(F_d\\) on the airfoil as a function of three parameters which describe its flight conditions:\n\nThe angle of attack \\(\\alpha\\)\nThe density of the fluid \\(\\rho\\)\nThe freestream velocity of the air \\(v\\)\n\nTo put this problem in our abstract framework, we define \\(z = (\\alpha,\\rho,v)^\\top\\) to be a three-dimensional input, and take the output to be the drag force \\(y= F_d\\). In order to define a regression problem, we require the existence of a data set \\(\\{(z_i,y_i)\\}_{i=1}^N\\). Note that in this case \\(z_i = (\\alpha_i,\\rho_i,v_i)\\). We assume that this data set is given.\nIn linear regression problems, defining the model class amounts to choosing a set of regression features by defining \\(x\\). A simple choice takes the inputs themselves to be features: \\(x^{(1)}(z) = z = (\\alpha,\\rho,v)^\\top\\). This leads to a class of parametrized models with a three-dimensional unknown parameter vector \\(\\beta\\in\\mathbb{R}^3\\). The models in this class have the following form:\n\\[\nf^{(1)}(z;\\beta) = x^{(1)}(z)^\\top\\beta = (\\alpha,\\rho,v) \\beta = \\beta_1\\alpha + \\beta_2\\rho + \\beta_3 v.\n\\]\nThere are many other possible choices. For example, consider \\(x^{(2)}(z) = (\\alpha,\\rho, v, \\alpha^2, \\rho^2, v^2, \\alpha\\rho, \\alpha v, \\rho v)^\\top\\). This leads to a parametrized model class with a nine-dimensional unknown parameter vector \\(\\beta\\in\\mathbb{R}^9\\):\n\\[\n\\begin{aligned}\nf^{(2)}(z;\\beta) &= x^{(2)}(z)^\\top\\beta = (\\alpha,\\rho, v, \\alpha^2, \\rho^2, v^2, \\alpha\\rho, \\alpha v, \\rho v)\\beta \\\\\n&= \\beta_1\\alpha + \\beta_2\\rho + \\beta_3 v + \\beta_4\\alpha^2 + \\beta_5\\rho^2 + \\beta_6 v^2 + \\beta_7\\alpha\\rho + \\beta_8\\alpha v + \\beta_9 \\rho v\n\\end{aligned}\n\\]\nFor either the above choices of features \\(x^{(1)}(z)\\) or \\(x^{(2)}(z)\\), we could then define and solve the minimization Equation 2.2 to find the optimal regression parameters and define our learned model \\(f^{(1)}(z;\\beta^*)\\) or \\(f^{(2)}(z;\\beta^*)\\).\n\n\n\n\n\n\nUnderstanding notation\n\n\n\nNote that we use \\(\\beta\\) to denote the unknown parameters in both \\(f^{(1)}\\) and \\(f^{(2)}\\) above despite \\(\\beta\\) referring to different quantities in the definition of the different functions. This is a common notational shortcut — while we could use the notation \\(\\beta^{(1)}\\in\\mathbb{R}^3\\) and \\(\\beta^{(2)}\\in\\mathbb{R}^9\\) to specify the different \\(\\beta\\) for the different functions, this can be cumbersome if we are considering many different options for the choice of features \\(x(z)\\), and it’s standard to just use \\(\\beta\\), where the definition of \\(\\beta\\) is implied by the context. One of the challenges in learning about machine learning and computational mathematics more generally is getting used to similar notation meaning different things in different contexts. That’s one of the things that we’ll practice in this course."
  },
  {
    "objectID": "11_ls.html#example-2-something-else",
    "href": "11_ls.html#example-2-something-else",
    "title": "2  Linear Least Squares Problems",
    "section": "2.4 Example 2: something else",
    "text": "2.4 Example 2: something else"
  },
  {
    "objectID": "11_ls.html#example-3-something-else",
    "href": "11_ls.html#example-3-something-else",
    "title": "2  Linear Least Squares Problems",
    "section": "2.5 Example 3: something else",
    "text": "2.5 Example 3: something else"
  },
  {
    "objectID": "11_ls.html#exercises",
    "href": "11_ls.html#exercises",
    "title": "2  Linear Least Squares Problems",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\na few relatively short questions that test the learning outcomes."
  },
  {
    "objectID": "11_ls.html#classying-regression-problems-as-linear-vs-nonlinear",
    "href": "11_ls.html#classying-regression-problems-as-linear-vs-nonlinear",
    "title": "2  Linear Least Squares Problems",
    "section": "2.1 Classying regression problems as linear vs nonlinear",
    "text": "2.1 Classying regression problems as linear vs nonlinear\nWe have previously introduced regression problems in a general way: recall that the three ingredients of (parametrized) regression problems are (1) paired input and output data, (2) the choice of a parametrized model class, and (3) a method for choosing a model from within that class. The classification of a regression problem as linear or nonlinear depends solely on ingredient (2), the parametrized model class: if the models in that class depend linearly on the model parameters, the regression problem is a linear regression problem.\n\n\n\n\n\n\nCheck your knowledge: Do you remember what it means for a function to depend linearly on a variable?\n\n\n\n\n\nThe function \\(f(z;\\theta): \\mathbb{R}^d\\times\\Theta\\to\\mathbb{R}\\) is said to be linear in the parameters \\(\\theta\\) if, for all \\(a,b\\in\\mathbb{R}\\) and all \\(\\theta_1,\\theta_2\\in\\Theta\\), the following holds: \\(f(z; a\\theta_1 + b\\theta_2) = af(z;\\theta_1) + bf(z;\\theta_2)\\).\nNote that when we say a function is “linear”, we have to specify in what. That is, we can also say \\(f(z;\\theta)\\) is linear in the inputs if, for all \\(a,b\\in\\mathbb{R}\\) and all \\(z_1,z_2\\in\\mathbb{R}^d\\), the following holds: \\(f(az_1 + bz_2;\\theta) = af(z_1;\\theta)+bf(z_2;\\theta)\\).\n\n\n\nThe classification of regression problems as linear or nonlinear depends solely on the dependence of the functions in the parametrized model class on the parameters. That is, we can define functions that are linear in \\(\\theta\\) while being nonlinear in \\(z\\).\n\n\n\n\n\n\nExercise\n\n\n\nConsider the model classes (Equation 1.1)-(Equation 1.3) introduced previously. Are these model classes linear or nonlinear in the parameters? In the inputs?"
  },
  {
    "objectID": "11_ls.html#further-reading",
    "href": "11_ls.html#further-reading",
    "title": "2  Linear Least Squares Problems",
    "section": "2.7 Further reading",
    "text": "2.7 Further reading\nany appropriate links"
  },
  {
    "objectID": "12_lslinalg.html#matrix-notation",
    "href": "12_lslinalg.html#matrix-notation",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.1 matrix notation",
    "text": "3.1 matrix notation\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]"
  },
  {
    "objectID": "12_lslinalg.html#the-least-squares-optimization-problem",
    "href": "12_lslinalg.html#the-least-squares-optimization-problem",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.2 The Least-Squares Optimization Problem",
    "text": "3.2 The Least-Squares Optimization Problem\nOur goal is to adjust the parameters \\(\\beta\\) so that our predictions, \\(\\hat{\\mathbf{Y}}\\), are as close to the true outputs, \\(\\mathbf{Y}\\) as possible. One way to measure prediction error is with Mean Squared Error:\n\\[ \\text{MSE} = \\frac{1}{N} \\sum_{i=1}^N (\\hat{y}_i - y_i)^2 = \\frac{1}{N} || \\hat{\\mathbf{Y}} - \\mathbf{Y}||_2^2 = \\frac{1}{N} || \\mathbf{X} \\beta - \\mathbf{Y} ||_2^2 \\]\nthe \\(\\frac{1}{N}\\) is only a scalar, we wish to choose the value of \\(\\beta\\) that minimizes the following loss-function:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2 \\]"
  },
  {
    "objectID": "12_lslinalg.html#solving-the-least-squares-problem",
    "href": "12_lslinalg.html#solving-the-least-squares-problem",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.3 Solving the Least-Squares Problem",
    "text": "3.3 Solving the Least-Squares Problem\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum."
  },
  {
    "objectID": "12_lslinalg.html#experimental-example",
    "href": "12_lslinalg.html#experimental-example",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.4 Experimental Example",
    "text": "3.4 Experimental Example\nNow suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called df:\n\ndf.head()\n\n\n\n\n\n\n\n\nalpha\nrho\nvelocity\nf_drag\n\n\n\n\n0\n16.854305\n1.319114\n79.481130\n9425.204935\n\n\n1\n42.782144\n1.203298\n50.263709\n13722.379248\n\n\n2\n32.939727\n1.320528\n57.690388\n12863.441979\n\n\n3\n26.939632\n0.696729\n49.251769\n3644.076532\n\n\n4\n7.020839\n1.227098\n19.524299\n186.612122\n\n\n\n\n\n\n\nWe can create \\(\\mathbf{X}\\) and \\(\\mathbf{Y}\\) matrices by extracting the input features and outputs from the dataframe:\n\nX = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))\nY = df['f_drag'].values\n\nWe can solve for \\(\\hat{\\beta}\\) by computing the normal equations:\n\nbeta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n\nAnd then compute the model’s predictions at the training inputs:\n\nY_hat = X @ beta_hat\n\nNow let’s plot the \\(\\hat{\\mathbf{Y}}\\) and \\(\\mathbf{Y}\\) to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs:\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\nThere is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE:\n\nlinear_mse = np.linalg.norm(Y_hat - Y, 2) / N\nprint(\"Linear Features Mean-Squared Error: %.2f\" % (linear_mse))\n\nLinear Features Mean-Squared Error: 645.47"
  },
  {
    "objectID": "12_lslinalg.html#using-nonlinear-features-to-improve-model-performance",
    "href": "12_lslinalg.html#using-nonlinear-features-to-improve-model-performance",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.5 Using Nonlinear Features to Improve Model Performance",
    "text": "3.5 Using Nonlinear Features to Improve Model Performance\nWe know the underlying formula for drag-force is:\n\\[ F_d = \\frac{1}{2} \\rho v^2 C_d A  \\]\nWhile this function doesn’t depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens:\n\\[ \\ln(F_d) = \\ln(\\frac{1}{2} \\rho v^2 C_d A) = \\ln(\\frac{1}{2}) + \\ln(\\rho) + 2\\ln(v) + \\ln(C_d) + \\ln(A) \\]\nWhen our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let’s alter our inputs and outputs accordingly, so our problem becomes:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\ln \\alpha_1 & \\ln \\rho_1 & \\ln v_1 \\\\ 1 & \\ln \\alpha_2 & \\ln \\rho_2 & \\ln v_2 \\\\ & & \\vdots & \\\\ 1 & \\ln \\alpha_N & \\ln \\rho_N & \\ln v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} \\ln F_{d1} \\\\ \\ln F_{d2} \\\\ \\vdots \\\\ \\ln F_{d3} \\end{bmatrix} \\]\nLet’s see how this works programmatically:\n\nX_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))\nY_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)\n\nbeta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)\n\nY_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1\n\nplt.figure(figsize=(8,4))\nplt.scatter(Y, Y_hat_log)\nplt.grid()\nplt.xlabel(\"True Drag Force\")\nplt.ylabel(\"Model Predicted Drag Force\")\n\nText(0, 0.5, 'Model Predicted Drag Force')\n\n\n\n\n\nNow let’s see if our MSE has changed:\n\nlog_mse = np.linalg.norm(Y_hat_log - Y, 2)/N\nprint(\"Logarithmically Scaled Features Mean-Squared Error: %.2f\" % (log_mse))\n\nLogarithmically Scaled Features Mean-Squared Error: 144.70\n\n\nWe have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions."
  },
  {
    "objectID": "12_lslinalg.html#normal-equations",
    "href": "12_lslinalg.html#normal-equations",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.2 normal equations",
    "text": "3.2 normal equations\n\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum."
  },
  {
    "objectID": "12_lslinalg.html#range-kernel-and-expressivity-well-posedness",
    "href": "12_lslinalg.html#range-kernel-and-expressivity-well-posedness",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.1 range, kernel and expressivity, well-posedness",
    "text": "3.1 range, kernel and expressivity, well-posedness\nfeature selection\nmultiple solutions\nlow-rank or near-low-rank-ness"
  },
  {
    "objectID": "11_ls.html#solution-via-normal-equations",
    "href": "11_ls.html#solution-via-normal-equations",
    "title": "2  Linear Least Squares Problems",
    "section": "2.4 Solution via normal equations",
    "text": "2.4 Solution via normal equations\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]\n\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum."
  },
  {
    "objectID": "11_ls.html#matrix-notation",
    "href": "11_ls.html#matrix-notation",
    "title": "2  Linear Least Squares Problems",
    "section": "2.5 matrix notation",
    "text": "2.5 matrix notation\nSuppose we have taken \\(N\\) real-life samples of the input variables and their corresponding drag-force, \\(F_d\\). Let each sample of the system under various operating conditions form row of a matrix \\(\\mathbf{X} \\in \\mathbb{R}^{N \\times 4}\\) for the inputs and a matrix \\(\\mathbf{Y} \\in \\mathbb{R}^N\\) for their corresponding outputs:\n\\[ \\mathbf{X} = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} , \\mathbf{Y} = \\begin{bmatrix} F_{d1} \\\\ F_{d2} \\\\ \\vdots \\\\ F_{d3} \\end{bmatrix} \\]\nWe can efficiently compute the predictions of \\(h(\\mathbf{X}; \\beta)\\) with a simple matrix-vector multiplication:\n\\[ \\hat{\\mathbf{Y}} = \\mathbf{X} \\beta = \\begin{bmatrix} 1 & \\alpha_1 & \\rho_1 & v_1 \\\\ 1 & \\alpha_2 & \\rho_2 & v_2 \\\\ & & \\vdots & \\\\ 1 & \\alpha_N & \\rho_N & v_N \\end{bmatrix} \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\end{bmatrix} = \\begin{bmatrix}  \\beta_0 + \\beta_1 \\alpha_1 + \\beta_2 \\rho_1 + \\beta_3 v_1 \\\\ \\beta_0 + \\beta_1 \\alpha_2 + \\beta_2 \\rho_2 + \\beta_3 v_2  \\\\ \\vdots \\\\ \\beta_0 + \\beta_1 \\alpha_N + \\beta_2 \\rho_N + \\beta_3 v_N \\end{bmatrix}  \\in \\mathbb{R}^N \\]"
  },
  {
    "objectID": "11_ls.html#normal-equations",
    "href": "11_ls.html#normal-equations",
    "title": "2  Linear Least Squares Problems",
    "section": "2.6 normal equations",
    "text": "2.6 normal equations\n\nBecause the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as:\n\\[ L(\\beta) = ||\\mathbf{X} \\beta - \\mathbf{Y}||_2^2= (\\mathbf{X} \\beta - \\mathbf{Y})^\\top (\\mathbf{X} \\beta - \\mathbf{Y}) \\] \\[ = (\\beta^\\top \\mathbf{X}^\\top - \\mathbf{Y}^\\top) (\\mathbf{X} \\beta - \\mathbf{Y}) \\]\n\\[ = \\beta^\\top \\mathbf{X^\\top X} \\beta - 2 \\beta^\\top \\mathbf{X^\\top \\mathbf{Y}} + \\mathbf{Y^\\top Y}\\]\nAs we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:\n\\[ \\nabla L_\\beta = 2 \\mathbf{X^\\top X} \\beta - 2 \\mathbf{X^\\top Y} = \\mathbf{0}\\]\nSolving this equation for \\(\\beta\\) yields only one critical point:\n\\[ \\hat{\\beta} = (\\mathbf{X^\\top X})^{-1} \\mathbf{X^\\top Y} \\]\nTo check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian:\n\\[ \\nabla^2 L_\\beta = 2 \\mathbf{X^\\top X} \\]\nBecause the Hessian is symmetric positive semidefinite and does not depend on \\(\\beta\\), this means that \\(L(\\beta)\\) is convex everywhere. Hence, \\(\\hat{\\beta}\\) must be a global local minimum."
  },
  {
    "objectID": "11_ls.html#classifying-regression-problems-as-linear-vs-nonlinear",
    "href": "11_ls.html#classifying-regression-problems-as-linear-vs-nonlinear",
    "title": "2  Linear Least Squares Problems",
    "section": "2.1 Classifying regression problems as linear vs nonlinear",
    "text": "2.1 Classifying regression problems as linear vs nonlinear\nWe have previously introduced regression problems in a general way: recall that the three ingredients of (parametrized) regression problems are (1) paired input and output data, (2) the choice of a parametrized model class, and (3) a method for choosing a model from within that class. The classification of a regression problem as linear or nonlinear depends solely on ingredient (2), the parametrized model class: if the models in that class depend linearly on the model parameters, the regression problem is a linear regression problem.\n\n\n\n\n\n\nCheck your knowledge: Do you remember what it means for a function to depend linearly on a variable?\n\n\n\n\n\nThe function \\(f(z;\\theta): \\mathbb{R}^d\\times\\Theta\\to\\mathbb{R}\\) is said to be linear in the parameters \\(\\theta\\) if, for all \\(a,b\\in\\mathbb{R}\\) and all \\(\\theta_1,\\theta_2\\in\\Theta\\), the following holds: \\(f(z; a\\theta_1 + b\\theta_2) = af(z;\\theta_1) + bf(z;\\theta_2)\\).\nNote that when we say a function is “linear”, we have to specify in what. That is, we can also say \\(f(z;\\theta)\\) is linear in the inputs if, for all \\(a,b\\in\\mathbb{R}\\) and all \\(z_1,z_2\\in\\mathbb{R}^d\\), the following holds: \\(f(az_1 + bz_2;\\theta) = af(z_1;\\theta)+bf(z_2;\\theta)\\).\n\n\n\nThe classification of regression problems as linear or nonlinear depends solely on the dependence of the functions in the parametrized model class on the parameters. That is, we can define functions that are linear in \\(\\theta\\) while being nonlinear in \\(z\\).\n\n\n\n\n\n\nExercise\n\n\n\nConsider the model classes (Equation 1.1)-(Equation 1.3) introduced previously. Are these model classes linear or nonlinear in the parameters? In the inputs?"
  },
  {
    "objectID": "11_ls.html#assessing-the-learned-models",
    "href": "11_ls.html#assessing-the-learned-models",
    "title": "2  Linear Least Squares Problems",
    "section": "2.5 Assessing the learned models",
    "text": "2.5 Assessing the learned models\nvarious metrics, notion of a test data set. k-fold cross-validation for class?"
  },
  {
    "objectID": "12_lslinalg.html#qr-decomposition",
    "href": "12_lslinalg.html#qr-decomposition",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.2 QR decomposition",
    "text": "3.2 QR decomposition\nalgorithm, cost"
  },
  {
    "objectID": "12_lslinalg.html#svd",
    "href": "12_lslinalg.html#svd",
    "title": "3  LLS: Linear Algebra Perspective",
    "section": "3.3 SVD",
    "text": "3.3 SVD\nfor data reduction, and for regularization"
  }
]