{
  "hash": "85c33e85963d3d3cacbc4876c258583f",
  "result": {
    "markdown": "---\ntitle: \"Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent\"\nhtml-math-method:\n  method: mathjax\n  url: \"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\nnumber-sections: true\nformat: \n    html: default\nexecute:\n    echo: true\n    freeze: auto\n---\n\n# Problem Motivation\nSo far, we have developed analytical tools that allow us to find and classify critical points of functions. However, this analytical approach to finding minima is often infeasible, esecially when the objective function is a result of a numerical model. To combat this, we turn to interative algorithms that prgressively work towards finding a minimum while only relying on function and gradient evaluations. The main idea is that we will start from some initial guess $x_0$ and produce a sequence of points $x_1, x_2, x_3, \\ldots, x_j, \\ldots$, eventually converging to some local minimizer $x^\\star$. \n\nThere are two major classes of iterative optimization methods that produce the aforementioned sequence of points: *line search* methods and *trust region* methods. In this course, we will focus on the former, but we will provide some resources for those interested in the latter. Line search methods consist of three main steps that occur at each iteration:\n\n1. Identify a suitable *search direction* from the current point\n2. Determine a *step size* (by performing a line search)\n3. Move to the new point and update all function and gradient values\n\nThe whole process is summarized in the diagram below.\n\n\n\n```{mermaid}\n%%| echo: false\nflowchart LR\n  A(Starting guess) --> B(Search direction)\n  B --> C(Step size)\n  C --> D(Is this a minimum?)\n  D -->|Yes| E(Converged)\n  D -->|No| F(Update values)\n  F --> B\n\n```\n\n\n\nSteps 1 and 2 can be understood as two separate subproblems in the overall optimization scheme. In this note, we will examine the first of these subproblems by introducing the *steepest descent* algorithm, and seeing how the subproblem of determining a suitable step size arises as a natural consequence.\n\n\n\n# Steepest Descent\n## Motivation\nGiven some objective function $f$, recall that the gradient $\\nabla f$ is a vector with each component quantifying the function's local rate of change with respect to each variable.\n\n**Fact:** The gradient is a vector that points to the direction that yields the greatest function increase from the current point. \n\n**Idea:** From any given point $x$, we can find the direction of steepest descent by taking $-\\nabla f(x)$. So, we can define our search direction at iteration $k$ as: $p_k = -\\nabla f(x_k)$\n\nOne problem with the above idea is that the gradient does not give us any information regarding the step size we should take. Hence, the search direction is often normalized as:\n\n$$\np_k = -\\frac{\\nabla f(x_k)}{\\|\\nabla f(x_k)\\|_2}\n$$\n\n## Algorithm\nNeed to include an algorithm block here. \n\n## Example\nConsider the quadratic function:\n$$\nf(x_1, x_2) = x_1^2 + \\beta x_2^2\n$$\n\nFirst, let us consider the case where $\\beta = 1$ and the starting point is $x_0 = (10,1)$.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\n0.0002487577548903103\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nText(0, 0.5, '$x_2$')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](21_ugbo2_files/figure-html/cell-2-output-3.png){width=773 height=434}\n:::\n:::\n\n\nThis is a test citation [@martins2021engineering].\n\n",
    "supporting": [
      "21_ugbo2_files"
    ],
    "filters": [],
    "includes": {}
  }
}