---
title: "Introduction"
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
number-sections: true
execute:
    freeze: auto
---

{{< include _macros.qmd >}}

Welcome to AE 4803 AIM: Foundations of Scientific Machine Learning. This is a new course offered in the Spring 2025 term at Georgia Tech and is intended to be a "foundations" level course in the new College of Engineering AI for Engineering minor. 

## What's in a name? Artificial intelligence, machine learning, data science, and the scope of this course.

I googled "artificial intelligence" (often abbreviated AI) and the first result comes from Google's new "AI overview" feature[^1]:
![Image Source: Google.com](images/01_intro_AIgoogle.png){fig-align="center" width=100% fig-alt="Artificial intelligence (AI) is a field of study that focuses on developing machines that can learn, reason, and act in ways that are usually associated with human intelligence."}

[^1]: It seems apt to use AI to define AI, and I'm quoting it for illustrative purposes here, but I do want to point out that Google's AI Overview is not at all transparent about how these responses are generated and thus does not meet the standards for being cited as a source in most publishing venues. 

Because I closed the tab with my first search and wanted to go back to the webpage to copy the text for the image alt-text above, I repeated my search, and got a somewhat different answer: 
![Image Source: Google.com](images/01_intro_AIgoogle2.png){fig-align="center" width=100% fig-alt="Artificial intelligence (AI) is the ability of a machine to perform tasks that are usually associated with human intelligence."}

These are probably both reasonable definitions for casual conversation, but that's not what we're here for. Instead, we're here to really learn deeply about what AI is, and for that we're going to need **precision** -- that is, of our definitions. 

::: {.callout-note}
## Exercise
Consider the two different definitions of "AI" above carefully. In what (if any) senses are they (a) exactly the same, (b) similar, (c) somewhat different, (d) very different? What consequences might these differences have (a) developing AI algorithms, (b) evaluating AI impacts, (c) creating AI policies?
:::

I'm not going to provide a definition of AI for now and instead I'm going to throw two more terms into the mix that you may have heard. The first is "machine learning" (often abbreviated ML). Rather than get an AI definition for this too, I decided to go to the dictionary Merriam-Webster, which provides the following primary definition [@merriamML2024]: 

> a computational method that is a subfield of artificial intelligence and that enables a computer to learn to perform tasks by analyzing a large dataset without being explicitly programmed

And finally I'll add the term "data science" (curiously, rarely abbreviated DS). I wanted to give you a Merriam-Webster definition here, but the term isn't in their dictionary as of writing this on October 28, 2024. So instead I'm going to use Cambridge Dictionary's definition [@cambridgeDS2024]:

> the use of scientific methods to obtain useful information from computer data, especially large amounts of data

::: {.callout-note}
## Exercise
For both the terms "machine learning" and "data science", find an alternative definition from a source that is not a generative AI. What differences exist between the new definitions you've found and the ones I've cited above? 
:::

Clearly, different people/entities may have different ideas of what AI, ML, and data science may mean. Some people may use these terms  to describe generative tools like ChatGPT, GitHub copilot, and Dall-E (or similar products developed by other entities). Others use these terms to refer to more purpose-built algorithms like AlphaGo (for playing Go) or GraphCast (for weather prediction).[^2] Many academics use these terms to describe the study of the underlying mathematical and programming ideas on which such products are built.

[^2]: this paragraph lists examples that came to me most quickly and thus reflects to some extent my own cognitive biases based on the media I've consumed. I welcome suggestions of other examples of AI/ML/data science to include that are less well-known -- Email me!

My goal is not to give you a single definition of any of these terms and then to argue that my definition is more correct than any other definition. The point I want to make is that it's worth being clear about how we define these terms in any given context, whether it be in a textbook, a news article, or perhaps a spirited discussion between friends. To that end, I now want to make clear what it is that we will and will not cover in this class, which is a "foundations"-level course in the College of Engineering's AI minor. 

The focus of this class will be the mathematical and programming foundations of *scientific machine learning*, which I define as *the study of algorithms which use scientific data to define computational tools that perform useful scientific tasks*. The main scientific task that we will focus on in this course is the task of *predictive simulation*, which seeks to predict the behavior or outcomes of scientific or engineering systems. Predictive simulation is a key task in engineering disciplines like design and control, where we seek to predict design outcomes and control responses in order to make decisions about design parameters and control inputs. The class of machine learning methods that we will focus on in this class will therefore be *regression* methods, which use data to define relationships between inputs and outputs that allow us to take a specified input and issue a prediction for the output. 

## Regression methods: an overview

### Motivation and problem description
We use the notation $z\in \R^d$ to denote a real-valued vector of $d$ input variables, and the notation $y \in\R$ to denote a real-valued scalar output variable. Our goal is to be able to predict the value of $y$ if we know the value(s) of the input variable $z$. Some examples:

* in aerodynamic modeling, $z$ could contain airfoil geometry parameters like camber and thickness, and $y$ could represent the lift coefficient. Being able to predict $y$ from $z$ enables engineers to choose more aerodynamically efficient designs. 
* in orbital dynamics, $z$ could represent orbital parameters like altitude and inclination, and $y$ could represent the total time a satellite spends outside the sun's shadow in a given time period. Being able to predict $y$ from $z$ enables engineers to determine if a satellite's solar panels will generate enough power to support the satellite's mission. 
* in chemical process engineering, $z$ could represent conditions within a reactor like temperature and chemical mixture properties and $y$ could represent the reaction rate. Being able to predict $y$ from $z$ enables engineers to design more efficient reactors. 


::: {.callout-note}
## Exercise
Propose your own example scenario where it would be useful to predict real-valued outputs from inputs, drawing on your own experience, e.g. in personal projects, previous coursework, work/internship/co-op experiences, or extracurriculars. What would $z$ and $y$ represent? What does predicting $y$ from $z$ enable in your scenario?
:::

Mathematically, predicting $y$ from $z$ amounts to defining a *function* $f$ that takes in a $d$-dimensional input and outputs a scalar. Mathematical notational shorthand for this is $f:\R^d\to\R$. The question at hand is: how do we choose $f$? There are many ways to do so:

1. At a baseline, you could just make up a model: let's just say $y = f(z) = \|z\|^2$. This is mathematically valid, but it's probably a bad model for the three example scenarios above, because this model probably issues predictions that are very different from the true outputs. 

2. Alternatively, you could develop a model based on physical principles (a "physics-based" model) -- if you have taken classes in (aero/thermo)dynamics, then you would have learned some ways to calculate $y$ from $z$ in the above examples, e.g. based on potential flow theory, rigid body dynamics, or the Arrhenius equation. These models are likely to be more accurate than our made-up model above, although they are often imperfectly accurate because they make simplifying assumptions. One drawback of physics-based models is that they may be computationally expensive (some computational fluid dynamics simulations require many thousands of hours of supercomputing time). Additionally, fully physics-based models may not even exist in some applications (e.g., there are many aspects of plasma physics for which we currently lack a complete theoretical understanding).

3. Finally, our focus will be on using *data* to define a model (a "data-driven" model or a "learned" model). We assume that we have a data set consisting of $N$ pairs of input and output data, $(z_i,y_i)$ for $i = 1,\ldots,N$. To define our model, we want to choose an $f$ so that the predicted output $f(z_i)$ is close to the output data $y_i$ for all the data in our data set. This is sometimes called "fitting" the model to data. The advantages of data-driven models are that they may be significantly cheaper than physics-based models, and they can be fit to experimental data even when we lack scientific theory for developing physics-based models. The disadvantages are that data-driven models require data -- and the amount of data that would be "enough" to ensure that the learned model is accurate or useful is highly dependent on the application. 

Learning how to fit models to data and assess their accuracy and usefulness is the focus of this course. 

### Mathematical setting and problem formulation

formulation as selection from within a parametrized model class 

choosing parameters via optimization 

some implication of the breadth of methods

### Things that are not regression

I want to emphasize that this class is not and indeed cannot (realistically) be an exhaustive introduction to machine learning, artificial intelligence, or data science. Even the community of professionals who describe themselves as working in "scientific machine learning" is quite broad in scope and would include folks working on topics that I do not intend to cover in this class. There are many topics within AI/ML/data science we will not cover (beyond perhaps at most a very surface level), including generative modeling, decision trees, unsupervised learning methods like clustering, and many more. 

Give one example, list other examples, I cannot possibly hope to cover all these things in this course, so another goal of the course is to teach the language of ML so you are prepared to learn other things in future courses and on your own. 

## The three pillars of AI: mathematics, computation, and human intelligence 

mathematics is the language that describes what we want to do

computation/programming is the execution (translation)

human intelligence is woven throughout, specifies problem, evaluates results, re-specifies problem. 

### Course structure and intended learning outcomes
fill in nearer to term

<!-- ## A Motivating Example -->

<!-- ![Image Source: Embry-Riddle Aeronautical University](images/AirfoilDrag.png){fig-align="center" width=80%} -->
<!-- 
Suppose we wish to efficiently approximate the force of drag ($F_d$), measured in $N$, on a specific airplane wing if we only have access to the following information about the wing and its operating conditions: 

* The angle of attack ($\alpha$), measured in degrees
* The density of the fluid ($\rho$), measured in $kg/m^3$ 
* The velocity of the fluid ($v$), measured in $m/s$  -->

<!-- ## Linear Approximation of an Unknown Function

Let's bundle our inputs into a single vector, defined by: 

$$ \mathbf{x} = \begin{bmatrix} \alpha \\ \rho \\ v\end{bmatrix} $$ 


We assume there is some unknown function, $f(\cdot):\mathbb{R}^3 \rightarrow \mathbb{R}$, that gives us an optimal estimate for drag-force based on these "features": 

$$ F_d = f (\mathbf{x}) + \varepsilon $$ 

where $\varepsilon$ is some external noise, disturbances or information entirely independent of the input variables.  -->

<!-- Now consider a function $h(\mathbf{x}; \beta):\mathbb{R}^3 \rightarrow \mathbb{R}$ which is a simple linear combination of the inputs: 

$$ h(\mathbf{x}; \beta) = \begin{bmatrix} 1 & \mathbf{x}^\top \end{bmatrix} \begin{bmatrix}  \beta_0 \\ \beta_1 \\ \beta_2 \\ \beta_3  \end{bmatrix} = \beta_0 + \beta_1 \alpha + \beta_2 \rho + \beta_3 v $$

**The Million Dollar Question:**

Given we know the structure of $h(\mathbf{x}; \beta)$, how can we efficiently optimize the parameters of $h(\mathbf{x}; \beta)$ to best approximate $f(\mathbf{x})$? 

## Representing Observed Input-Output Data

Suppose we have taken $N$ real-life samples of the input variables and their corresponding drag-force, $F_d$. Let each sample of the system under various operating conditions form row of a matrix $\mathbf{X} \in \mathbb{R}^{N \times 4}$ for the inputs and a matrix $\mathbf{Y} \in \mathbb{R}^N$ for their corresponding outputs: 

$$ \mathbf{X} = \begin{bmatrix} 1 & \alpha_1 & \rho_1 & v_1 \\ 1 & \alpha_2 & \rho_2 & v_2 \\ & & \vdots & \\ 1 & \alpha_N & \rho_N & v_N \end{bmatrix} , \mathbf{Y} = \begin{bmatrix} F_{d1} \\ F_{d2} \\ \vdots \\ F_{d3} \end{bmatrix} $$ 

 
We can efficiently compute the predictions of $h(\mathbf{X}; \beta)$ with a simple matrix-vector multiplication: 

$$ \hat{\mathbf{Y}} = \mathbf{X} \beta = \begin{bmatrix} 1 & \alpha_1 & \rho_1 & v_1 \\ 1 & \alpha_2 & \rho_2 & v_2 \\ & & \vdots & \\ 1 & \alpha_N & \rho_N & v_N \end{bmatrix} \begin{bmatrix} \beta_0 \\ \beta_1 \\ \beta_2 \\ \beta_3 \end{bmatrix} = \begin{bmatrix}  \beta_0 + \beta_1 \alpha_1 + \beta_2 \rho_1 + \beta_3 v_1 \\ \beta_0 + \beta_1 \alpha_2 + \beta_2 \rho_2 + \beta_3 v_2  \\ \vdots \\ \beta_0 + \beta_1 \alpha_N + \beta_2 \rho_N + \beta_3 v_N \end{bmatrix}  \in \mathbb{R}^N $$ 

## The Least-Squares Optimization Problem

Our goal is to adjust the parameters $\beta$ so that our predictions, $\hat{\mathbf{Y}}$, are as close to the true outputs, $\mathbf{Y}$ as possible. One way to measure prediction error is with Mean Squared Error: 

$$ \text{MSE} = \frac{1}{N} \sum_{i=1}^N (\hat{y}_i - y_i)^2 = \frac{1}{N} || \hat{\mathbf{Y}} - \mathbf{Y}||_2^2 = \frac{1}{N} || \mathbf{X} \beta - \mathbf{Y} ||_2^2 $$ 

the $\frac{1}{N}$ is only a scalar, we wish to choose the value of $\beta$ that minimizes the following loss-function: 

$$ L(\beta) = ||\mathbf{X} \beta - \mathbf{Y}||_2^2 $$

## Solving the Least-Squares Problem

Because the squared 2-Norm can be rewritten as an inner product, we can rewrite this loss-function as: 

$$ L(\beta) = ||\mathbf{X} \beta - \mathbf{Y}||_2^2= (\mathbf{X} \beta - \mathbf{Y})^\top (\mathbf{X} \beta - \mathbf{Y}) $$
$$ = (\beta^\top \mathbf{X}^\top - \mathbf{Y}^\top) (\mathbf{X} \beta - \mathbf{Y}) $$

$$ = \beta^\top \mathbf{X^\top X} \beta - 2 \beta^\top \mathbf{X^\top \mathbf{Y}} + \mathbf{Y^\top Y}$$

As we learned in multivariable calculus, to find a the extrema of a continuous function, we need to identify the critical points of the function. This means setting the gradient of the loss-function equal to the zero-vector:

$$ \nabla L_\beta = 2 \mathbf{X^\top X} \beta - 2 \mathbf{X^\top Y} = \mathbf{0}$$ 

Solving this equation for $\beta$ yields only one critical point: 

$$ \hat{\beta} = (\mathbf{X^\top X})^{-1} \mathbf{X^\top Y} $$ 

To check whether this point is a local minimum, maximum, or neither, we examine the nature of the Hessian: 

$$ \nabla^2 L_\beta = 2 \mathbf{X^\top X} $$ 

Because the Hessian is symmetric positive semidefinite and does not depend on $\beta$, this means that $L(\beta)$ is convex everywhere. Hence, $\hat{\beta}$ must be a global local minimum. 

## Experimental Example

Now suppose we have 100 experimental observations of various angles of attack, air-densities and velocities with the corresponding drag-force in a pandas DataFrame called `df`: 

```{python}
#| echo: false
import numpy as np 
import matplotlib.pyplot as plt 
import pandas as pd
import math

np.random.seed(42)

def Cd(alpha):
    return 0.1 * np.exp(math.pi / 180.0 * alpha)

def Fd(alpha, rho, v):
    C_d = Cd(alpha)
    A = 1.2 # m^2 
    return 0.5*rho*alpha*v**2*C_d +1

N = 100
alpha = np.random.rand(N)*45
rho = np.random.randn(N)*0.3 + 1.293 
v = np.random.rand(N)*100
F_d = Fd(alpha, rho, v) + 0*np.random.randn(N)

df_dict = {
    "alpha":alpha,
    "rho":rho,
    "velocity":v, 
    "f_drag":F_d
}

df = pd.DataFrame(df_dict)
```

```{python}
df.head()
```

We can create $\mathbf{X}$ and $\mathbf{Y}$ matrices by extracting the input features and outputs from the dataframe: 

```{python}
X = np.hstack((np.ones((N, 1)), df[['alpha', 'rho', 'velocity']].values))
Y = df['f_drag'].values
```

We can solve for $\hat{\beta}$ by computing the normal equations: 

```{python}
beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ Y)
```

And then compute the model's predictions at the training inputs: 

```{python}
Y_hat = X @ beta_hat
```

Now let's plot the $\hat{\mathbf{Y}}$ and $\mathbf{Y}$ to examine how closely correlated the two are. A straight line with slope-1 would mean the model exactly fitted all of the outputs: 

```{python}
plt.figure(figsize=(8,4))
plt.scatter(Y, Y_hat)
plt.grid()
plt.xlabel("True Drag Force")
plt.ylabel("Model Predicted Drag Force")
```

There is clearly a strong, but nonlinear correlation between the true and model-predicted drag-force. This indicates that there is a nonlinear relationship between the features and the output values. Let us quantify the MSE: 

```{python}
linear_mse = np.linalg.norm(Y_hat - Y, 2) / N
print("Linear Features Mean-Squared Error: %.2f" % (linear_mse))
```

## Using Nonlinear Features to Improve Model Performance

We know the underlying formula for drag-force is: 

$$ F_d = \frac{1}{2} \rho v^2 C_d A  $$ 

While this function doesn't depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens: 

$$ \ln(F_d) = \ln(\frac{1}{2} \rho v^2 C_d A) = \ln(\frac{1}{2}) + \ln(\rho) + 2\ln(v) + \ln(C_d) + \ln(A) $$

When our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let's alter our inputs and outputs accordingly, so our problem becomes: 

$$ \mathbf{X} = \begin{bmatrix} 1 & \ln \alpha_1 & \ln \rho_1 & \ln v_1 \\ 1 & \ln \alpha_2 & \ln \rho_2 & \ln v_2 \\ & & \vdots & \\ 1 & \ln \alpha_N & \ln \rho_N & \ln v_N \end{bmatrix} , \mathbf{Y} = \begin{bmatrix} \ln F_{d1} \\ \ln F_{d2} \\ \vdots \\ \ln F_{d3} \end{bmatrix} $$ 

Let's see how this works programmatically: 

```{python}
X_log = np.hstack((np.ones((N, 1)), np.log(df[['alpha', 'rho', 'velocity']].values)))
Y_log = np.log(df['f_drag'].values - df['f_drag'].min() + 1)

beta_log = np.linalg.inv(X_log.T @ X_log) @ (X_log.T @ Y_log)

Y_hat_log = np.exp(X_log @ beta_log)+ df['f_drag'].min() - 1

plt.figure(figsize=(8,4))
plt.scatter(Y, Y_hat_log)
plt.grid()
plt.xlabel("True Drag Force")
plt.ylabel("Model Predicted Drag Force")
```

Now let's see if our MSE has changed: 

```{python}
log_mse = np.linalg.norm(Y_hat_log - Y, 2)/N
print("Logarithmically Scaled Features Mean-Squared Error: %.2f" % (log_mse))
```

We have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions.  -->

---