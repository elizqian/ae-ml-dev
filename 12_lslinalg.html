<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; LLS: Linear Algebra Perspective – AE 4803 AIM: Course Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./13_lsnla.html" rel="next">
<link href="./11_ls.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./12_lslinalg.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">LLS: Linear Algebra Perspective</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AE 4803 AIM: Course Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_ls.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Least Squares Problems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_lslinalg.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">LLS: Linear Algebra Perspective</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_lsnla.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">LLS: Computational Considerations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_ugbo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Unconstrained Gradient Based Optimization (UGBO)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_ugbo2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Unconstrained Gradient Based Optimization (UGBO) II - Steepest Descent</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_linalg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Linear algebra review</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#mathematical-problem-formulation" id="toc-mathematical-problem-formulation" class="nav-link active" data-scroll-target="#mathematical-problem-formulation"><span class="header-section-number">3.1</span> Mathematical problem formulation</a></li>
  <li><a href="#well-posedness-of-xbeta-y" id="toc-well-posedness-of-xbeta-y" class="nav-link" data-scroll-target="#well-posedness-of-xbeta-y"><span class="header-section-number">3.2</span> Well-posedness of <span class="math inline">\(X\beta = Y\)</span></a>
  <ul class="collapse">
  <li><a href="#well-posedness-of-square-linear-systems" id="toc-well-posedness-of-square-linear-systems" class="nav-link" data-scroll-target="#well-posedness-of-square-linear-systems"><span class="header-section-number">3.2.1</span> Well-posedness of square linear systems</a></li>
  <li><a href="#overdetermined-least-squares-problems" id="toc-overdetermined-least-squares-problems" class="nav-link" data-scroll-target="#overdetermined-least-squares-problems"><span class="header-section-number">3.2.2</span> Overdetermined least-squares problems</a></li>
  <li><a href="#underdetermined-least-squares-problems" id="toc-underdetermined-least-squares-problems" class="nav-link" data-scroll-target="#underdetermined-least-squares-problems"><span class="header-section-number">3.2.3</span> Underdetermined least-squares problems</a></li>
  <li><a href="#summary-of-linear-least-squares-problem-formulation" id="toc-summary-of-linear-least-squares-problem-formulation" class="nav-link" data-scroll-target="#summary-of-linear-least-squares-problem-formulation"><span class="header-section-number">3.2.4</span> Summary of linear least-squares problem formulation</a></li>
  </ul></li>
  <li><a href="#feature-selection-expressivity-accuracy-and-well-posedness" id="toc-feature-selection-expressivity-accuracy-and-well-posedness" class="nav-link" data-scroll-target="#feature-selection-expressivity-accuracy-and-well-posedness"><span class="header-section-number">3.3</span> Feature selection: expressivity, accuracy, and well-posedness</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">3.4</span> Exercises</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">LLS: Linear Algebra Perspective</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<!-- \renewcommand{\P}{\mathrm{P}} -->
<!-- $$
\DeclarePairedDelimiters{\set}{\{}{\}}
\DeclareMathOperator*{\argmax}{argmax}
$$

\definecolor{quarto-callout-note-color}{HTML}{4477AA} -->
</div>
<p>We now take a deeper dive into the structure of linear least squares problems. We will see how theoretical concepts from linear algebra can be used to describe and explain properties of learned linear regression models, and we will introduce fundamental algorithms from computational linear algebra that are used to solve linear least squares problems.</p>
<p>The intended learning outcomes of these notes are that students should be able to:</p>
<section id="mathematical-problem-formulation" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="mathematical-problem-formulation"><span class="header-section-number">3.1</span> Mathematical problem formulation</h2>
<p>We briefly recap the mathematical problem formulation that we consider. Given a data set <span class="math inline">\(\{(z_i,y_i)\}_{i=1}^N\)</span>, where <span class="math inline">\(z_i\in\mathbb{R}^d\)</span> and <span class="math inline">\(y_i\in\mathbb{R}\)</span> are paired inputs and outputs, we choose a feature mapping <span class="math inline">\(x: \mathbb{R}^d\to\mathbb{R}^n\)</span>. We seek to find coefficients <span class="math inline">\(\beta\in\mathbb{R}^n\)</span> so that the model</p>
<p><span class="math display">\[
f(z;\beta) = x(z)^\top\beta = \sum_{j=1}^n \beta_j x_j(z)
\]</span></p>
<p>accurately predicts the output <span class="math inline">\(y\)</span>. To do this, we define the matrix <span class="math inline">\(X\in\mathbb{R}^{N\times n}\)</span> and vector <span class="math inline">\(Y\in\mathbb{R}^N\)</span>,</p>
<p><span id="eq-def-X-y"><span class="math display">\[
X = \begin{pmatrix}
- &amp;x^\top(z_1) &amp; - \\
&amp; \vdots &amp; \\
- &amp; x^\top(z_N) &amp; -
\end{pmatrix},
\qquad
Y = \begin{pmatrix}
y_1 \\ \vdots \\ y_N
\end{pmatrix},
\qquad(3.1)\]</span></span></p>
<p>and write the least-squares problem as follows:</p>
<p><span id="eq-ls-matrix"><span class="math display">\[
X\beta = Y
\qquad(3.2)\]</span></span></p>
<p>This is a different notation than the minimization (<a href="11_ls.html#eq-linreg-minimization" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>) introduced earlier, but is also fairly common. One way to think of the expression <a href="#eq-ls-matrix" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> is to note that our goal is to find <span class="math inline">\(\beta\)</span> so that <span class="math inline">\(X\beta\)</span> is as close to <span class="math inline">\(Y\)</span> is possible – where ideally we would have <span class="math inline">\(X\beta = Y\)</span>. But <a href="#eq-ls-matrix" class="quarto-xref">Equation&nbsp;<span>3.2</span></a> has a more precise and technical meaning. The goal of these notes is to explain that precise technical definition and its implications for model learning.</p>
</section>
<section id="well-posedness-of-xbeta-y" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="well-posedness-of-xbeta-y"><span class="header-section-number">3.2</span> Well-posedness of <span class="math inline">\(X\beta = Y\)</span></h2>
<p>In math, the term “well-posedness” refers to the existence and uniqueness of solutions to a problem. We say a mathematical problem is “well-posed” if it has a unique solution. Existence and uniqueness of solutions may seem like abstract theoretical concepts, but as we will soon see, they have very practical consequences for the accuracy and reliability of the models we learn.</p>
<section id="well-posedness-of-square-linear-systems" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="well-posedness-of-square-linear-systems"><span class="header-section-number">3.2.1</span> Well-posedness of square linear systems</h3>
<p>Suppose for a moment that <span class="math inline">\(N = n\)</span>. Then the square linear system <span class="math inline">\(X\beta = Y\)</span> describes a system of <span class="math inline">\(n\)</span> linear equations for <span class="math inline">\(n\)</span> unknowns (the elements of the unknown coefficient vector <span class="math inline">\(\beta\in\mathbb{R}^n\)</span>). The problem of solving <span class="math inline">\(X\beta = Y\)</span> for <span class="math inline">\(\beta\)</span> is well-posed if and only if <span class="math inline">\(X\)</span> is invertible. In this case, the solution exists and is uniquely given by <span class="math inline">\(\beta=X^{-1}Y\)</span>.</p>
<p>Remember that in our setting, <span class="math inline">\(X\)</span> is a matrix of feature data (one row per data point), and <span class="math inline">\(Y\)</span> is a vector with the corresponding output data. For square invertible <span class="math inline">\(X\)</span>, the <em>existence</em> of a solution to <span class="math inline">\(X\beta=Y\)</span> means that there is a choice of <span class="math inline">\(\beta\)</span> so that the learned model will <em>interpolate</em> the data, i.e., the model will satisfy</p>
<p><span class="math display">\[
f(z_i;\beta) = y_i \quad \text{for all }i = 1,\ldots,N.
\]</span></p>
<p>The fact that the solution is <em>unique</em> means there is only one choice of <span class="math inline">\(\beta\)</span> that perfectly matches the data. Imagine for a moment if there were more than one choice of <span class="math inline">\(\beta\)</span> that perfectly matched the data: how would you choose which <span class="math inline">\(\beta\)</span> to use for predicting model outputs at new inputs?</p>
<p>What if <span class="math inline">\(X\)</span> is <em>not</em> invertible? This is clearly the case in the general linear regression problem we have set up where <span class="math inline">\(N\neq n\)</span> and <span class="math inline">\(X\)</span> is rectangular, but <span class="math inline">\(X\)</span> can also be non-invertible and square. There are essentially two ways <span class="math inline">\(X\)</span> can fail to be invertible:</p>
<ol type="1">
<li><p><span class="math inline">\(X\)</span> can have column rank less than <span class="math inline">\(n\)</span>, i.e., the number of linearly independent columns in <span class="math inline">\(X\)</span> is less than the number of columns <span class="math inline">\(n\)</span>. In this case, we say <span class="math inline">\(X\)</span> is “column rank-deficient” or <span class="math inline">\(X\)</span> “does not have full column rank”.</p></li>
<li><p><span class="math inline">\(X\)</span> can have row rank less than <span class="math inline">\(N\)</span>, i.e., the number of linearly independent rows in <span class="math inline">\(X\)</span> is less than the number of rows <span class="math inline">\(N\)</span>. In this case, we say <span class="math inline">\(X\)</span> is “row rank-deficient” or <span class="math inline">\(X\)</span> “does not have full row rank”.</p></li>
</ol>
<p>These are not mutually exclusive: <span class="math inline">\(X\)</span> can be simultaneously column rank-deficient and row rank-deficient. However, these different types of rank deficiencies have different consequences for well-posedness the existence and uniqueness of solutions, and different implications for learning linear regression models.</p>
</section>
<section id="overdetermined-least-squares-problems" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="overdetermined-least-squares-problems"><span class="header-section-number">3.2.2</span> Overdetermined least-squares problems</h3>
<p>Let’s start with the row rank-deficient case. If <span class="math inline">\(X\)</span> has fewer linearly independent rows than the total number of rows, this means that some of the rows of <span class="math inline">\(X\)</span> are redundant. This means that some of the linear equations represented by rows of the linear system <span class="math inline">\(X\beta=Y\)</span> have redundant left-hand sides. Because redundant equations place more constraints on the solution than can be simultaneously satisfied, this case is called the <em>overdetermined</em> case.</p>
<p>One way overdetermined linear systems can arise is if we have multiple copies of the same input in the data set, i.e., suppose <span class="math inline">\(z_1 = z_2\)</span>. Note that having multiple copies of the same input datum usually does not mean that the associated output data are also copies of each other (so you can still have <span class="math inline">\(y_1 \neq y_2\)</span>): for example, you might take multiple experimental measurements with the same configuration and get different measured values due to sensor noise or external factors that you don’t account for in your inputs. If this happens, your data set contains “contradictory” information, because <span class="math inline">\(x(z_1)^\top\beta=y_1\)</span> and <span class="math inline">\(x(z_2)^\top\beta= x(z_1)^\top\beta=y_2\)</span> cannot simultaneously be true.</p>
<p>What does row rank-deficiency mean for solving <span class="math inline">\(X\beta=Y\)</span>? In most cases this means that there is no choice of <span class="math inline">\(\beta\)</span> that will exactly solve the equation — the equality cannot simultaneously hold for all rows of the system. That means <em>no solution exists</em> for the linear system. This means there is no choice of <span class="math inline">\(\beta\)</span> that can perfectly match all the data.</p>
<p>Instead of looking for <span class="math inline">\(\beta\)</span> that yields a perfect match to the data, the least-squares problem formulation looks to minimize the misfit to the data. Let’s define the <em>residual</em> of the system as follows:</p>
<p><span id="eq-res-def"><span class="math display">\[
r(\beta) = X\beta-Y.
\qquad(3.3)\]</span></span></p>
<p>For a given parameter <span class="math inline">\(\beta\)</span>, the residual norm <span class="math inline">\(\|r(\beta)\|\)</span> is a measure of the model misfit over the training data set. Note that if <span class="math inline">\(X\beta=Y\)</span> holds with equality for all rows, then the residual (norm) is zero. In the overdetermined case where <span class="math inline">\(X\beta=Y\)</span>, since we can’t have a zero residual, we aim for the next best thing, which is minimizing the size of the residual (recall that the norm is a measure of the size of a vector)<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<p><span id="eq-ls-res-min"><span class="math display">\[
\beta^* = \arg\min_{\beta\in\mathbb{R}^n} \|r(\beta)\| = \arg\min_{\beta\in\mathbb{R}^n}\|r(\beta)\|^2
\qquad(3.4)\]</span></span></p>
<p>With the residual defined in <a href="#eq-res-def" class="quarto-xref">Equation&nbsp;<span>3.3</span></a>, the expression <a href="#eq-ls-res-min" class="quarto-xref">Equation&nbsp;<span>3.4</span></a> recovers our original expression for the formulation of a least-squares problem<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, <a href="11_ls.html#eq-linreg-minimization" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>. In this sense, the least-squares formulation “fixes” the lack of existence of a solution to the linear system due to row redundancy. For this reason, if you see <span class="math inline">\(X\beta=Y\)</span> written for a non-invertible system<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, the way you should understand that is in the sense of solving <a href="11_ls.html#eq-linreg-minimization" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>explain that row redundancy can also happen if not literally the same thing</p>
</div>
</div>
</section>
<section id="underdetermined-least-squares-problems" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="underdetermined-least-squares-problems"><span class="header-section-number">3.2.3</span> Underdetermined least-squares problems</h3>
<p>We now turn our attention to the column rank-deficient case. If <span class="math inline">\(X\)</span> has fewer linearly independent columns than the total number of columns, this means that some of the columns of <span class="math inline">\(X\)</span> are redundant. Recall that <span class="math inline">\(X\beta\in\mathbb{R}^N=\sum_{j=1}^n \beta_j x_j\)</span>, where <span class="math inline">\(x_j\in\mathbb{R}^N\)</span> is the <span class="math inline">\(j\)</span>th column of <span class="math inline">\(X\)</span>. If <span class="math inline">\(X\)</span> has redundant columns, this means that there are different ways to weight the columns of <span class="math inline">\(X\)</span> using the coefficients in <span class="math inline">\(\beta\)</span> that lead to the same model predictions. This means that requiring <span class="math inline">\(X\beta=Y\)</span> will not fully specify what <span class="math inline">\(\beta\)</span> is, so we call this the <em>underdetermined</em> case.</p>
<p>One way underdetermined systems arise is if there are more unknown coefficients in <span class="math inline">\(\beta\)</span> than there data points to constrain the problem. This can happen if we choose a very large set of features (<span class="math inline">\(n\)</span> large) but only have a small amount of data (<span class="math inline">\(N&lt;n\)</span>).</p>
<p>What does column rank-deficiency mean for solving <span class="math inline">\(X\beta=Y\)</span>? This means that <em>the solution is not unique</em>. This non-uniqueness comes from the fact that column rank-deficiency of <span class="math inline">\(X\)</span> means that <span class="math inline">\(X\)</span> has a nonzero kernel (aka nullspace). Recall that this means there exists some nonzero <span class="math inline">\(v\in\mathbb{R}^n\)</span> satisfying <span class="math inline">\(Xv = 0\)</span>. Let <span class="math inline">\(r^*\)</span> be the minimum possible residual,</p>
<p><span class="math display">\[
r^* = \min_{\beta\in\mathbb{R}^n}\|r(\beta)\|.
\]</span></p>
<p>Suppose we find some <span class="math inline">\(\beta^*\)</span> that leads to this minimum residual, so that <span class="math inline">\(r^* = X\beta^* - Y\)</span>. Well, if <span class="math inline">\(v\)</span> lies in the kernel of <span class="math inline">\(X\)</span>, then we can add any multiple of <span class="math inline">\(v\)</span> to <span class="math inline">\(\beta^*\)</span> and get the same minimum residual! That is, if <span class="math inline">\(\beta^*\)</span> is <em>a</em> solution to <a href="#eq-ls-res-min" class="quarto-xref">Equation&nbsp;<span>3.4</span></a>, then so is <span class="math inline">\(\beta^* + av\)</span> for any <span class="math inline">\(a\in\mathbb{R}\)</span>. This means there are infinitely many solutions. To make underdetermined problems well-posed, we have to decide on a way of choosing a single unique solution out of the many possible minimizers of <a href="#eq-ls-res-min" class="quarto-xref">Equation&nbsp;<span>3.4</span></a>.</p>
<p>Deciding on a method of choosing a single unique solution out of many possible solutions is called <em>regularization</em> and is a topic we will explore in more depth later. In the meantime, the most common and vanilla way of regularizing is to specify that we want to find what’s called the “minimum-norm” solution: i.e., out of all possible solutions, we take the smallest one. That is,</p>
<p><span id="eq-min-norm-ls"><span class="math display">\[
\beta^* = \arg\min_{\beta\in\mathbb{R}^n} \|\beta\| \quad \text{subject to } \|X\beta - Y\| = r^*.
\qquad(3.5)\]</span></span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>explain that col redundancy can also happen even if <span class="math inline">\(N\geq n\)</span> if features are redundant.</p>
</div>
</div>
</section>
<section id="summary-of-linear-least-squares-problem-formulation" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="summary-of-linear-least-squares-problem-formulation"><span class="header-section-number">3.2.4</span> Summary of linear least-squares problem formulation</h3>
<p>For <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span> defined as in <a href="#eq-def-X-y" class="quarto-xref">Equation&nbsp;<span>3.1</span></a>, to solve <span class="math inline">\(X\beta=Y\)</span> means to find the minimum-norm least-squares solution as described in <a href="#eq-min-norm-ls" class="quarto-xref">Equation&nbsp;<span>3.5</span></a>. This is generally what is happening under the hood when you use any scientific computing or machine learning software that has a built-in least-squares function, including</p>
<ul>
<li><tt>scipy.linalg.lstsq</tt></li>
<li><tt>numpy.linalg.lstsq</tt></li>
<li>MATLAB’s “backslash operator” <tt>\</tt> also known as <tt>mldivide</tt></li>
</ul>
<p>In a later chapter we will introduce some of the basic algorithms that are used to find (minimum-norm) least-squares solutions that these functions use. For now you should focus on understanding the precise mathematical definition of the least squares solution given in <a href="#eq-min-norm-ls" class="quarto-xref">Equation&nbsp;<span>3.5</span></a>.</p>
</section>
</section>
<section id="feature-selection-expressivity-accuracy-and-well-posedness" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="feature-selection-expressivity-accuracy-and-well-posedness"><span class="header-section-number">3.3</span> Feature selection: expressivity, accuracy, and well-posedness</h2>
<p>You may wonder why you should bother understanding what these built-in functions are doing if they’re going to just do them for you. One reason is that you can debug machine learning code much more effectively if you understand what the code is supposed to be doing theoretically. Another reason is that considerations of well-posedness have big implications for your job as an intelligent human designer of machine learning models.</p>
<p>For linear regression models, your job as an intelligent human is to decide on the <em>feature</em> mapping <span class="math inline">\(x:\mathbb{R}^d \to\mathbb{R}^n\)</span>, which determines what kinds of terms appear in your learned model.</p>
<p>give examples of choice of features (polynomial, fourier, random features/neural nets) as well as examples where you might downselect (image/PDE data)</p>
<p>explain expressivity in terms of the columnspace (range) of the features (basis), generally more features = more expressivity = more ability to match the training data</p>
<p>point out that however, more expressivity means more likely to be underdetermined, requiring regularization</p>
<p>link to overfitting and accuracy on test vs training data. move the cross validation part here?</p>
</section>
<section id="exercises" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="exercises"><span class="header-section-number">3.4</span> Exercises</h2>
<ul>
<li>some scenarios to classify as under or over-determined or both</li>
</ul>
<!-- ## Using Nonlinear Features to Improve Model Performance -->
<!-- We know the underlying formula for drag-force is: 

$$ F_d = \frac{1}{2} \rho v^2 C_d A  $$  -->
<!-- While this function doesn't depend on the angle of attack, we do see how the features are polynomially related to one another. Naturally, it is going to be difficult for a linear combination of features to replicate this. However, if we take the log of both sides, something interesting happens: 

$$ \ln(F_d) = \ln(\frac{1}{2} \rho v^2 C_d A) = \ln(\frac{1}{2}) + \ln(\rho) + 2\ln(v) + \ln(C_d) + \ln(A) $$

When our features and outputs are log-scaled, we see a friendly linear-combination of log-scaled versions features emerge! Let's alter our inputs and outputs accordingly, so our problem becomes: 

$$ \mathbf{X} = \begin{bmatrix} 1 & \ln \alpha_1 & \ln \rho_1 & \ln v_1 \\ 1 & \ln \alpha_2 & \ln \rho_2 & \ln v_2 \\ & & \vdots & \\ 1 & \ln \alpha_N & \ln \rho_N & \ln v_N \end{bmatrix} , \mathbf{Y} = \begin{bmatrix} \ln F_{d1} \\ \ln F_{d2} \\ \vdots \\ \ln F_{d3} \end{bmatrix} $$  -->
<!-- We have nearly a 5x reduction in MSE just by log-scaling our features! If we choose the right features, linear regression can be an extremely powerful method for approximating complex functions.  -->
<hr>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>Note that the second equality follows because squaring the norm doesn’t change where the minimum is because <span class="math inline">\(a^2\)</span> is monotone increasing in <span class="math inline">\(a\)</span> for non-negative <span class="math inline">\(a\)</span>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>up to a multiplying constant anyway, which I’ve emphasized before really doesn’t matter when it’s inside a minimization.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>see, for example, the documentation for the numpy function <a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.lstsq.html"><tt>linalg.lstsq</tt></a> or the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html#scipy.linalg.lstsq">scipy version</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./11_ls.html" class="pagination-link" aria-label="Linear Least Squares Problems">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Linear Least Squares Problems</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./13_lsnla.html" class="pagination-link" aria-label="LLS: Computational Considerations">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">LLS: Computational Considerations</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>